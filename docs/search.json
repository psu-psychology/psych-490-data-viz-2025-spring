[
  {
    "objectID": "supplemental/psych-sci-figs.html",
    "href": "supplemental/psych-sci-figs.html",
    "title": "Findings: Data viz in psych sci",
    "section": "",
    "text": "This page extracts information about the data visualizations we explored in Exercise-01 from the shared Google Sheet."
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#about",
    "href": "supplemental/psych-sci-figs.html#about",
    "title": "Findings: Data viz in psych sci",
    "section": "",
    "text": "This page extracts information about the data visualizations we explored in Exercise-01 from the shared Google Sheet."
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#survey",
    "href": "supplemental/psych-sci-figs.html#survey",
    "title": "Findings: Data viz in psych sci",
    "section": "Survey",
    "text": "Survey\nDirect link: https://docs.google.com/spreadsheets/d/1X-3kWpGAACdkAJ8-AeqYiu5TS6tRzpfdgXBYyPooCPo/edit?gid=0#gid=0\n\nLoading…"
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#preparation",
    "href": "supplemental/psych-sci-figs.html#preparation",
    "title": "Findings: Data viz in psych sci",
    "section": "Preparation",
    "text": "Preparation\nFirst, we load the external packages (groups of R commands) that we will be using.\n\n\n\n\n\n\nImportant\n\n\n\nThe code uses the quietly() function from the purrr package to suppress most of the feedback.\n\n\n\n\nCode\nlibrary('ggplot2')\nlibrary('dplyr')\n\nr_functions &lt;- list.files(file.path(here::here(), \"src\", \"R\"), \"\\\\.R$\", full.names = TRUE)\n\npurrr::map(r_functions, source) |&gt;\n  purrr::quietly()\n\n\nfunction (...) \ncapture_output(.f(...))\n&lt;bytecode: 0x106d76f28&gt;\n&lt;environment: 0x106d76c50&gt;"
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#gathering",
    "href": "supplemental/psych-sci-figs.html#gathering",
    "title": "Findings: Data viz in psych sci",
    "section": "Gathering",
    "text": "Gathering\nNext, we download the data from the Google Sheet where it is collected. Dr. Gilmore has stored his Google account credentials in a special environment file that can be accessed by the R command Sys.getenv(\"GMAIL_SURVEY\").\n\n\n\n\n\n\nTip\n\n\n\nIt’s vital to be very careful when creating and sharing code like this that involves sensitive information like login credentials.\nGilmore likes to put credentials in an .Renviron file that lives in his home directory. This is a recommended practice. On Mac OS and Linux, that’s ~/.Renviron. You can use the usethis::edit_r_profile() command at the R console (not the Terminal) to open your own .Renviron file. In Gilmore’s case, he has added the following line to that file:\nGMAIL_SURVEY=\"&lt;my-google-account&gt;\"\nHere, he has substituted his Google account with credentials/access to the required files for &lt;my-google-account&gt;. Then, when the R code below calls Sys.getenv(\"GMAIL_SURVEY\"), the value of those credentials is returned as a text string.\nMake sure to close and save the .Renviron file and restart your R session before testing this yourself.\n\n\n\n\nCode\nif (!dir.exists('csv')) {\n  message(\"Creating missing `csv/`.\")\n  dir.create(\"csv\")\n}\n\nif (params$update_data) {\n  options(gargle_oauth_email = Sys.getenv(\"GMAIL_SURVEY\"))\n  googledrive::drive_auth()\n\n  googledrive::drive_download(\n    \"PSYCH-490.003-Spr-2025-Psych-Viz\",\n    path = file.path(\"csv\", params$fn),\n    type = \"csv\",\n    overwrite = TRUE\n  )\n  message(\"Data updated.\")\n} else {\n  message(\"Using stored data.\")\n}\n\n\nThe data file has been saved as a comma-separated value (CSV) format data file in a special directory called csv/.\n\n\n\n\n\n\nNote\n\n\n\nBecause these data might contain sensitive or identifiable information, we only keep a local copy and do not share it publicly via GitHub. This is achieved by adding the name of the data directory to a special .gitignore file."
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#cleaning",
    "href": "supplemental/psych-sci-figs.html#cleaning",
    "title": "Findings: Data viz in psych sci",
    "section": "Cleaning",
    "text": "Cleaning\nNext we load the saved data file, and then proceed to clean it.\n\n\nCode\nex01 &lt;-\n  readr::read_csv(file.path(\"csv\", params$fn), show_col_types = FALSE)\n\n\nThere are 87 responses.\nThese are the column/variable names.\n\n\nCode\n# Google Forms puts the full question in the top row of the data file.\n# We use the names() function to extract and print the original questions.\nex01_qs &lt;- names(ex01)\nex01_qs\n\n\n[1] \"identifier\"    \"source_type\"   \"url_to_src\"    \"why_selected\" \n[5] \"comment\"       \"url_to_figure\"\n\n\nFor simplicity, we visualize below only those with non-empty URLs to the specific figure."
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#summary-data",
    "href": "supplemental/psych-sci-figs.html#summary-data",
    "title": "Findings: Data viz in psych sci",
    "section": "Summary data",
    "text": "Summary data\n\n\nCode\nfigs_w_urls &lt;- ex01 |&gt;\n  filter(!is.na(url_to_figure))\n\n\nThere were n=25 unique respondents.\nOf the 87 responses from these individuals or teams, n=67 had URLs we could link to directly."
  },
  {
    "objectID": "supplemental/psych-sci-figs.html#figures-found",
    "href": "supplemental/psych-sci-figs.html#figures-found",
    "title": "Findings: Data viz in psych sci",
    "section": "Figures found",
    "text": "Figures found\n\nCode\nthese_figs &lt;- ex01 |&gt;\n  filter(!is.na(url_to_figure))\n\nres &lt;- invisible(lapply(1:dim(these_figs)[1], return_img_chunk, df = these_figs))\ncat(unlist(res), sep = \"\\n\")\n\n\nFigure 1\nSource: https://www.psychologicalscience.org/observer/teaching-current-directions-in-psychological-science-27#lives\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nrog1\nweb_site\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 2\nSource: https://journals.sagepub.com/doi/full/10.1177/21677026241301298\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nrog1\narticle\nROC figures are used only in specialized contexts\n\n\n\n\n\n\nComments\n\n\n\n\nMore info about sensitivity and specificity: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n\n\n\n\n\nFigure 3\nSource: https://www.sfn.org/publications/latest-news/2020/01/27/the-brain-may-need-iron-for-healthy-cognitive-development\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nbre1\narticle\nI was drawn in to the topic examining the impact of iron on cognitive development and found the scatterplot to be very informative, however a bit difficult to interpret at first glance.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 4\nSource: https://psycnet.apa.org/fulltext/2025-31206-001.pdf?auth_token=7fcec614b0825ba1032680320e7e094213c3f483\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nbre1\narticle\nI enjoyed the mindmap used within the article, I felt it was very digestible to the public eye and conveyed the meaning and significance of the topic.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 5\nSource: https://psycnet.apa.org/doiLanding?doi=10.1037%2Fdev0001841\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nbre1\narticle\nThe conceptual diagram caught my eye as it provided a great visual of the upward incline and the severity of this effect.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 6\nSource: https://www.nature.com/articles/s41380-023-02202-z/figures/1\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\ntjd1\narticle\nI thought this visualization was about an interesting topic, and also enjoyed exploring story it tells - the ages of onset for various mental illnesses in young people.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 7\nSource: https://www.eneuro.org/content/11/10/ENEURO.0210-24.2024/tab-figures-data\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nilw 1\narticle\nIllusionism and visual processing.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 8\nSource: https://journals.sagepub.com/cms/10.1177/0956797618761373/asset/images/large/10.1177_0956797618761373-fig2.jpeg\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nilw 1\narticle\nI had not seen a study conducted on a mundane idea like this before which makes it intriguing. It compares the enjoyment level of the giver versus the reciever of a personalized versus a “normal” or plain mug. It is very straightforward and easy to read.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 9\nSource: https://srcd.onlinelibrary.wiley.com/cms/asset/907c790a-fabe-474b-b142-3b4799f38ce3/cdev14156-fig-0002-m.png\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nilw 1\narticle\nParents’ judgement of their children’s cognitive ability versus children’s actual cognitive ability level. It is straightforward and easy to read, interesting concept.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 10\nSource: https://journals.sagepub.com/doi/full/10.1177/19485506231204463\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc 1\narticle\nNetwork and mediation/moderation example\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 11\nSource: https://www.jneurosci.org/content/44/44/e0231242024/tab-figures-data\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc 1\narticle\nExtremely complex and dense visualization\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 12\nSource: https://www.jneurosci.org/content/44/37/e2236232024/tab-figures-data\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc 1\narticle\nExample of neuroimaging, BOLD signal visualization\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 13\nSource: https://journals.sagepub.com/doi/full/10.1177/19485506231211628\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc 1\narticle\nSimple comparative visualization\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 14\nSource: https://piktochart.com/wp-content/uploads/2023/03/track-national-unemployment.jpg\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\njvm\nwebsite\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 15\nSource: https://www.apa.org/pubs/reports/stress-in-america/2024/postelection-stress-coping-during-holidays\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI thought the small pictures next to each item was a unique feature that I have not seen on many other graphics of that nature\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 16\nSource: https://journals.sagepub.com/doi/10.1177/09567976241286865\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI have never seen this type of visualization with areas of colors surrounding the lines showing the range of values. I think the differences in colors greatly help to distinguish data and show how they may interact\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 5\n\n\n\n\n\nFigure 17\nSource: https://journals.sagepub.com/doi/10.1177/15291006231221978\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI found the separate graph breakdown of number of studies to be very thorough and the differing graphs with different colors ensured that the data could be visualized appropriately based on the category\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 18\nSource: https://www.proquest.com/psycarticles/docview/3156133891/B9D8033C647D446CPQ/11?accountid=13158&sourcetype=Scholarly%20Journals\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI appreciate the overlap in the data being shown directly on the same graph to better understand differences in data\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 19\nSource: https://www.proquest.com/psycarticles/docview/3108366413/902261B578114B8FPQ/1?accountid=13158&sourcetype=Scholarly%20Journals\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI have never seen this type of visualization with the length of vector used to symbolize data.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 20\nSource: https://www.proquest.com/psycarticles/docview/3156133920/B9D8033C647D446CPQ/13?accountid=13158&sourcetype=Scholarly%20Journals\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nThis graph distinguishes data by total and direct effect to understand variable significance and I have never seen a graph of this nature.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 4\n\n\n\n\n\nFigure 21\nSource: https://www.proquest.com/psycarticles/docview/3156133916/B33C55DC844C41DEPQ/1?accountid=13158&sourcetype=Scholarly%20Journals\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI appreciate the distinguishing of demographic by color to quickly identify varying categories of interaction\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 22\nSource: https://www.proquest.com/psycarticles/docview/3154909502/298FE26D70EF4859PQ/14?accountid=13158&sourcetype=Scholarly%20Journals\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI think this study researching the differences in number of words men and women speak each day is insightful and I appreciate the further breakdown by age group\n\n\n\n\n\n\nComments\n\n\n\n\nFigures 3-4\n\n\n\n\n\nFigure 23\nSource: https://www.proquest.com/psycarticles/docview/1539480322/FDF2333734CC41FBPQ/9?accountid=13158&sourcetype=Scholarly%20Journals\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\narticle\nI am interested in the relationship between life satisfaction regarding the workplace and I feel this graph concisely presents the data related to life satiafaction in couples after an unemployment event\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 24\nSource: https://www.sciencedirect.com/science/article/abs/pii/S0022399923002945?via%3Dihub\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nrta5133 (Rand)\narticle\nI selected this because it particularly visualizes cross-lagged variables which I thought is interesting. It also has signs such as epsilons to denote residuals and a lot of arrows which I thought merit a second peek.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 25\nSource: https://srcd.onlinelibrary.wiley.com/doi/10.1111/cdev.14152\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nApf1\narticle\nI liked the topic of study and how the data was displayed\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 26\nSource: https://link.springer.com/article/10.3758/s13421-017-0708-1?fromPaywallRec=false\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\njxu5065\narticle\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 27\nSource: https://www.science.org/doi/10.1126/scirobotics.adn3802\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\njxu5065\narticle\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 28\nSource: https://www.nature.com/articles/s41562-024-02077-2\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nNMSL\narticle\nThe relation between AI and human communication is clearly showed.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 29\nSource: https://www.nature.com/articles/s41598-024-75262-y?fromPaywallRec=false\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nNMSL\narticle\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 30\nSource: https://journals.sagepub.com/doi/epub/10.1177/21677026221121762\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nssw, hrq, tjd\nJournal\nBar graph representing 3 different measured variables amongst racial populations within Los Angeles.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 31\nSource: https://journals.sagepub.com/stoken/default+domain/10.1177%2F15291006211051956-FREE/pdf\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nssw,hrq, tjd\nwebsite\nThis journal explains what creating effective visuals for data communication and research.\n\n\n\n\n\n\n\n\n\nComments\n\n\n\n\nfigure 1: This is useful to understanding how visuals affect the growth of data.\n\n\n\n\n\nFigure 32\nSource: https://www.nature.com/articles/s41380-023-02202-z/figures/1\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nssw,hrq, tjd\narticle\nI thought this visualization was about an interesting topic, and also enjoyed exploring story it tells - the ages of onset for various mental illnesses in young people.\n\n\n\n\n\n\nComments\n\n\n\n\nFrom Society of Research on Adolesence\n\n\n\n\n\nFigure 33\nSource: https://journals.sagepub.com/doi/epub/10.1177/21677026221121762\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nssw,hrq, tjd\nJournal\nHeat map of Los Angeles showing health and economic status differences\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 34\nSource: https://www.tandfonline.com/doi/full/10.1080/15622975.2022.2112074#d1e584\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\narticle\nThe flow chart shows the conceptual steps that a “lifestyle-based” mental health care provider would use\n\n\n\n\n\n\nComments\n\n\n\n\nAPA\n\n\n\n\n\nFigure 35\nSource: https://www.nature.com/articles/s41586-024-08359-z\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\narticle\nThis chart clearly shows the comparison of errors between languages that the program was created to know\n\n\n\n\n\n\nComments\n\n\n\n\nNature (Journal)\n\n\n\n\n\nFigure 36\nSource: https://www.nature.com/articles/s41586-024-08423-8\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\narticle\nThis “Image” shows 8 different graphs and charts that help to paint the whole picture of the validation of MAVs and PVVs in regards to the prolonged persistence of mutagenic DNA lesions in somatic cells\n\n\n\n\n\n\nComments\n\n\n\n\nNature (Journal)\n\n\n\n\n\nFigure 37\nSource: https://www.nature.com/articles/s41562-024-02077-2\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\narticle\nThis image shows the interaction between AI and humans through flow charts and points plotted on a graph\n\n\n\n\n\n\nComments\n\n\n\n\nNature Human Behavior (Journal)\n\n\n\n\n\nFigure 38\nSource: https://www.nature.com/articles/s41562-024-02061-w\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\narticle\nThis image shows 3 different types of visualizations of the data regarding reporting-error-adjusted participation weights\n\n\n\n\n\n\nComments\n\n\n\n\nNature Human Behavior (Journal)\n\n\n\n\n\nFigure 39\nSource: https://iovs.arvojournals.org/article.aspx?articleid=2793527\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nThis figure shows an easy to understand representation for the experiment taking place of a drug injection into the eye with results of leakage\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 40\nSource: https://www.apa.org/news/press/releases/stress/2023/collective-trauma-recovery\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nFigure clearly puts data into seperate visual categories to make their point on stress levels pre pandemic vs post pandemic by age specifically\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 41\nSource: https://www.tandfonline.com/doi/full/10.1080/00221325.2024.2400362#d1e771\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure is interesting because it shows the association between teacher-student relationship quality and maternal depressive symptoms and children’t externalizing behavior problem. This shows the importance of maternal depressive symptom to teacher-student relationship.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 4\n\n\n\n\n\nFigure 42\nSource: https://onlinelibrary-wiley-com.ezaccess.libraries.psu.edu/doi/10.1002/dys.1790\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows an word cloud of 25 interviews on raising awareness of dyslexia, it shows a simple photo that has the result of 25 interviews\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 43\nSource: https://onlinelibrary.wiley.com/doi/full/10.1111/jora.13045\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows how adolescent with elevated depression before and during the COVID-19 will more likely to be in the high risk profile.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 44\nSource: https://onlinelibrary.wiley.com/doi/full/10.1111/jora.13052\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the correlation of LGBTQ+ state policies and mental health symptomology with other factors like school safety, peer victimization, and others.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 45\nSource: https://myscp-onlinelibrary-wiley-com.ezaccess.libraries.psu.edu/doi/10.1002/jcpy.1446\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the anticipated negative impact on the relationship between gift given on time and late, from gift recipient and gift giver.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 46\nSource: https://journals-sagepub-com.ezaccess.libraries.psu.edu/doi/10.1177/1077801212440017\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the rate of reports and arrest for forcible rape per 100,000 U.S. inhabitants. It shows how there is a large amount of reported rape compared to a small amount of arrest\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 47\nSource: https://www.apa.org/pubs/reports/practitioner/2024\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nzw\nwebsite\nThe graph is about the frequency of AI usage for psychologists at different career stage and I find that interesting\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 48\nSource: https://www.apa.org/monitor/2024/01/trends-pathways-access-mental-health-care\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nzw\nwebsite\nThe figure shows 90% of the public believe there’s a mental health crisis in the US but a lot of the people I know dont even believe in mental health issues\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 49\nSource: &lt;Self‐reported alcohol consumption during participation in a text messaging‐based online drinking moderation platform - Vadhan - 2024 - Alcohol, Clinical and Experimental Research - Wiley Online Library&gt;\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nzw\narticle\nI am working on a lab projject that is related to drinking\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 50\nSource: https://journals.sagepub.com/doi/10.1177/1077801212440017\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nzw\narticle\nThis figure is about reports of forcible rape to law enforcement and the number of arrests resulted, as a woman I care about this kind of issue\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 51\nSource: https://featuredcontent.psychonomic.org/color-me-impressed-psychology-research-links-colors-and-emotions-for-over-a-century/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nRta5133(Rand)\nNews article\nI thought they very intellignetly modeled the participants connection of color and emotion\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 52\nSource: https://featuredcontent.psychonomic.org/neural-processing-of-sarcasm-hows-that-for-a-great-title/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nRta5133 (Rand)\nNews article\nI thought they did a very good job to represent the brain activity results in an intuitive manner\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 53\nSource: https://featuredcontent.psychonomic.org/neural-processing-of-sarcasm-hows-that-for-a-great-title/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThe information shown on the figure is interesting because it shows the weighted mean of trust in scientist across countries and religion\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 54\nSource: https://www.nature.com/articles/s41562-024-02071-8\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the nut-cracking efficiency of the chimpanzees.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 55\nSource: https://www.nature.com/articles/s41586-024-08375-z\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the pattern of extinction risk in tetrapods and freshwater species\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 56\nSource: https://www.nature.com/articles/s41586-024-08448-z\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the percentage of catch with different levels of rights devolution in formally governed SSF\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 57\nSource: https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(21)00051-6\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the percentage of “yes” response of whether the headline were accurate or whether they consider sharing to true and false headlines\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2a\n\n\n\n\n\nFigure 58\nSource: https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(24)00269-9\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\narticle\nThis figure shows the memory decay in animals studied\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1c\n\n\n\n\n\nFigure 59\nSource: https://featuredcontent.psychonomic.org/color-me-impressed-psychology-research-links-colors-and-emotions-for-over-a-century/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nkvv\narticle\nThe graph is interesting because it easily shows and connects different colors to different emotions.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 60\nSource: https://www.nature.com/articles/s41562-024-02077-2\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nkvv\narticle\nThis graph was a great way of demonstarting to someone how the affects of AI can disrupt human feedback compared to human-human interactions\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 61\nSource: https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(24)00253-5\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nkvv\narticle\nI decided to pick this graph because it is very confusing. This graph is really interesting because it is (i feel) is overpacked. Too many graphs and images on 1 figure\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 62\nSource: https://www.jneurosci.org/content/41/1/3#abstract-1\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\ntps5764\narticle\nI mainly chose this graph because I rarely see dot-plots like this one in papers. I see bar graphs used much more often, so I found the choice to use dots interesting.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 63\nSource: https://link.springer.com/article/10.3758/s13421-023-01476-6\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\ntps5764\narticle\nI chose this graph because I really like the topic of memory, and was one of my favorite classes.\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 64\nSource: https://pmc.ncbi.nlm.nih.gov/articles/PMC5722463/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nhtt5112\narticle\nI chose this graph because with the rise of social media, we can see how it creates loneliness and social awkwardness\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 65\nSource: https://psycnet.apa.org/fulltext/2005-03224-011.html\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nhtt5112\narticle\nI chose this graph because everyone experiences stressful situations, especially college students\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 66\nSource: https://pmc.ncbi.nlm.nih.gov/articles/PMC4286245/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nhtt5112\narticle\nI chose this graph because college students are able to relate to it and can see how important sleep is for our brains\n\n\n\n\n\n\nComments\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 67\nSource: https://www.jneurosci.org/content/45/4/etwij45042025\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nash99\narticle\nI chose this figure because it does a great job of visually depicting brain activity when responding to sound and auditory rhythym processing by the brain.\n\n\n\n\n\n\nComments\n\n\n\n\nNA"
  },
  {
    "objectID": "supplemental/ex01-feedback.html",
    "href": "supplemental/ex01-feedback.html",
    "title": "Feedback on Exercise 01",
    "section": "",
    "text": "This page provides some general comments about the write-ups submitted for Exercise 01.\nPlease take these observations to heart and implement them in future assignments."
  },
  {
    "objectID": "supplemental/ex01-feedback.html#about",
    "href": "supplemental/ex01-feedback.html#about",
    "title": "Feedback on Exercise 01",
    "section": "",
    "text": "This page provides some general comments about the write-ups submitted for Exercise 01.\nPlease take these observations to heart and implement them in future assignments."
  },
  {
    "objectID": "supplemental/ex01-feedback.html#observations",
    "href": "supplemental/ex01-feedback.html#observations",
    "title": "Feedback on Exercise 01",
    "section": "Observations",
    "text": "Observations\n\nThe best submissions wrote a complete essay. The submissions included an introductory paragraph, several body paragraphs, usually one per figure, a conclusion, and a reference section.\nThe best submissions also mentioned the purpose of the exercise: To evaluate how some sample figures from various sources in psychological science communicated information about some topic.\nThe best submissions read the papers or websites where the figures were drawn from and provided helpful information about what the figures were depicting.\nThe best submissions adhered to the APA paper format. Here is a sample template.\nWhile it wasn’t required for the exercise, papers that provided excerpts of the figures under discussion were easier to evaluate. We did not penalize submissions that did not provide figure excerpts because the assignment did not require it. To capture images for future exercises, see the tutorial."
  },
  {
    "objectID": "exercises/ex07-figs-w-python.html",
    "href": "exercises/ex07-figs-w-python.html",
    "title": "Exercise 07",
    "section": "",
    "text": "Work in progress\n\n\n\nThis page is under construction."
  },
  {
    "objectID": "exercises/ex05-figure-prep-guidelines.html",
    "href": "exercises/ex05-figure-prep-guidelines.html",
    "title": "Exercise 05",
    "section": "",
    "text": "Work in progress\n\n\n\nThis page is under construction."
  },
  {
    "objectID": "exercises/ex05-figure-prep-guidelines.html#dates",
    "href": "exercises/ex05-figure-prep-guidelines.html#dates",
    "title": "Exercise 05",
    "section": "Dates",
    "text": "Dates"
  },
  {
    "objectID": "exercises/ex05-figure-prep-guidelines.html#goals",
    "href": "exercises/ex05-figure-prep-guidelines.html#goals",
    "title": "Exercise 05",
    "section": "Goals",
    "text": "Goals\n\nRead and understand published figure preparation guidelines for prospective authors of scientific manuscripts.\nEvaluate the guidelines relative to the best practices we’ve discussed this semester in class."
  },
  {
    "objectID": "exercises/ex05-figure-prep-guidelines.html#assignment",
    "href": "exercises/ex05-figure-prep-guidelines.html#assignment",
    "title": "Exercise 05",
    "section": "Assignment",
    "text": "Assignment\n\nBackground\nSome scientific journals provide advice to prospective authors about how to prepare figures for manuscripts submitted to the journals. Here are two examples:\n\nNature\nAmerican Psychological Association (APA)\n\n\n\nTasks\n\nFind and read critically the guidelines for publishing figures in a journal of your choosing.\nCompare the guidelines to the best practices that we have discussed this semester in class (@ Franconeri, Padilla, Shah, Zacks, & Hullman, 2021; Knaflic, 2015; Tufte, 2001).\nDo the guidelines reflect current knowledge about data visualization practices. If not how could the guidelines be amended to provide better guidance to authors in these journals?"
  },
  {
    "objectID": "exercises/ex05-figure-prep-guidelines.html#submit",
    "href": "exercises/ex05-figure-prep-guidelines.html#submit",
    "title": "Exercise 05",
    "section": "Submit",
    "text": "Submit\nA 3-5 pp (750-1,300 word) write-up of your findings."
  },
  {
    "objectID": "exercises/ex03-making-data.html",
    "href": "exercises/ex03-making-data.html",
    "title": "Exercise 03",
    "section": "",
    "text": "In-class work on Tuesday, January 28 and Thursday, January 30.\nSubmit write-up for credit due by Tuesday, Feburary 11."
  },
  {
    "objectID": "exercises/ex03-making-data.html#dates",
    "href": "exercises/ex03-making-data.html#dates",
    "title": "Exercise 03",
    "section": "",
    "text": "In-class work on Tuesday, January 28 and Thursday, January 30.\nSubmit write-up for credit due by Tuesday, Feburary 11."
  },
  {
    "objectID": "exercises/ex03-making-data.html#goals",
    "href": "exercises/ex03-making-data.html#goals",
    "title": "Exercise 03",
    "section": "Goals",
    "text": "Goals\nIn this exercise, you will work alone or with a team of classmates to create a survey using the Google Forms tool. The survey you create will be used later in the course for data visualizations that you will also create."
  },
  {
    "objectID": "exercises/ex03-making-data.html#assignment",
    "href": "exercises/ex03-making-data.html#assignment",
    "title": "Exercise 03",
    "section": "Assignment",
    "text": "Assignment\n\nSign-in to the Google drive account associated with your Penn State Access ID. This will make it somewhat easier for us to share forms.\nOpen Google Forms by visiting https://forms.google.com.\nCreate a new form by clicking on the ‘Blank Form’ button.\n\n{fig-google-form-blank-form} 3. Give your form a useful title, for example, ‘PSYCH-490.003-2025-spring-team-A’ or ‘PSYCH-490.003-2025-spring-rog1’.\n\n\n\n\n\n\nImportant\n\n\n\nYou can be assigned a team name/letter if you choose.\nIf you\n\n\n\nCustomize the theme if you wish by clicking on the palette icon.\nCreate a survey with 8 questions. Your questions should be ones that your classmates can answer without embarrassment or loss of privacy and which meet the following criteria:\n\n\nGenerate two questions with nominal (un-ordered) answers (e.g., favorite color).\nGenerate two questions with ordinal (e.g., 1-5) answers analogous to a Likert scale.\nGenerate two questions with continuous answers (e.g., age and shoe size). It doesn’t matter if these are interval or ratio scaled.\nGenerate one question with a date or time as an answer (e.g., a favorite relative’s birthday).\nInclude one field for comments.\n\n\nWhen you are happy with a draft of your survey, conduct a quality assurance (QA) review of it by having your team or someone else take the survey. The easiest way to do this is to use the ‘Send’ button to send your survey to you collaborator(s).\n\n\n\n\nGoogle Forms ‘Send’\n\n\nMake sure to have your QA testers answer the Comments question with the same response, e.g., ‘test-response’. This will make it easier later to filter-out the test responses.\n\nMake sure that all of your collaborators have edit privileges on the form. Click on the ‘more’ button with three dots and add collaborators.\n\n\n\n\nAdd collaborators"
  },
  {
    "objectID": "exercises/ex03-making-data.html#submit",
    "href": "exercises/ex03-making-data.html#submit",
    "title": "Exercise 03",
    "section": "Submit",
    "text": "Submit\nWhether or not you are submitting a write-up for Exercise 03, please add Dr. Gilmore (rog1@psu.edu) and Sara He (cfh5558@psu.edu) as collaborators on the survey so that we can all benefit from your good work.\nPlease also add the URL to your survey to this Google Sheet:\nhttps://docs.google.com/spreadsheets/d/1Z-TJQLOQ-yFBs0UimtCtv4pWIqcfq7jhAUA1QjVX89w/edit?usp=sharing\nIf you are submitting a short 2-4 page write-up via Canvas, please provide answers to the following questions:\n\nWhat is a defining feature of data items that are nominal?\n\nWhat assumptions might analysts make about ordinal data when it comes time to visualize or analyze the results?\n\nWhat assumptions must a researcher make when conducting survey research of this sort?\n\nFocusing on those available within Google Forms, what user interface(s) work best for different types of data?\n\nIf you’ve used Qualtics previously to generate surveys, briefly compare Qualtrics with Google Forms."
  },
  {
    "objectID": "exercises/ex01-figs-in-psych-sci.html",
    "href": "exercises/ex01-figs-in-psych-sci.html",
    "title": "Exercise 01",
    "section": "",
    "text": "In-class work on Tuesday, January 14 and Thursday, January 16.\nWrite-up for credit due on Thursday, January 23.\nCanvas dropbox.\n\n\n\n\n\n\nPost-submission feedback\n\n\n\nWe have prepared a page with general feedback that should be helpful for future assignments. The feedback can be found here."
  },
  {
    "objectID": "exercises/ex01-figs-in-psych-sci.html#dates",
    "href": "exercises/ex01-figs-in-psych-sci.html#dates",
    "title": "Exercise 01",
    "section": "",
    "text": "In-class work on Tuesday, January 14 and Thursday, January 16.\nWrite-up for credit due on Thursday, January 23.\nCanvas dropbox.\n\n\n\n\n\n\nPost-submission feedback\n\n\n\nWe have prepared a page with general feedback that should be helpful for future assignments. The feedback can be found here."
  },
  {
    "objectID": "exercises/ex01-figs-in-psych-sci.html#goals",
    "href": "exercises/ex01-figs-in-psych-sci.html#goals",
    "title": "Exercise 01",
    "section": "Goals",
    "text": "Goals\nIn this exercise, you may choose to work alone or with a team of classmates to find data visualizations from the societies of three (3) professional associations and three (3) journals. You will add links to the visualizations to a common database that we will use for discussion about the types of visualizations and types of data that are commonly used in psychological science."
  },
  {
    "objectID": "exercises/ex01-figs-in-psych-sci.html#assignment",
    "href": "exercises/ex01-figs-in-psych-sci.html#assignment",
    "title": "Exercise 01",
    "section": "Assignment",
    "text": "Assignment\n\nVisit the websites of at least three (3) professional associations.\n\nThe following are examples. Feel free to choose a different professional society.\n\nAmerican Psychological Association (APA)\nAssociation for Psychological Science (APS)\nVision Sciences Society\nSociety for Personality and Social Psychology\nSociety for Research in Child Development\nSociety for Research on Adolescence\nCognitive Neuroscience Society\nSociety for Neuroscience\nPsychonomics Society\nSociety for Industrial and Organizational Psychology\n\n\nFor each society website, find at least two visualizations of data.\n\nTry to pick visualizations that are interesting to you in some way.\n\nAdd information about the visualizations to a Google Sheet that all of us will share:\n\nhttps://docs.google.com/spreadsheets/d/1X-3kWpGAACdkAJ8-AeqYiu5TS6tRzpfdgXBYyPooCPo/edit?usp=sharing\nSpecifically, enter your team identifier in the identifier field, the source in source_type, and the URL in the url field. Please say briefly why you chose this particular visualization. If you have any comments to add, put those in the comments field.\nDuring class on 2025-01-16, Gilmore added a url_to_figure field. If you want to add that, right click on the image and see if an option to ‘open image in new tab’ or ‘copy image address’ is available.\n\n\n\n\n\n\nImportant\n\n\n\nYou do not have to use your PSU ID as your identifier.\nGilmore did so just to provide some sample data.\n\n\n\nNext, visit the websites of at least three (3) journals and do the same thing–pick at least two (2) visualizations from each of the journals.\n\nNote that some societies publish one or more journals, so you might find a journal that interests you from the society website.\nHere are some additional journal resources that you might find interesting to explore:\n\nScience Magazine\nNature\nNature Human Behavior\nTrends in Cognitive Sciences\nAnnual Reviews\n\nFigures with “psychology” as search term\nFigures with “neuroscience” as search term\nKnowable Magazine has a graphics library\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe goal here is to gather via ‘crowd-sourcing’ a diverse set of visualizations. So, feel free to mix it up."
  },
  {
    "objectID": "exercises/ex01-figs-in-psych-sci.html#submit",
    "href": "exercises/ex01-figs-in-psych-sci.html#submit",
    "title": "Exercise 01",
    "section": "Submit",
    "text": "Submit\n\nEveryone\n\nYour data to the shared Google Spreadsheet.\n\nStudents who want this submission to count for one of their four (4) required exercises\n\nA 2-3 page write-up in APA format where you describe three (3) figures your group found, focusing on these questions:\n\nWhat graphic elements of the visualization map to which aspects of the data?\nWhat prior knowledge does someone viewing these data need to have in order to understand the visualizations clearly?\nWhy is the source presenting these data?\nWhat story or message is the source trying to communicate and to what audience?\nHow effective is the message?\n\nStudents who work in teams should submit one (1) write-up with all of the authors’ names. One grade will be assigned.\nNote: Your references section need only include the citation to the source paper or website. You should identify in your text which figure you have chosen to analyze.\n\n\n\n\n\n\n\n\nAPA template\n\n\n\nThis template document may be helpful."
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#announcements",
    "href": "slides/wk03-2025-01-30-figure-types.html#announcements",
    "title": "Figure types",
    "section": "Announcements",
    "text": "Announcements\n\nDue on Tuesday, February 11: Exercise-03 | Canvas dropbox\nExercise 01 feedback"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#last-time",
    "href": "slides/wk03-2025-01-30-figure-types.html#last-time",
    "title": "Figure types",
    "section": "Last time…",
    "text": "Last time…\nMaking data"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#core-ideas",
    "href": "slides/wk03-2025-01-30-figure-types.html#core-ideas",
    "title": "Figure types",
    "section": "Core ideas",
    "text": "Core ideas\n\nData are made\n\nMap characteristics (of people, things) to quantities/categories\n\nBy some measurement procedure\n\nReflect, but also select and deflect (Burke, 1968)\n\nMappings have different scale types (Stevens, 1946)\nScales determine i) permissible/logical stats & ii) best visualizations"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#data-typesscales",
    "href": "slides/wk03-2025-01-30-figure-types.html#data-typesscales",
    "title": "Figure types",
    "section": "Data types/scales",
    "text": "Data types/scales\n\nExtending Stevens (1946), see also Wikipedia contributors (2024)\n\n\n\nNominal\n\nBinary (0,1)\nCategorical\n\nOrdinal\n\ne.g., 1st, 2nd, 3rd, …"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#data-types-continued",
    "href": "slides/wk03-2025-01-30-figure-types.html#data-types-continued",
    "title": "Figure types",
    "section": "Data types (continued)",
    "text": "Data types (continued)\n\n\nCounts\n\ne.g., 1, 2, 3, 4, …\n\nContinuous/Real-valued\n\nInterval\nRatio\n\nSpatial data"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#what-data-types",
    "href": "slides/wk03-2025-01-30-figure-types.html#what-data-types",
    "title": "Figure types",
    "section": "What data type(s)?",
    "text": "What data type(s)?\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/supplemental/psych-sci-figs.html#figure-1"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#what-data-types-1",
    "href": "slides/wk03-2025-01-30-figure-types.html#what-data-types-1",
    "title": "Figure types",
    "section": "What data type(s)?",
    "text": "What data type(s)?\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/supplemental/psych-sci-figs.html#figure-3"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#what-data-types-2",
    "href": "slides/wk03-2025-01-30-figure-types.html#what-data-types-2",
    "title": "Figure types",
    "section": "What data type(s)?",
    "text": "What data type(s)?\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/supplemental/psych-sci-figs.html#figure-26"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#what-data-types-3",
    "href": "slides/wk03-2025-01-30-figure-types.html#what-data-types-3",
    "title": "Figure types",
    "section": "What data type(s)?",
    "text": "What data type(s)?\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/supplemental/other-field-figs.html#figure-15"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#what-data-types-4",
    "href": "slides/wk03-2025-01-30-figure-types.html#what-data-types-4",
    "title": "Figure types",
    "section": "What data type(s)?",
    "text": "What data type(s)?\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/supplemental/other-field-figs.html#figure-21"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#today",
    "href": "slides/wk03-2025-01-30-figure-types.html#today",
    "title": "Figure types",
    "section": "Today",
    "text": "Today\n\nExercise 03 Making Data\nMapping data types to figures"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#goals",
    "href": "slides/wk03-2025-01-30-figure-types.html#goals",
    "title": "Figure types",
    "section": "Goals",
    "text": "Goals\n\nPractice making instruments for different data types\nUnderstand how different data types map to\n\ndifferent types of data visualizations\ndifferent types of data summaries\n\nGain an appreciation of the variety of data visualizations"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#considerations",
    "href": "slides/wk03-2025-01-30-figure-types.html#considerations",
    "title": "Figure types",
    "section": "Considerations",
    "text": "Considerations\n\nWhat figure type(s) are appropriate for the data type\nWhat figure type(s) are most informative/least misleading"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#nominal-data",
    "href": "slides/wk03-2025-01-30-figure-types.html#nominal-data",
    "title": "Figure types",
    "section": "Nominal data",
    "text": "Nominal data\n\nBar chart\nPie chart\nRing/donut chart\nMosaic chart (2 variables)"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#ordinal-data",
    "href": "slides/wk03-2025-01-30-figure-types.html#ordinal-data",
    "title": "Figure types",
    "section": "Ordinal data",
    "text": "Ordinal data\n\nAll of the nominal types…\nSorted in some order based on the ordinal variable"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#some-examples",
    "href": "slides/wk03-2025-01-30-figure-types.html#some-examples",
    "title": "Figure types",
    "section": "Some examples",
    "text": "Some examples\n\nUsing data created here"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#bar-chart",
    "href": "slides/wk03-2025-01-30-figure-types.html#bar-chart",
    "title": "Figure types",
    "section": "Bar chart",
    "text": "Bar chart\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#visualizing"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#bar-lollipop-chart-mappings",
    "href": "slides/wk03-2025-01-30-figure-types.html#bar-lollipop-chart-mappings",
    "title": "Figure types",
    "section": "Bar, lollipop chart mappings",
    "text": "Bar, lollipop chart mappings\n\nWhat data component maps to what figure dimension?\n\n\n\n\nNumber of observations in category \\(\\rightarrow\\) height/length\nColor-category \\(\\rightarrow\\) fill color\nSchool \\(\\rightarrow\\) position on horizontal axis"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#making-figures",
    "href": "slides/wk03-2025-01-30-figure-types.html#making-figures",
    "title": "Figure types",
    "section": "Making figures",
    "text": "Making figures\n\nMultiple possible figure types for each data/scale type\nDifferent data \\(\\rightarrow\\) figure feature mappings\nFigure types vary in clarity\n\nPerceiving length/height vs. area"
  },
  {
    "objectID": "slides/wk03-2025-01-30-figure-types.html#references",
    "href": "slides/wk03-2025-01-30-figure-types.html#references",
    "title": "Figure types",
    "section": "References",
    "text": "References\n\n\n\n\nBurke, K. (1968). Language as Symbolic Action. University of California Press. Retrieved from https://www.ucpress.edu/books/language-as-symbolic-action/paper\n\n\nChannel, M. O. (2024). Every CHART types explained in 12 minutes. Youtube. Retrieved from https://www.youtube.com/watch?v=cuMwWvtNmJ0\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science (New York, N.Y.), 103, 677–680. https://doi.org/10.1126/science.103.2684.677\n\n\nWikipedia contributors. (2024, November 23). Statistical data type. Retrieved from https://en.wikipedia.org/wiki/Statistical_data_type"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#mortality-trends-by-education-level",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#mortality-trends-by-education-level",
    "title": "Data viz in art, sports, & journalism",
    "section": "Mortality trends by education level",
    "text": "Mortality trends by education level\n\nNovosad, Rafkin, & Asher (2022)"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#announcements",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#announcements",
    "title": "Data viz in art, sports, & journalism",
    "section": "Announcements",
    "text": "Announcements\n\nExercise 01 due\nTutorial on capturing images"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#last-time",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#last-time",
    "title": "Data viz in art, sports, & journalism",
    "section": "Last time…",
    "text": "Last time…\nVisualization in government and business"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#what-did-we-uncover",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#what-did-we-uncover",
    "title": "Data viz in art, sports, & journalism",
    "section": "What did we uncover?",
    "text": "What did we uncover?\n\nSummary report"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#today",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#today",
    "title": "Data viz in art, sports, & journalism",
    "section": "Today",
    "text": "Today\nVisualization in art, sports, & journalism"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#goals",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#goals",
    "title": "Data viz in art, sports, & journalism",
    "section": "Goals",
    "text": "Goals\n\nWhat sort(s) of visualizations are common in these fields?\nApply principles of semiotics to these visualizations.\n\nSemantics: Mappings between signs and what they signify?\nSyntax: Rules for arrangement/organization"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#musical-notation",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#musical-notation",
    "title": "Data viz in art, sports, & journalism",
    "section": "Musical notation",
    "text": "Musical notation\n\nhttps://www.britannica.com/art/musical-notation"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#antecdents",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#antecdents",
    "title": "Data viz in art, sports, & journalism",
    "section": "Antecdents",
    "text": "Antecdents\n\nhttps://www.britannica.com/art/musical-notation/Evolution-of-Western-staff-notation"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#hebrew-trope",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#hebrew-trope",
    "title": "Data viz in art, sports, & journalism",
    "section": "Hebrew trope",
    "text": "Hebrew trope\n\nWikipedia contributors (2025a)"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#styles",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#styles",
    "title": "Data viz in art, sports, & journalism",
    "section": "Styles",
    "text": "Styles\n\nStyle guide"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#what-is-being-mapped",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#what-is-being-mapped",
    "title": "Data viz in art, sports, & journalism",
    "section": "What is being mapped?",
    "text": "What is being mapped?\n\nPitch\nTiming, tempo\nLoudness\nStylistic properties\netc."
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#dance",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#dance",
    "title": "Data viz in art, sports, & journalism",
    "section": "Dance",
    "text": "Dance\n\nFlores (2021)"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#visual-arts",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#visual-arts",
    "title": "Data viz in art, sports, & journalism",
    "section": "Visual arts",
    "text": "Visual arts\n\n“Blue Skies and Cloud Cover” by Laura Guertin, BTAA Data Viz 2024 Champion"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#examples",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#examples",
    "title": "Data viz in art, sports, & journalism",
    "section": "Examples",
    "text": "Examples\n\nhttps://operations.nfl.com/gameday/analytics/stats-articles/\nhttps://www.tableau.com/sports-data"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#data-journalism",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#data-journalism",
    "title": "Data viz in art, sports, & journalism",
    "section": "Data journalism",
    "text": "Data journalism\n\nThe Economist\nThe New York Times"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#the-washington-post",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#the-washington-post",
    "title": "Data viz in art, sports, & journalism",
    "section": "The Washington Post",
    "text": "The Washington Post\n\nVan Dam (2022)"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#accuweather.com",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#accuweather.com",
    "title": "Data viz in art, sports, & journalism",
    "section": "Accuweather.com",
    "text": "Accuweather.com\n\nhttps://www.accuweather.com/en/us/state-college/16801/weather-forecast/335315?current=true"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#knowable-magazine",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#knowable-magazine",
    "title": "Data viz in art, sports, & journalism",
    "section": "Knowable Magazine",
    "text": "Knowable Magazine\n\nhttps://knowablemagazine.org/\nGraphics library"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#data-viz-outside-psi",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#data-viz-outside-psi",
    "title": "Data viz in art, sports, & journalism",
    "section": "Data viz outside \\(\\Psi\\)",
    "text": "Data viz outside \\(\\Psi\\)\n\nNon-science fields visualize data, too\nMultiple purposes/uses of data viz"
  },
  {
    "objectID": "slides/wk02-2025-01-23-art-sports-journ.html#references",
    "href": "slides/wk02-2025-01-23-art-sports-journ.html#references",
    "title": "Data viz in art, sports, & journalism",
    "section": "References",
    "text": "References\n\n\n\n\nFlores, M. S. (2021). Graph dance 2021 (STEM ingenuity grp 2). Youtube. Retrieved from https://www.youtube.com/watch?v=VQYuNKvbPDg\n\n\nFowers, A., & Van Dam, A. (2024, December 13). Unraveling america’s great puritan-name resurgence. The Washington Post. The Washington Post. Retrieved from https://www.washingtonpost.com/business/2024/12/13/virtue-names-hope-faith-charity/\n\n\nNovosad, P., Rafkin, C., & Asher, S. (2022). Mortality change among less educated americans. American Economic Journal. Applied Economics, 14, 1–34. https://doi.org/10.1257/app.20190297\n\n\nParis, F. (2025, January 13). Childhood vaccination rates were falling even before the rise of R.F.K. jr. The New York Times. The New York Times. Retrieved from https://www.nytimes.com/interactive/2025/01/13/upshot/vaccination-rates.html\n\n\nsmalin. (2011). Beethoven, symphony 9, 4th movement (complete) ode to joy, presto, philharmonia baroque. Youtube. Retrieved from https://www.youtube.com/watch?v=ljGMhDSSGFU\n\n\nStiles, M., O’Key, S., Manley, B., Robinson, L., Merrill, C., Choi, A., … Rigdon, R. (2025, January 8). Visualizing the los angeles wildfires in maps and charts. Retrieved January 12, 2025, from https://www.cnn.com/2025/01/08/us/maps-visuals-los-angeles-wildfires-dg/index.html\n\n\nVan Dam, A. (2022, June 29). Where fun facts are serious business. The Washington Post. The Washington Post. Retrieved from https://www.washingtonpost.com/business/2022/06/29/dept-of-data/\n\n\nWikipedia contributors. (2025a, January 5). Hebrew cantillation. Retrieved from https://en.wikipedia.org/wiki/Hebrew_cantillation\n\n\nWikipedia contributors. (2025b, January 12). Musical notation. Retrieved from https://en.wikipedia.org/wiki/Musical_notation"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#william-playfair",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#william-playfair",
    "title": "Semiotics of data visualization",
    "section": "William Playfair",
    "text": "William Playfair\n\n\n\n“engineer, political economist, and scoundrel” (Spence & Wainer, 2017)\nFounder of graphical methods of statistics\nIntroduced line, area, and bar chart\nLikely published first pie chart and circle graphs\n\n\n\n\n\nEarliest statistical graphic, William Playfair; Wikipedia"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#announcements",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#announcements",
    "title": "Semiotics of data visualization",
    "section": "Announcements",
    "text": "Announcements\n\nFree access to newspapers\n\n ## Announcements\n\nMay change class location"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#last-time",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#last-time",
    "title": "Semiotics of data visualization",
    "section": "Last time…",
    "text": "Last time…\n\nCourse introduction"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#today",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#today",
    "title": "Semiotics of data visualization",
    "section": "Today",
    "text": "Today\n\nVisualization in psychological science\n\nExercise-01\n\nSemiotics of data visualization"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#resources",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#resources",
    "title": "Semiotics of data visualization",
    "section": "Resources",
    "text": "Resources\n\nAssignment\nGoogle Sheet for capturing & sharing data"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#measures-in-psi-science",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#measures-in-psi-science",
    "title": "Semiotics of data visualization",
    "section": "Measures in \\(\\Psi\\) science",
    "text": "Measures in \\(\\Psi\\) science\n\n\nInternal states (thoughts, feelings, memories, opinions, decisions, judgments…)\nPhysiological states\nIndividual characteristics\nEnvironmental characteristics"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#questions",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#questions",
    "title": "Semiotics of data visualization",
    "section": "Questions",
    "text": "Questions\n\nAre there common types of visualizations in psychological science?\nWhat (types) messages are conveyed?\nHow clearly are they conveyed?\nHow are the following depicted?\n\nResponses to surveys\nPerformance on tasks/tests\nBrain structure or activity"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#semi-whatics",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#semi-whatics",
    "title": "Semiotics of data visualization",
    "section": "Semi-whatics?",
    "text": "Semi-whatics?\n\nThe Editors of Encyclopedia Britannica (2024)"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#the-symbolic-animal",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#the-symbolic-animal",
    "title": "Semiotics of data visualization",
    "section": "The symbolic animal",
    "text": "The symbolic animal\n\nErnst Cassirer\n\n\nCassirer argues that the classic Aristotelian definition of the human being as a rational animal is wrong, or at least incomplete. Instead we should think of ourselves as “symbolic animals,” since ratiocination is only one expression of the human instinct to think in symbols. Kirsch (2021)"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#the-communicating-animal",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#the-communicating-animal",
    "title": "Semiotics of data visualization",
    "section": "The communicating animal",
    "text": "The communicating animal\n\nCommunication as transmission of information\nFrom world\n\n\n\n\n\n\nflowchart LR\n  A[World] --&gt; B[You]"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#communication",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#communication",
    "title": "Semiotics of data visualization",
    "section": "Communication",
    "text": "Communication\n\nFrom others (direct)\n\n\n\n\n\n\nflowchart LR\n  A[Me] --&gt; B[You]\n\n\n\n\n\n\n\nFrom others (via some medium)\n\n\n\n\n\n\nflowchart LR\n  A[Me] --&gt; B((Medium))\n  B --&gt; C[You]"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#media",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#media",
    "title": "Semiotics of data visualization",
    "section": "Media",
    "text": "Media\n\nSource of signs1\nSign relation\n\nSign (as a thing) –&gt; Meaning\nRelation is arbitrary, defined by social convention (Sausurre)\n\n\nmore general than language"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#core-qualities-of-sign-systems",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#core-qualities-of-sign-systems",
    "title": "Semiotics of data visualization",
    "section": "Core qualities of sign systems",
    "text": "Core qualities of sign systems\n\nSemantics\n\nRelations between signs –&gt; meaning\n\nSyntax (grammar)\n\nRules/conventions for arranging signs"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#multiple-input-channels",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#multiple-input-channels",
    "title": "Semiotics of data visualization",
    "section": "Multiple input channels",
    "text": "Multiple input channels\n\n\n\nAcoustic\nTactile\nOlfactory\nVisual\n\n\n\n\n\nhttps://elearning.adobe.com/2018/04/classic-learning-research-practice-sensory-channels-keep-learners-attention/"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#vary-in-meaningfulness",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#vary-in-meaningfulness",
    "title": "Semiotics of data visualization",
    "section": "Vary in ‘meaningfulness’",
    "text": "Vary in ‘meaningfulness’\n\n\n\n\n\nhttps://www.religious-symbols.net/\n\n\n\n\n\n\nhttps://www.vecteezy.com/free-vector/symbols"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#communication-between-minds",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#communication-between-minds",
    "title": "Semiotics of data visualization",
    "section": "Communication between minds",
    "text": "Communication between minds\n\nVia signs and symbols\nBased on shared social conventions\nAbout sign relations (what signs “mean” or convey)\nOpen vs. closed symbol systems"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#sign-systems-can-uniteinform-or-divideconfuse",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#sign-systems-can-uniteinform-or-divideconfuse",
    "title": "Semiotics of data visualization",
    "section": "Sign systems can unite/inform or divide/confuse",
    "text": "Sign systems can unite/inform or divide/confuse\n\nSteiner (1998)"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#sign-system-grammars",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#sign-system-grammars",
    "title": "Semiotics of data visualization",
    "section": "Sign system grammars",
    "text": "Sign system grammars\n\n\n\n\\(2+2*3=4\\) vs. \\(2+(2*3)=4\\)\n“Up with you I will not put.” vs. “I will not put up with you.”"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#grammar-of-graphics",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#grammar-of-graphics",
    "title": "Semiotics of data visualization",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n\n\n\n\n\nWilkinson, Wills, Rope, Norton, & Dubbs (2005)\n\n\n\n\n\n\nWickham, Navarro, & Pedersen (n.d.)"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#how-scientists-communicate-formally",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#how-scientists-communicate-formally",
    "title": "Semiotics of data visualization",
    "section": "How scientists communicate (formally)",
    "text": "How scientists communicate (formally)\n\nPapers\nPosters\nTextbooks\nWebsites\nTalks"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#components-of-a-scientific-papers",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#components-of-a-scientific-papers",
    "title": "Semiotics of data visualization",
    "section": "Components of a scientific papers",
    "text": "Components of a scientific papers\n\nText\n\nExplanation/argument\nEvidence (statistical summaries)\n\nFigures\nTables\n\nEvidence (statistical summaries)\n\nReferences\nData, materials"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#questions-about-scientific-communication",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#questions-about-scientific-communication",
    "title": "Semiotics of data visualization",
    "section": "Questions about scientific communication",
    "text": "Questions about scientific communication\n\nWhat do the words mean?\nWhat do the numbers/statistics mean?\nWhat do the figures mean?\nDoes the evidence (+ argument) persuade?"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#semioticssemiology-of-graphics",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#semioticssemiology-of-graphics",
    "title": "Semiotics of data visualization",
    "section": "Semiotics/Semiology of Graphics",
    "text": "Semiotics/Semiology of Graphics\n\nBertin (2010)"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#semiotics-of-data-visualization-1",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#semiotics-of-data-visualization-1",
    "title": "Semiotics of data visualization",
    "section": "Semiotics of data visualization",
    "text": "Semiotics of data visualization\n\nWhat do the components mean?\nWhat message is the visualization creator trying to convey?"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#semiotics-of-data-visualization-2",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#semiotics-of-data-visualization-2",
    "title": "Semiotics of data visualization",
    "section": "Semiotics of data visualization",
    "text": "Semiotics of data visualization\n\nSemiotics: study of signs and symbols\nWhat meanings do the visual elements of data graphics convey?\nHow do data visualizations relate to other communicative elements?"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#visualization-in-psychological-science-1",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#visualization-in-psychological-science-1",
    "title": "Semiotics of data visualization",
    "section": "Visualization in psychological science",
    "text": "Visualization in psychological science\n\nConventions (common patterns) in data visualization\nDifferent viz types for different psychological measures?"
  },
  {
    "objectID": "slides/wk01-2025-01-16-semiotics-data-viz.html#references",
    "href": "slides/wk01-2025-01-16-semiotics-data-viz.html#references",
    "title": "Semiotics of data visualization",
    "section": "References",
    "text": "References\n\n\n\n\nBertin, J. (2010). Semiology of graphics: Diagrams, networks, maps. Redlands, CA: ESRI Press.\n\n\nDenton, C. A., Asphaug, E., Emsenhuber, A., & Melikyan, R. (2025). Capture of an ancient charon around pluto. Nature Geoscience, 18, 37–43. https://doi.org/10.1038/s41561-024-01612-0\n\n\nFont style interpolation with diffusion models. (n.d.). Retrieved January 10, 2025, from https://arxiv.org/html/2402.14311v1\n\n\nKirsch, A. (2021, March 18). The symbolic animal. Retrieved January 10, 2025, from https://www.nybooks.com/articles/2021/04/08/ernst-cassirer-symbolic-animal/\n\n\nSpence, I., & Wainer, H. (2017). William Playfair and the invention of statistical graphs. In Information design (1st Edition, pp. 59–76). Routledge. https://doi.org/10.4324/9781315585680-10\n\n\nSteiner, G. (1998). After babel: Aspects of language and translation (3rd ed.). London, England: Oxford University Press. Retrieved from https://www.amazon.com/After-Babel-Aspects-Language-Translation/dp/0192880934\n\n\nThe Editors of Encyclopedia Britannica. (2024, December 19). Semiotics. In Encyclopedia britannica. Retrieved from https://www.britannica.com/science/semiotics\n\n\nWickham, H., Navarro, D., & Pedersen, T. L. (n.d.). ggplot2: Elegant graphics for data analysis (3e). Retrieved January 12, 2025, from https://ggplot2-book.org/\n\n\nWilkinson, L., Wills, D., Rope, D., Norton, A., & Dubbs, R. (2005). The grammar of graphics (statistics and computing) (2nd edition). Springer. Retrieved from https://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448"
  },
  {
    "objectID": "surveys/survey-01.html",
    "href": "surveys/survey-01.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "surveys/survey-01.html#about",
    "href": "surveys/survey-01.html#about",
    "title": "",
    "section": "About",
    "text": "About\nThis page summarizes work related to Survey-01.\n\nLoading…"
  },
  {
    "objectID": "surveys/survey-01.html#gathering",
    "href": "surveys/survey-01.html#gathering",
    "title": "",
    "section": "Gathering",
    "text": "Gathering"
  },
  {
    "objectID": "surveys/survey-01.html#cleaning",
    "href": "surveys/survey-01.html#cleaning",
    "title": "",
    "section": "Cleaning",
    "text": "Cleaning"
  },
  {
    "objectID": "surveys/survey-01.html#visualizing",
    "href": "surveys/survey-01.html#visualizing",
    "title": "",
    "section": "Visualizing",
    "text": "Visualizing"
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-psu.html",
    "href": "tutorials/tutorial-rstudio-on-psu.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-psu.html#about",
    "href": "tutorials/tutorial-rstudio-on-psu.html#about",
    "title": "",
    "section": "About",
    "text": "About\nThis page provides help starting and using RStudio from a Penn State computer lab machine. For instructions on how to install this free progam on your own personal computer, see the accompanying tutorial."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-psu.html#what-is-rstudio",
    "href": "tutorials/tutorial-rstudio-on-psu.html#what-is-rstudio",
    "title": "",
    "section": "1.1 What is RStudio?",
    "text": "1.1 What is RStudio?\nRStudio is an integrated development environment (IDE) for doing data science. An IDE is a computer program that provides tools for people who are developing and testing software. You might not think of yourself as a software developer (yet). But RStudio is a powerful tool for beginners, too. It began life as a tool primarily for users writing code in R, hence the name. RStudio supports multiple programming languages, including R and Python."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html",
    "href": "tutorials/tutorial-r-ggplot.html",
    "title": "Plotting with ggplot2",
    "section": "",
    "text": "This section describes some ways to generate plots using the R package ggplot2."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#about",
    "href": "tutorials/tutorial-r-ggplot.html#about",
    "title": "Plotting with ggplot2",
    "section": "",
    "text": "This section describes some ways to generate plots using the R package ggplot2."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#why-r",
    "href": "tutorials/tutorial-r-ggplot.html#why-r",
    "title": "Plotting with ggplot2",
    "section": "Why R",
    "text": "Why R\nR is a programming language specialized for data analysis and visualization."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#background",
    "href": "tutorials/tutorial-r-ggplot.html#background",
    "title": "Plotting with ggplot2",
    "section": "Background",
    "text": "Background\n‘ggplot2’ is a package1 for making 2D plots in R. It implements a special “language” for making plots based on the grammar of graphics suggested by Cleveland CITE. That’s where the ‘gg’ in the name comes from.\nIn ggplot, we create a base plot, then add layers to it using a plus sign + operator."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#set-up",
    "href": "tutorials/tutorial-r-ggplot.html#set-up",
    "title": "Plotting with ggplot2",
    "section": "Set-up",
    "text": "Set-up\nTo check whether {ggplot2} is already installed, run the following chunk:\n\n\nCode\n# The require() function returns TRUE if ggplot2 is installed and FALSE if it is not. The exclamation point symbol ('!') turns FALSE into TRUE and TRUE into FALSE. So, `!require(ggplot2)` will be TRUE if require(ggplot2) is FALSE. When this occurs, the `install.packages(ggplot)` commands runs and installs ggplot2.\nif (!require(ggplot2)) {\n  install.packages(ggplot2)\n}\n\n\nLoading required package: ggplot2"
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#plotting-one-variable",
    "href": "tutorials/tutorial-r-ggplot.html#plotting-one-variable",
    "title": "Plotting with ggplot2",
    "section": "Plotting one variable",
    "text": "Plotting one variable\n\nDiscrete/nominal\nFirst, we make some data.\n\n\nCode\ndata_random_discrete &lt;- data.frame(category = c('ab', 'xy', 'mn', \n                                                'qp', 'ea', 'f2',\n                                                'gg', 'h*'),\n                                   value = c(4.8, 5.5, 3.5, \n                                           4.6, 6.5, 6.6, \n                                           2.6, 3.0))\n\n\n\nBarplot\nIf the variable we want to plot contains the values we care about plotting, then we use geom_col. A column plot is just a type of barplot.\n\n\nCode\ndata_random_discrete |&gt;\n  ggplot() +\n  aes(x = category, y = value) +\n  geom_col()\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nHere, we have a categorical variable imaginatively named category and a continuous variable named value.\n\n\n\n\n\n\nYour turn\n\n\n\n\nWhat would we need to do to make the category variable ordinal?\nWhy do we think that value is continuous?\n\n\n\n\n\n\nContinuous\nFirst, let’s generate some random data.\n\n\nCode\n# Set a seed for our 'random' number generator\nset.seed(19680801)\nn_values &lt;- 100000\n\ndata_random_norm &lt;- data.frame(val = rnorm(n = n_values, mean = 0, sd = 1))\n\n\n\nHistogram\n\n\nCode\nhist_1 &lt;- data_random_norm |&gt;\n  ggplot() +\n  aes(x = val) +\n  geom_histogram()\n\n\nWhat the code is saying is this: Send data_random_norm to ggplot; make the plot and its various layers; then give the plot a name (hist_1) so we can use it later. Like now, for instance:\n\n\nCode\nhist_1\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 2: A simple histogram\n\n\n\n\n\nTo replicate the side-by-side histograms in ?@fig-dual-histograms-matplotlib, we do the following:\nMake two random data sets that differ slightly.\n\n\nCode\nx1 &lt;- rnorm(n = n_values, mean = 0, sd = 1)\ndata_random_norm_2 &lt;- data.frame(side = c(rep('l', n_values), rep('r', n_values)),\n                            val = c(x1,\n                                    0.4 * x1 + 5))\n\n\nThen plot the data.\n\n\nCode\nhist_2 &lt;- data_random_norm_2 |&gt;\n  ggplot() +\n  aes(x = val) +\n  geom_histogram() +\n  facet_wrap(vars(side), ncol = 2)\n\nhist_2\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 3: Side-by-side histograms of two random (normal) sets of data.\n\n\n\n\n\n\n\nViolin\n\n\nCode\nviolin_2 &lt;- data_random_norm_2 |&gt;\n  ggplot() +\n  aes(x = side, y = val) +\n  geom_violin()\n\nviolin_2\n\n\n\n\n\n\n\n\nFigure 4: Side-by-side violin plots of two random (normal) sets of data.\n\n\n\n\n\n\n\nBoxplot\n\n\nCode\nboxplot_2 &lt;- data_random_norm_2 |&gt;\n  ggplot() +\n  aes(x = side, y = val) +\n  geom_boxplot()\n\nboxplot_2\n\n\n\n\n\n\n\n\nFigure 5: Side-by-side violin plots of two random (normal) sets of data."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#comparing-distributions",
    "href": "tutorials/tutorial-r-ggplot.html#comparing-distributions",
    "title": "Plotting with ggplot2",
    "section": "Comparing distributions",
    "text": "Comparing distributions\nLet’s see how these plots can help us see when the distributions differ by more than just magnitude or standard deviation.\n\n\nCode\n# Normal \"bell\"-shaped like before\nx_norm &lt;- rnorm(n = n_values, mean = 0, sd = 1)\n\n# Uniform-shaped\nx_unif &lt;- runif(n = n_values, min = -2.75, max = 2.75)\n\ndata_random_2 &lt;- data.frame(side = c(rep('norm', n_values), rep('unif', n_values)),\n                            val = c(x_norm, x_unif))\n\n\n\n\nCode\nhist_2_diff &lt;- data_random_2 |&gt;\n  ggplot() +\n  aes(x = val) +\n  geom_histogram() +\n  facet_wrap(vars(side), ncol = 2)\n\nhist_2_diff\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 6: Side-by-side histograms of two random sets of data with different distributions.\n\n\n\n\n\n\n\nCode\nviolin_2_diff &lt;- data_random_2 |&gt;\n  ggplot() +\n  aes(x = side, y = val) +\n  geom_violin()\n\nviolin_2_diff\n\n\n\n\n\n\n\n\nFigure 7: Side-by-side violin plots of two random sets of data with different distributions.\n\n\n\n\n\n\n\nCode\nboxplot_2_diff &lt;- data_random_2 |&gt;\n  ggplot() +\n  aes(x = side, y = val) +\n  geom_boxplot()\n\nboxplot_2_diff\n\n\n\n\n\n\n\n\nFigure 8: Side-by-side box plots of two random sets of data with different distributions."
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#plotting-two-variables",
    "href": "tutorials/tutorial-r-ggplot.html#plotting-two-variables",
    "title": "Plotting with ggplot2",
    "section": "Plotting two variables",
    "text": "Plotting two variables\n\n\n\n\n\n\nWarning\n\n\n\nThis page is under construction. Many components are missing.\n\n\n\nScatterplot\nA scatterplot is a great way to compare two continuous variables.\n\n\nCode\nscatter_data &lt;- tibble::tibble(norm = x_norm,\n                               unif = x_unif)\n\nscatter_data |&gt;\n  ggplot() +\n  aes(x = x_norm, y = x_unif) +\n  geom_point()"
  },
  {
    "objectID": "tutorials/tutorial-r-ggplot.html#footnotes",
    "href": "tutorials/tutorial-r-ggplot.html#footnotes",
    "title": "Plotting with ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA collection of special commands for doing specific things.↩︎"
  },
  {
    "objectID": "tutorials/tutorial-making-data.html",
    "href": "tutorials/tutorial-making-data.html",
    "title": "Making and visualizing data",
    "section": "",
    "text": "This tutorial shows how we can construct data of different types.\nThe material serves as a companion to the classes on making data, figure types, and figure components.\n\n\nCode\n# Load required package dependencies \"quietly\"\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(ggmosaic))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(ggpattern))\nsuppressPackageStartupMessages(library(fillpattern))"
  },
  {
    "objectID": "tutorials/tutorial-making-data.html#about",
    "href": "tutorials/tutorial-making-data.html#about",
    "title": "Making and visualizing data",
    "section": "",
    "text": "This tutorial shows how we can construct data of different types.\nThe material serves as a companion to the classes on making data, figure types, and figure components.\n\n\nCode\n# Load required package dependencies \"quietly\"\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(ggmosaic))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(ggpattern))\nsuppressPackageStartupMessages(library(fillpattern))"
  },
  {
    "objectID": "tutorials/tutorial-making-data.html#nominal-data",
    "href": "tutorials/tutorial-making-data.html#nominal-data",
    "title": "Making and visualizing data",
    "section": "Nominal data",
    "text": "Nominal data\nLet’s focus on nominal or categorical data, specifically the favorite colors of some imaginary set of people.\n\n\nCode\n# Make an array of color names\ncolors &lt;- c(\"red\", \"orange\", \"yellow\", \"green\", \"cyan\", \"blue\", \"violet\", \"white\", \"black\", \"gray\")\n\n\nThere are n=10 colors in this set.\n\n\n\n\n\n\nYour turn\n\n\n\nWhy are these data nominal or nominally scaled? Or rather, why aren’t they ordinal, interval, or ratio?\n\n\n\nGenerating\nFor demonstration purposes, we want to take some number of random samples of these colors. Let’s pick n=200 and sample with replacement (replace=TRUE in the code below), meaning that we could have any number of colors in our sample of 200 imaginary people.\n\n\nCode\n# Use `sample()` to pick a random sample of these *with* replacement so that \n# the numbers/color differ.\nour_color_sample &lt;- sample(colors, size=200, replace=TRUE)\nour_color_sample\n\n\n  [1] \"black\"  \"yellow\" \"blue\"   \"green\"  \"gray\"   \"black\"  \"yellow\" \"yellow\"\n  [9] \"violet\" \"orange\" \"blue\"   \"black\"  \"red\"    \"black\"  \"cyan\"   \"white\" \n [17] \"cyan\"   \"green\"  \"violet\" \"blue\"   \"white\"  \"orange\" \"green\"  \"orange\"\n [25] \"gray\"   \"orange\" \"black\"  \"red\"    \"black\"  \"black\"  \"yellow\" \"black\" \n [33] \"blue\"   \"violet\" \"yellow\" \"black\"  \"black\"  \"black\"  \"black\"  \"red\"   \n [41] \"orange\" \"black\"  \"violet\" \"blue\"   \"cyan\"   \"black\"  \"green\"  \"red\"   \n [49] \"blue\"   \"red\"    \"white\"  \"red\"    \"white\"  \"cyan\"   \"green\"  \"orange\"\n [57] \"orange\" \"blue\"   \"white\"  \"blue\"   \"orange\" \"green\"  \"red\"    \"red\"   \n [65] \"orange\" \"black\"  \"green\"  \"yellow\" \"white\"  \"gray\"   \"red\"    \"red\"   \n [73] \"orange\" \"red\"    \"green\"  \"violet\" \"yellow\" \"green\"  \"gray\"   \"black\" \n [81] \"green\"  \"cyan\"   \"violet\" \"cyan\"   \"blue\"   \"cyan\"   \"cyan\"   \"violet\"\n [89] \"white\"  \"blue\"   \"white\"  \"black\"  \"orange\" \"gray\"   \"green\"  \"cyan\"  \n [97] \"violet\" \"violet\" \"blue\"   \"orange\" \"yellow\" \"red\"    \"blue\"   \"cyan\"  \n[105] \"red\"    \"gray\"   \"white\"  \"white\"  \"white\"  \"blue\"   \"white\"  \"cyan\"  \n[113] \"blue\"   \"violet\" \"black\"  \"red\"    \"yellow\" \"green\"  \"orange\" \"yellow\"\n[121] \"cyan\"   \"gray\"   \"blue\"   \"blue\"   \"gray\"   \"cyan\"   \"cyan\"   \"orange\"\n[129] \"gray\"   \"orange\" \"gray\"   \"gray\"   \"violet\" \"red\"    \"orange\" \"red\"   \n[137] \"green\"  \"red\"    \"green\"  \"orange\" \"cyan\"   \"white\"  \"gray\"   \"violet\"\n[145] \"red\"    \"green\"  \"violet\" \"green\"  \"blue\"   \"white\"  \"violet\" \"black\" \n[153] \"red\"    \"orange\" \"white\"  \"white\"  \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"  \n[161] \"violet\" \"blue\"   \"yellow\" \"gray\"   \"gray\"   \"white\"  \"yellow\" \"yellow\"\n[169] \"gray\"   \"black\"  \"gray\"   \"blue\"   \"black\"  \"white\"  \"white\"  \"black\" \n[177] \"yellow\" \"violet\" \"white\"  \"gray\"   \"green\"  \"orange\" \"blue\"   \"orange\"\n[185] \"green\"  \"cyan\"   \"orange\" \"cyan\"   \"cyan\"   \"red\"    \"white\"  \"black\" \n[193] \"violet\" \"violet\" \"gray\"   \"gray\"   \"cyan\"   \"blue\"   \"yellow\" \"orange\"\n\n\nOn its own, that’s not especially easy to visualize. What if we sorted it?\n\n\nCode\nsort(our_color_sample)\n\n\n  [1] \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\" \n  [9] \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\" \n [17] \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"black\"  \"blue\"  \n [25] \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"  \n [33] \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"blue\"  \n [41] \"blue\"   \"blue\"   \"blue\"   \"blue\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"  \n [49] \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"  \n [57] \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"   \"cyan\"  \n [65] \"cyan\"   \"cyan\"   \"cyan\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"  \n [73] \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"  \n [81] \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"gray\"   \"green\"  \"green\" \n [89] \"green\"  \"green\"  \"green\"  \"green\"  \"green\"  \"green\"  \"green\"  \"green\" \n [97] \"green\"  \"green\"  \"green\"  \"green\"  \"green\"  \"green\"  \"green\"  \"green\" \n[105] \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\"\n[113] \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\"\n[121] \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"orange\" \"red\"    \"red\"   \n[129] \"red\"    \"red\"    \"red\"    \"red\"    \"red\"    \"red\"    \"red\"    \"red\"   \n[137] \"red\"    \"red\"    \"red\"    \"red\"    \"red\"    \"red\"    \"red\"    \"red\"   \n[145] \"red\"    \"red\"    \"violet\" \"violet\" \"violet\" \"violet\" \"violet\" \"violet\"\n[153] \"violet\" \"violet\" \"violet\" \"violet\" \"violet\" \"violet\" \"violet\" \"violet\"\n[161] \"violet\" \"violet\" \"violet\" \"violet\" \"white\"  \"white\"  \"white\"  \"white\" \n[169] \"white\"  \"white\"  \"white\"  \"white\"  \"white\"  \"white\"  \"white\"  \"white\" \n[177] \"white\"  \"white\"  \"white\"  \"white\"  \"white\"  \"white\"  \"white\"  \"white\" \n[185] \"white\"  \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\"\n[193] \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\" \"yellow\"\n\n\nStill not all that helpful.\n\n\nSummarizing\nWhat can we say to summarize categorical data?\nWe can report the number of total responses.\n\n\nCode\nlength(our_color_sample)\n\n\n[1] 200\n\n\nWe can report the number of unique categories.\n\n\nCode\nlength(unique(our_color_sample))\n\n\n[1] 10\n\n\nWe can report the number of responses per category.\n\n\nCode\ncolors_df &lt;- data.frame(favorite_color = our_color_sample)\n\nxtabs(formula = ~favorite_color, data = colors_df)\n\n\nfavorite_color\n black   blue   cyan   gray  green orange    red violet  white yellow \n    23     21     23     19     18     22     20     18     21     15 \n\n\n\n\nVisualizing\nSingle nominal variables don’t offer us many options for visualization. A bar plot showing the number of observations in each category seems to be it.\n\n\nCode\ncolors_df |&gt;\n  ggplot() +\n  aes(x = favorite_color) +\n  geom_bar(stat = \"count\")\n\n\n\n\n\n\n\n\nFigure 1: A black and white barplot of the random favorite color data\n\n\n\n\n\nWe can also add colors to the bars.\n\n\nCode\ncolors_df |&gt;\n  ggplot() +\n  aes(x = favorite_color, fill = favorite_color) +\n  geom_bar() +\n  scale_discrete_manual(aesthetics = c(\"color\", \"fill\"),\n                        values = sort(colors))\n\n\n\n\n\n\n\n\nFigure 2: A colorful barplot of the random favorite color data\n\n\n\n\n\nWe can think of this as mapping the name of the color category in our data to the way that category is represented in our figure.\nWe can flip the axis just for fun. Which is more readable?\n\nHorizontal barplot\n\n\nCode\ncolors_df |&gt;\n  ggplot() +\n  aes(x = favorite_color, fill = favorite_color) +\n  scale_fill_identity() +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\nFigure 3: A colorful horizontal barplot of the random favorite color data\n\n\n\n\n\n\n\nBar/column with textures\nSometimes we don’t want to use color to distinguish nominal categories.\n\n\nCode\ncolors_df |&gt;\n  ggplot() +\n  aes(x = favorite_color, fill = favorite_color) +\n  geom_bar(aes(y = after_stat(count))) +\n  scale_fill_pattern() + # from package 'fillpattern' \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 4: A barplot of the random favorite color data using textures\n\n\n\n\n\nOr, we want to use some different textures and have control over them.\n\n\nCode\ncolors_xtab &lt;- data.frame(table(colors_df))\nnames(colors_xtab) &lt;- c(\"favorite_color\", \"count\")\n\ncolors_xtab |&gt;\n  ggplot() +\n  aes(x = favorite_color, y = count) +\n  # From package 'ggpattern'\n  # See https://r-graph-gallery.com/368-black-and-white-barchart.html\n  geom_col_pattern(\n    aes(\n      pattern = favorite_color,\n      pattern_angle = favorite_color,\n      pattern_spacing = favorite_color\n    ),\n    fill = 'white',\n    color = 'black',\n    pattern_density = 0.5,\n    pattern_fill = 'black',\n    pattern_color = 'darkgrey'\n  )\n\n\n\n\n\n\n\n\nFigure 5: A barplot of the random favorite color data using textures\n\n\n\n\n\n\n\nOrdered\nIt can be useful to sort the counts of nominal variables to faciliate comparisons among categories.\n\n\nCode\ncolors_df |&gt;\n  count(favorite_color) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(favorite_color = factor(favorite_color, levels = favorite_color)) |&gt;\n  ggplot() +\n  aes(x = favorite_color) +\n  geom_bar(aes(y = n), stat = \"identity\")\n\n\n\n\n\n\n\n\nFigure 6: A horizontal barplot of the random favorite color data, sorted\n\n\n\n\n\nLet’s order the other ones while we’re at it.\n\n\nCode\ncolors_df |&gt;\n  count(favorite_color) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(favorite_color = factor(favorite_color, levels = favorite_color)) |&gt;\n  ggplot() +\n  aes(x = favorite_color, y = n, fill = favorite_color) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_pattern() + # from package 'fillpattern'\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\nFigure 7: A barplot of the random favorite color data using textures\n\n\n\n\n\n\n\nCode\ncolors_df |&gt;\n  count(favorite_color) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(favorite_color = factor(favorite_color, levels = favorite_color)) |&gt;\n  ggplot() +\n  aes(x = favorite_color, y = n) +\n  # From package 'ggpattern'\n  # See https://r-graph-gallery.com/368-black-and-white-barchart.html\n  geom_col_pattern(\n    aes(\n      pattern = favorite_color,\n      pattern_angle = favorite_color,\n      pattern_spacing = favorite_color\n    ),\n    fill = 'white',\n    color = 'black',\n    pattern_density = 0.5,\n    pattern_fill = 'black',\n    pattern_color = 'darkgrey'\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 8: A barplot of the random favorite color data using textures\n\n\n\n\n\n\n\nLollipop chart\nThe lollipop chart uses less ink, so the ink/data ratio (Tufte, 2001) is higher than with barplots.\n\n\nCode\ncolors_df |&gt;\n  count(favorite_color) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(favorite_color = factor(favorite_color, levels = favorite_color)) |&gt;\n  ggplot() +\n    geom_point(aes(\n    x = favorite_color,\n    y = n,\n    color = favorite_color,\n    fill = favorite_color\n  )) +\n  geom_segment(aes(\n    x = favorite_color,\n    xend = favorite_color,\n    y = 0,\n    yend = n,\n    color = favorite_color\n  )) +\n  scale_color_identity() +\n  scale_fill_identity()\n\n\n\n\n\n\n\n\nFigure 9: A lollipop plot of the random favorite color data\n\n\n\n\n\n\n\nStacked barplot\nWe can also stack them.\n\n\nCode\ncolors_df |&gt;\n  count(favorite_color) |&gt;\n  ggplot() +\n  aes(x = \"\", y = n, fill = favorite_color) +\n  geom_col(position = \"stack\") +\n  scale_fill_identity() +\n  xlab(\"\")\n\n\n\n\n\n\n\n\nFigure 10: A stacked barplot of the random favorite color data\n\n\n\n\n\nThis makes more sense with another nominal variable in the mix.\nLet’s add a ‘school’ variable.\n\n\nCode\nschool &lt;- sample(c(\"psu\", \"osu\", \"mich\", \"usc\"), size=200, replace=TRUE)\ncolors_school_df &lt;- colors_df\ncolors_school_df$school &lt;- school\n\n\nThen create the plot.\n\n\nCode\ncolors_school_xtab &lt;- data.frame(table(colors_school_df))\nnames(colors_school_xtab) &lt;- c(\"favorite_color\", \"school\", \"count\")\n\n# colors_school_xtab |&gt;\n#   ggplot() +\n#   aes(x = school, y=count, fill = favorite_color) +\n#   scale_fill_identity() +\n#   geom_bar(stat=\"identity\", position=\"stack\")\n\ncolors_school_df |&gt; \n  count(school, favorite_color) |&gt; \n  ggplot() + \n  aes(school, n, fill = favorite_color) + \n  scale_fill_identity() + \n  geom_bar(stat=\"identity\", position=\"stack\")\n\n\n\n\n\n\n\n\nFigure 11: A stacked barplot of the random favorite color data\n\n\n\n\n\n\n\nStacked barplot alternative\n\n\nCode\ncolors_school_xtab |&gt;\n  ggplot() +\n  aes(x = favorite_color, y=count, fill = school) +\n  geom_bar(stat=\"identity\", position=\"stack\")\n\n\n\n\n\n\n\n\nFigure 12: Another stacked barplot of the random favorite color data.\n\n\n\n\n\n\n\nDodged barplot\nUsing the ‘dodge’ parameter is another way to show data with two categorical variables.\n\n\nCode\ncolors_school_xtab |&gt;\n  ggplot() +\n  aes(x = school, y=count, fill = favorite_color) +\n  scale_fill_identity() +\n  geom_bar(stat=\"identity\", position=\"dodge\")\n\n\n\n\n\n\n\n\nFigure 13: A horizontal barplot of the random favorite color data\n\n\n\n\n\n\n\nPie chart\n\n\nCode\ncolors_xtab &lt;- data.frame(table(colors_df))\nnames(colors_xtab) &lt;- c(\"favorite_color\", \"count\")\n\ncolors_xtab |&gt;\n  ggplot(aes(x = \"\", y = count, fill = favorite_color)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_identity()\n\n\n\n\n\n\n\n\nFigure 14: A piechart of the random favorite color data\n\n\n\n\n\n\n\nRing chart\n\n\nCode\n# https://r-graph-gallery.com/128-ring-or-donut-plot.html\n\n# Compute percentages\ncolors_xtab$fraction = colors_xtab$count / sum(colors_xtab$count)\n\n# Compute the cumulative percentages (top of each rectangle)\ncolors_xtab$ymax = cumsum(colors_xtab$fraction)\n\n# Compute the bottom of each rectangle\ncolors_xtab$ymin = c(0, head(colors_xtab$ymax, n = -1))\n\n# Make the plot\ncolors_xtab |&gt;\n  ggplot(aes(\n    ymax = ymax,\n    ymin = ymin,\n    xmax = 4,\n    xmin = 3,\n    fill = favorite_color\n  )) +\n  geom_rect() +\n  coord_polar(theta = \"y\") + # Try to remove that to understand how the chart is built initially\n  xlim(c(2, 4)) + # Try to remove that to see how to make a pie chart\n  scale_fill_identity()\n\n\n\n\n\n\n\n\nFigure 15: A ring/donut chart of the random favorite color data\n\n\n\n\n\n\n\nMosaic plot\n\n\nCode\nggplot(data = colors_school_df) +\n  geom_mosaic(aes(x = product(favorite_color, school), fill = favorite_color)) +   \n  labs(y=\"Favorite\", x=\"School\", title = \"Favorite colors by school\") +\n  scale_fill_identity()\n\n\nWarning: The `scale_name` argument of `continuous_scale()` is deprecated as of ggplot2\n3.5.0.\n\n\nWarning: The `trans` argument of `continuous_scale()` is deprecated as of ggplot2 3.5.0.\nℹ Please use the `transform` argument instead.\n\n\nWarning: `unite_()` was deprecated in tidyr 1.2.0.\nℹ Please use `unite()` instead.\nℹ The deprecated feature was likely used in the ggmosaic package.\n  Please report the issue at &lt;https://github.com/haleyjeppson/ggmosaic&gt;.\n\n\n\n\n\n\n\n\nFigure 16: A mosaic chart of the random favorite color by school data"
  },
  {
    "objectID": "tutorials/tutorial-making-data.html#ordinal-data",
    "href": "tutorials/tutorial-making-data.html#ordinal-data",
    "title": "Making and visualizing data",
    "section": "Ordinal data",
    "text": "Ordinal data\nWe usually consider colors as nominal or categorical variables. But the physical input to the visual system is continuous.\n\n\n\nhttps://rmit.pressbooks.pub/colourtheory1/part/2-colour-theory-the-visible-spectrum/\n\n\nThe continuous variable that underlies color is wavelength, a property of electromagnetic radiation. The human visual system maps patterns of physical wavelength to the psychological dimension of color.\nCuriously, human color perception shows that this psychological mapping wraps in a circular way that physical wavelength does not.\n\n\n\nhttps://pixabay.com/vectors/rainbow-colors-circle-color-spectrum-154569/\n\n\n\nGenerating\nBut rather than dive down that particular rat hole now, let’s make some ordinal data from the random color dataset. Imagine that we had n=50 participants and each gave a rating to these colors. The ratings had numbers, with 1 assigned to the participant’s first choice, and 4 assigned to the fourth choice. We won’t keep track of the specific users at this point.\n\n\nCode\nratings &lt;- c(\"1st\", \"2nd\", \"3rd\", \"4th\")\n\nour_rating_sample &lt;- sample(ratings, size=200, replace=TRUE)\ncolors_rating_df &lt;- colors_df\ncolors_rating_df$rating &lt;- our_rating_sample\n\ncolors_rating_xtab &lt;- data.frame(table(colors_rating_df))\nnames(colors_rating_xtab) &lt;- c(\"favorite_color\", \"rating\", \"count\")\n\n\n\n\nVisualizing\nMany of the same plot types are available for ordinal data.\n\nBar plot ordinal dodge\n\n\nCode\ncolors_rating_xtab |&gt;\n  ggplot() +\n  aes(x=rating, y=count, fill = favorite_color) +\n  # aes(x = favorite_color, y = school, fill = favorite_color) +\n  scale_fill_identity() +\n  geom_bar(stat=\"identity\", position=\"dodge\")\n\n\n\n\n\n\n\n\nFigure 17: A barplot of the random favorite color data with an ordinal rating\n\n\n\n\n\n\n\nBar plot ordinal stacked\n\n\nCode\n# colors_rating_xtab |&gt;\n#   ggplot() +\n#   aes(x=favorite_color, y=count, fill = favorite_color) +\n#   scale_fill_identity() +\n#   geom_bar(stat=\"identity\", position=\"dodge\")\n\ncolors_rating_xtab |&gt;\n  ggplot() +\n  aes(x = rating, y=count, fill = favorite_color) +\n  scale_fill_identity() +\n  geom_bar(stat=\"identity\", position=\"stack\")\n\n\n\n\n\n\n\n\nFigure 18: A stacked barplot of the random favorite color data with an ordinal rating\n\n\n\n\n\n\n\nBar plot ordinal stacked alternative\n\n\nCode\ncolors_rating_xtab |&gt;\n  ggplot() +\n  aes(x = favorite_color, y=count, fill = rating) +\n  geom_bar(stat=\"identity\", position=\"stack\")\n\n\n\n\n\n\n\n\nFigure 19: Another stacked barplot of the random favorite color data with an ordinal rating"
  },
  {
    "objectID": "tutorials/tutorial-making-data.html#continuous-data",
    "href": "tutorials/tutorial-making-data.html#continuous-data",
    "title": "Making and visualizing data",
    "section": "Continuous data",
    "text": "Continuous data\n\nGenerating\nLet’s imagine that we are studying a group of people who vary in age and body temperature.\nWe’ll assume that they are healthy–fever free.\nAnd we assume that we’re sampling uniformly across children (0-18 years) and adults (18-85).\n\n\nCode\nn_kids &lt;- 100\nn_adults &lt;- 100\nage_days_kids &lt;- runif(n_kids, 0, 18*365)\nage_days_adults &lt;- runif(n_adults, 18*365+1, 85*365)\n\n# https://www.webmd.com/first-aid/normal-body-temperature\nbody_temps_kids &lt;- runif(n_kids, 95.9, 99.5)\nbody_temps_adults &lt;- runif(n_adults, 97, 99)\n\nage_days &lt;- c(age_days_kids, age_days_adults)\nbody_temp_F &lt;- c(body_temps_kids, body_temps_adults)\n\nage_temp_df &lt;- data.frame(age_days = age_days, body_temp = body_temp_F)\n\n# Mix them up a bit\nage_temp_df &lt;- age_temp_df[sample(nrow(age_temp_df)),]\n\n\n\n\nVisualizing\nTo visualize continuous data, we have to decide what question(s) we want to answer.\n\nScatterplot\nThe simplest visualization of two continuous variables is a scatterplot.\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days, y = body_temp) +\n  geom_point()\n\n\n\n\n\n\n\n\nFigure 20: A scatterplot of the age and body temperature data.\n\n\n\n\n\n\n\nHistograms\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 21: A histogram of the age data.\n\n\n\n\n\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = body_temp) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 22: A histogram of the body temperature data.\n\n\n\n\n\n\n\nViolin plots\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days, y = \"\") +\n  geom_violin()\n\n\n\n\n\n\n\n\nFigure 23: A violin plot of the age data.\n\n\n\n\n\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(y = \"\", x = body_temp) +\n  geom_violin()\n\n\n\n\n\n\n\n\nFigure 24: A violin plot of the body temperature data.\n\n\n\n\n\n\n\nDensity\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days) +\n  geom_density()\n\n\n\n\n\n\n\n\nFigure 25: A density plot of the age data.\n\n\n\n\n\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = body_temp) +\n  geom_density()\n\n\n\n\n\n\n\n\nFigure 26: A density plot of the body temperature data.\n\n\n\n\n\n\n\nBoxplot\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nFigure 27: A boxplot of the age data.\n\n\n\n\n\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = body_temp) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nFigure 28: A boxplot of the body temperature data.\n\n\n\n\n\n\n\nViolin + Boxplot\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days, y = \"\") +\n  geom_violin() +\n  geom_boxplot(alpha = .4)\n\n\n\n\n\n\n\n\nFigure 29: A combined violin/boxplot of the age data.\n\n\n\n\n\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = body_temp, y = \"\") +\n  geom_violin() +\n  geom_boxplot(alpha = .4)\n\n\n\n\n\n\n\n\nFigure 30: A combined violin/boxplot of the body temperature data.\n\n\n\n\n\n\n\nViolin + Boxplot + Scatter\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = age_days, y = \"\") +\n  geom_violin() +\n  geom_boxplot(alpha = .4) +\n  geom_jitter(width = 0, height = .2)\n\n\n\n\n\n\n\n\nFigure 31: A combined violin/boxplot/scatterplot of the age data.\n\n\n\n\n\n\n\nCode\nage_temp_df |&gt;\n  ggplot() +\n  aes(x = body_temp, y = \"\") +\n  geom_violin() +\n  geom_boxplot(alpha = .4) +\n  geom_jitter(width = 0, height = .2)\n\n\n\n\n\n\n\n\nFigure 32: A combined violin/boxplot/scatterplot of the body temperature data."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Surveying the landscape\n\n\nCourse introduction\n\nSlides\nExercise 01 assigned\n\n\n\n\nThe semiotics of data visualization\n\nRead: Cairo (2013), Chapter 1-2, PDF on Canvas\nSlides"
  },
  {
    "objectID": "schedule.html#week-01",
    "href": "schedule.html#week-01",
    "title": "Schedule",
    "section": "",
    "text": "Surveying the landscape\n\n\nCourse introduction\n\nSlides\nExercise 01 assigned\n\n\n\n\nThe semiotics of data visualization\n\nRead: Cairo (2013), Chapter 1-2, PDF on Canvas\nSlides"
  },
  {
    "objectID": "schedule.html#week-02",
    "href": "schedule.html#week-02",
    "title": "Schedule",
    "section": "January 20-24",
    "text": "January 20-24\nWho visualizes data and why\n\nTuesday, January 21\nVisualization in government & business\n\nSlides\nResults from Exercise 01\n\n\n\nThursday, January 23\nVisualization in art, sports, and journalism\n\nRead (recommended): Gelman & Unwin (2013)\nSlides\nAssigned: Exercise 02\nDue: Exercise 01 | Canvas dropbox"
  },
  {
    "objectID": "schedule.html#week-03",
    "href": "schedule.html#week-03",
    "title": "Schedule",
    "section": "January 27-31",
    "text": "January 27-31\nUnderstanding figures\n\nTuesday, January 28\nMaking (sense of) data\n\nRead: Stevens (1946)\nOptional:\n\nWikipedia contributors (2024)\nTourangeau, Rips, & Rasinski (2012) | PDF on Canvas.\n\nSlides\nAssigned: Exercise-03\n\n\n\nThursday, January 30\nFigure types\n\nExplore (pick at least two):\n\nRibecca (n.d.)\nHammond (2024)\nDiscovery (2024)\nAtlassian (n.d.)\n\nWatch: Channel (2024)\nSlides\nDue: Exercise 02 | Canvas dropbox |"
  },
  {
    "objectID": "schedule.html#week-04",
    "href": "schedule.html#week-04",
    "title": "Schedule",
    "section": "February 3-7",
    "text": "February 3-7\n\nTuesday, February 04\nFigure components\n\nSlides\nReview: Making and visualizing data\n\n\n\nThursday, February 06\nCancelled due to weather"
  },
  {
    "objectID": "schedule.html#week-05",
    "href": "schedule.html#week-05",
    "title": "Schedule",
    "section": "February 10-14",
    "text": "February 10-14\n\nTuesday, February 11\nFrom stimulus to sensation\n\nRead: Cairo (2013), Chapter 5, PDF on Canvas\nSlides\nDue: Exercise-03 | Canvas dropbox |\n\n\n\nThursday, February 13\nFrom sensation to perception\n\nRead:\n\nCairo (2013), Chapter 6, PDF on Canvas\nFew (2004), Chapter 5, PDF on Canvas\n\nOptional:\n\nCleveland & McGill (1984)\n\nSlides"
  },
  {
    "objectID": "schedule.html#week-06",
    "href": "schedule.html#week-06",
    "title": "Schedule",
    "section": "February 17-21",
    "text": "February 17-21\n\nTuesday, February 18\nFrom cognition to understanding\n\nRead:\n\nFranconeri, Padilla, Shah, Zacks, & Hullman (2021), pp. 109-122, PDF on Canvas\nCairo (2013), Chapter 7, PDF on Canvas\n\nSlides\nAssigned: Final Project proposal\n\n\n\nThursday, February 20\nDesigning efficient & understandable visualizations\n\nRead: Franconeri et al. (2021), pp. 123-139, PDF on Canvas\nSlides\nAssigned: Exercise-04"
  },
  {
    "objectID": "schedule.html#week-07",
    "href": "schedule.html#week-07",
    "title": "Schedule",
    "section": "February 24-28",
    "text": "February 24-28\n\nTuesday, February 25\nCommunicating uncertainty and risk\n\nRead: Franconeri et al. (2021), pp. 139-150, PDF on Canvas\n\n\n\nThursday, February 27\nStorytelling with data\n\nRead:\n\nKnaflic (2015), pp. ix-33, PDF on Canvas\nKnaflic (2015), pp. 33-69, PDF on Canvas\n\nSkim: Woodside, Sood, & Miller (2008)"
  },
  {
    "objectID": "schedule.html#week-08",
    "href": "schedule.html#week-08",
    "title": "Schedule",
    "section": "March 3-7",
    "text": "March 3-7\n\nTuesday, March 04\nCritiquing figures\n\nRead:\n\nTufte (2001), Chapter 1, PDF on Canvas\nTufte (2001), Chapter 2, PDF on Canvas\n\n\n\n\nThursday, March 06\n\nExploring data\n\nRead: Tukey (1977), Chapter 1, PDF on Canvas\nDue: Exercise-04\nAssigned: Exercise-05\nDue: Final Project proposal"
  },
  {
    "objectID": "schedule.html#spring-break",
    "href": "schedule.html#spring-break",
    "title": "Schedule",
    "section": "March 10-14 Spring Break",
    "text": "March 10-14 Spring Break"
  },
  {
    "objectID": "schedule.html#week-09",
    "href": "schedule.html#week-09",
    "title": "Schedule",
    "section": "March 17-21",
    "text": "March 17-21\nIntroduction to R\n\nTuesday, March 18\nWhy R we doing this?\n\n\nThursday, March 20\nNO CLASS\n\nDue: Exercise-05"
  },
  {
    "objectID": "schedule.html#week-10",
    "href": "schedule.html#week-10",
    "title": "Schedule",
    "section": "March 24-28",
    "text": "March 24-28\nExploring data with R\n\nTuesday, March 25\nGathering & cleaning data\n\n\nThursday, March 27\nMaking plots with ggplot2\n\nAssigned: Exercise-06"
  },
  {
    "objectID": "schedule.html#week-11",
    "href": "schedule.html#week-11",
    "title": "Schedule",
    "section": "March 31 - April 4",
    "text": "March 31 - April 4\nIntroduction to Python\n\nTuesday, April 01\n\nAssigned: Final project preferences survey\n\n\n\nThursday, April 03\n\nDue: Exercise-06"
  },
  {
    "objectID": "schedule.html#week-12",
    "href": "schedule.html#week-12",
    "title": "Schedule",
    "section": "April 7-11",
    "text": "April 7-11\nExploring data with Python\n\nTuesday, April 08\n\nDue: Final project preferences survey\n\n\n\nThursday, April 10\n\nAssigned: Exercise-07"
  },
  {
    "objectID": "schedule.html#week-13",
    "href": "schedule.html#week-13",
    "title": "Schedule",
    "section": "April 14-18",
    "text": "April 14-18\nMaking plots with JavaScript\n\nTuesday, April 15\n\n\nThursday, April 17\n\nDue: Exercise-07"
  },
  {
    "objectID": "schedule.html#week-14",
    "href": "schedule.html#week-14",
    "title": "Schedule",
    "section": "April 21-25",
    "text": "April 21-25\nFinal Project Preparation\n\nTuesday, April 22\n\n\nThursday, April 24"
  },
  {
    "objectID": "schedule.html#week-15",
    "href": "schedule.html#week-15",
    "title": "Schedule",
    "section": "April 28 - May 2",
    "text": "April 28 - May 2\nFinal Project Presentations\n\nTuesday, April 29\n\nSchedule: TBD1\n\n\n\nThursday, May 01\n\nSchedule: TBD"
  },
  {
    "objectID": "schedule.html#finals-week",
    "href": "schedule.html#finals-week",
    "title": "Schedule",
    "section": "May 5-9",
    "text": "May 5-9\nFinals Week\n\nTuesday, May 05\n\nDue: Final project write-up"
  },
  {
    "objectID": "schedule.html#footnotes",
    "href": "schedule.html#footnotes",
    "title": "Schedule",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo be determined↩︎"
  },
  {
    "objectID": "policies.html",
    "href": "policies.html",
    "title": "Policies",
    "section": "",
    "text": "Students with questions about academic integrity should visit http://www.la.psu.edu/current-students/undergraduate-students/education/academic-integrity.\nPenn State defines academic integrity as the pursuit of scholarly activity in an open, honest and responsible manner. All students should act with personal integrity, respect others dignity, rights and property, and help create and maintain an environment in which all can succeed through the fruits of their efforts (Faculty Senate Policy 49-20). Sanctions for academic misconduct can include a grade of F for the course as well as other penalties.\nUnless you are told otherwise, you must complete all course work entirely on your own, using only sources that have been permitted by your instructor, and you may not assist other students with papers, quizzes, exams, or other assessments. If I allow you to use ideas, images, or word phrases created by another person (e.g., from Course Hero or Chegg) or by generative technology, such as ChatGPT, you must identify their source.\nWhen you complete assignments, remember the ABCs to avoid plagiarism: Always place copied information within quotation marks, include information about the quoted or paraphrased source in a Bibliography, and Cite the source in the body (in the text) of your paper immediately after the quoted or paraphrased information. When in doubt, cite in the text and include the source in a bibliography.\nStudents with questions about academic integrity should ask me or the TA before submitting work.\nStudents facing allegations of academic misconduct may not drop/withdraw from the affected course unless they are cleared of wrongdoing (see G-9: Academic Integrity). Attempted drops will be prevented or reversed, and students will be expected to complete course work and meet course deadlines. Students who are found responsible for academic integrity violations face academic outcomes, which can be severe, and put themselves at jeopardy for other outcomes which may include ineligibility for Dean’s List, pass/fail elections, and grade forgiveness. Students may also face consequences from their home/major program and/or The Schreyer Honors College."
  },
  {
    "objectID": "policies.html#values",
    "href": "policies.html#values",
    "title": "Policies",
    "section": "Values",
    "text": "Values\n\nPenn State Principles\nThe Pennsylvania State University is a community dedicated to personal and academic excellence. The Penn State Principles were developed to embody the values that we hope our students, faculty, staff, administration, and alumni possess. At the same time, the University is strongly committed to freedom of expression. Consequently, these Principles do not constitute University policy and are not intended to interfere in any way with an individual’s academic or personal freedoms. We hope, however, that individuals will voluntarily endorse these common principles, thereby contributing to the traditions and scholarly heritage left by those who preceded them, and will thus leave Penn State a better place for those who follow.\nI will respect the dignity of all individuals within the Penn State community. The University is committed to creating and maintaining an educational environment that respects the right of all individuals to participate fully in the community. Actions motivated by hate, prejudice, or intolerance violate this principle. I will not engage in any behaviors that compromise or demean the dignity of individuals or groups, including intimidation, stalking, harassment, discrimination, taunting, ridiculing, insulting, or acts of violence. I will demonstrate respect for others by striving to learn from differences between people, ideas, and opinions and by avoiding behaviors that inhibit the ability of other community members to feel safe or welcome as they pursue their academic goals.\nI will practice academic integrity. Academic integrity is a basic guiding principle for all academic activity at Penn State University, allowing the pursuit of scholarly activity in an open, honest, and responsible manner. In accordance with the University Code of Conduct, I will practice integrity in regard to all academic assignments. I will not engage in or tolerate acts of falsification, misrepresentation or deception because such acts of dishonesty violate the fundamental ethical principles of the University community and compromise the worth of work completed by others.\nI will demonstrate social and personal responsibility. The University is a community that promotes learning; any behaviors that are inconsistent with that goal are unacceptable. Irresponsible behaviors, including alcohol or drug abuse and the use of violence against people or property, undermine the educational climate by threatening the physical and mental health of members of the community. I will exercise personal responsibility for my actions and I will make sure that my actions do not interfere with the academic and social environment of the University. I will maintain a high standard of behavior by adhering to the Code of Conduct and respecting the rights of others.\nI will be responsible for my own academic progress and agree to comply with all University policies. The University allows students to identify and achieve their academic goals by providing the information needed to plan the chosen program of study and the necessary educational opportunities, but students assume final responsibility for course scheduling, program planning, and the successful completion of graduation requirements. I will be responsible for seeking the academic and career information needed to meet my educational goals by becoming knowledgeable about the relevant policies, procedures, and rules of the University and academic program, by consulting and meeting with my adviser, and by successfully completing all of the requirements for graduation.\n\n\nPenn State Values\nIntegrity: We act with integrity and honesty in accordance with the highest academic, professional, and ethical standards.\nRespect: We respect and honor the dignity of each person, embrace civil discourse, and foster a diverse and inclusive community.\nResponsibility: We act responsibly, and we are accountable for our decisions, actions, and their consequences.\nDiscovery: We seek and create new knowledge and understanding, and foster creativity and innovation, for the benefit of our communities, society, and the environment.\nExcellence: We strive for excellence in all our endeavors as individuals, an institution, and a leader in higher education.\nCommunity: We work together for the betterment of our University, the communities we serve, and the world."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYCH 490.001",
    "section": "",
    "text": "ChatGPT/Dall-E-3 model response to ‘an image of “a picture paints a thousand words”’ on 2024-09-19"
  },
  {
    "objectID": "index.html#themes",
    "href": "index.html#themes",
    "title": "PSYCH 490.001",
    "section": "Themes",
    "text": "Themes\nIf a picture’s worth a thousand words (Wikipedia contributors, 2024), what exactly does it say? This course will focus on the psychology of data visualization—how to read, critique, and generate meaningful figures that inform but don’t mislead. We’ll take inspiration from recognized classic figures and unpack what makes them exemplary. We’ll critique figures that deliberately or inadvertently mislead or confuse. We’ll learn what 150 years of vision science, the foundation of experimental psychology, has to say about data visualization. And we’ll learn how to build our own reproducible figures using Python, R, and JavaScript. No prior programming experience is required."
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "PSYCH 490.001",
    "section": "Instructor",
    "text": "Instructor\nRick O. Gilmore, Ph.D. \nProfessor of Psychology\nrog1 AT-SIGN psu PERIOD edu\n\nSchedule an appointment: https://doodle.com/mm/rickgilmore/book-a-time\nLab web site: https://gilmore-lab.github.io"
  },
  {
    "objectID": "index.html#teaching-assistant",
    "href": "index.html#teaching-assistant",
    "title": "PSYCH 490.001",
    "section": "Teaching Assistant",
    "text": "Teaching Assistant\nSara He\nGraduate Student in Social Psychology\ncfh5558 AT-SIGN psu PERIOD edu\nMeetings by appointment over Zoom"
  },
  {
    "objectID": "index.html#meeting-time-location",
    "href": "index.html#meeting-time-location",
    "title": "PSYCH 490.001",
    "section": "Meeting time & location",
    "text": "Meeting time & location\nTuesday & Thursday, 9:05-10:20 am\n009 Sparks Building"
  },
  {
    "objectID": "index.html#canvas-site",
    "href": "index.html#canvas-site",
    "title": "PSYCH 490.001",
    "section": "Canvas site",
    "text": "Canvas site\nWe will use Canvas to submit assignments and grade them. The Canvas site may be found here:\nhttps://psu.instructure.com/courses/2381584\nMost of the course content will be found on this site."
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "PSYCH 490.001",
    "section": "Course structure",
    "text": "Course structure\nThis is a discussion-focused course. On most days we will discuss readings assigned prior to class. On many days, we will work together or individually on the assigned exercises, the final project, or another assignment."
  },
  {
    "objectID": "deadlines.html",
    "href": "deadlines.html",
    "title": "Deadlines",
    "section": "",
    "text": "This page summarizes some of the key deadlines in the course.\n\n\n\nDate\nWhat’s due/happening\n\n\n\n\n2025-01-23\nExercise 01\n\n\n2025-01-30\nExercise 02\n\n\n2025-02-11\nExercise 03\n\n\n2025-03-04\nFinal project proposal due\n\n\n2025-03-06\nExercise 04\n\n\n2025-03-27\nExercise 05\n\n\n2025-04-03\nExercise 06\n\n\n2025-04-08\nFinal project survey\n\n\n2025-04-17\nExercise 07\n\n\n2025-05-05\nFinal project writeup due"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "about.html#instructor",
    "href": "about.html#instructor",
    "title": "",
    "section": "Instructor",
    "text": "Instructor\nRick O. Gilmore, Ph.D. \nProfessor of Psychology\nrog1 AT-SIGN psu PERIOD edu\n\nSchedule an appointment: https://doodle.com/mm/rickgilmore/book-a-time\nLab web site: https://gilmore-lab.github.io"
  },
  {
    "objectID": "about.html#teaching-assistant",
    "href": "about.html#teaching-assistant",
    "title": "",
    "section": "Teaching Assistant",
    "text": "Teaching Assistant\nSara He\nGraduate Student in Social Psychology\ncfh5558 AT-SIGN psu PERIOD edu\nMeetings by appointment over Zoom"
  },
  {
    "objectID": "about.html#meeting-time-location",
    "href": "about.html#meeting-time-location",
    "title": "",
    "section": "Meeting time & location",
    "text": "Meeting time & location\nTuesday & Thursday, 9:05-10:20 am\n009 Sparks Building"
  },
  {
    "objectID": "about.html#canvas-site",
    "href": "about.html#canvas-site",
    "title": "",
    "section": "Canvas site",
    "text": "Canvas site\nWe will use Canvas to submit assignments and grade them. The Canvas site may be found here:\nhttps://psu.instructure.com/courses/2381584\nMost of the course content will be found on this site."
  },
  {
    "objectID": "about.html#course-structure",
    "href": "about.html#course-structure",
    "title": "",
    "section": "Course structure",
    "text": "Course structure\nThis is a discussion-focused course. On most days we will discuss readings assigned prior to class. On many days, we will work together or individually on the assigned exercises, the final project, or another assignment."
  },
  {
    "objectID": "evaluation.html",
    "href": "evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "Component\nDescription\nPoints\n\n\n\n\nAttendance\nYou will receive 1 point for each class you attend up to a maximum of 25.\n25\n\n\nExercises\nThere will be seven (7) exercises that we will work on. Each exercise is worth 10 points. You are required to submit four (4) toward your final grade.\n40\n\n\nFinal project\nYou will complete a final project, either on your own, or with a small group of 3 or less. Your final project is worth 35 points.\n35\n\n\n\nTOTAL POINTS POSSIBLE\n100\n\n\nExtra Credit\nIf you submit more than four (4) exercise write-ups, you may earn up to 10 extra credit points for these exercises."
  },
  {
    "objectID": "evaluation.html#eval-components",
    "href": "evaluation.html#eval-components",
    "title": "Evaluation",
    "section": "",
    "text": "Component\nDescription\nPoints\n\n\n\n\nAttendance\nYou will receive 1 point for each class you attend up to a maximum of 25.\n25\n\n\nExercises\nThere will be seven (7) exercises that we will work on. Each exercise is worth 10 points. You are required to submit four (4) toward your final grade.\n40\n\n\nFinal project\nYou will complete a final project, either on your own, or with a small group of 3 or less. Your final project is worth 35 points.\n35\n\n\n\nTOTAL POINTS POSSIBLE\n100\n\n\nExtra Credit\nIf you submit more than four (4) exercise write-ups, you may earn up to 10 extra credit points for these exercises."
  },
  {
    "objectID": "evaluation.html#grading-scheme",
    "href": "evaluation.html#grading-scheme",
    "title": "Evaluation",
    "section": "Grading Scheme",
    "text": "Grading Scheme\n\n\n\nPercent\nPoints\nGrade\n\n\n\n\n94+\n94+\nA\n\n\n90-93\n90-93\nA-\n\n\n87-89\n87-89\nB+\n\n\n84-86\n84-86\nB\n\n\n80-83\n80-83\nB-\n\n\n77-79\n77-70\nC+\n\n\n70-76\n70-76\nC\n\n\n60-69\n60-69\nD\n\n\n&lt;59\n&lt;=59\nF"
  },
  {
    "objectID": "meta.html",
    "href": "meta.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "meta.html#about",
    "href": "meta.html#about",
    "title": "",
    "section": "About",
    "text": "About\nThis page describes how the site is created and rendered."
  },
  {
    "objectID": "meta.html#workflow",
    "href": "meta.html#workflow",
    "title": "",
    "section": "Workflow",
    "text": "Workflow\nThe site is written in Quarto.\nThe project root uses a src/ directory to store the source code.\nA site-wide YAML file (_quarto.yml) controls the rendering process.\nSeparate directories contain lecture slides (slides/), exercises (exercises/), class-specific R functions (R/), surveys (surveys/), and tutorials (tutorials/). Quarto files with underscores (e.g., _index.qmd, _about.qmd, _evaluation.qmd, _schedule.qmd, and values.qmd) are the main targets for editing and updating. Parent files (e.g., index.qmd, evaluation.qmd, policies.qmd, and schedule.qmd) call upon these child files in the rendering process.\nA separate Quarto file (psych-490.003-2025-spring-syllabus.qmd) generates a PDF version of a syllabus."
  },
  {
    "objectID": "meta.html#rendering",
    "href": "meta.html#rendering",
    "title": "",
    "section": "Rendering",
    "text": "Rendering\nTo render the full site, quarto render src is executed from the command line. The fully rendered website is written to docs/."
  },
  {
    "objectID": "meta.html#software",
    "href": "meta.html#software",
    "title": "",
    "section": "Software",
    "text": "Software\nThe site uses the renv package to try to make all computation reproducible.\nIn addition, the site uses softbib to generate a full reference list of the package dependencies. This is saved in src/include/bib."
  },
  {
    "objectID": "values.html",
    "href": "values.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "values.html#values",
    "href": "values.html#values",
    "title": "",
    "section": "Values",
    "text": "Values\n\nPenn State Principles\nThe Pennsylvania State University is a community dedicated to personal and academic excellence. The Penn State Principles were developed to embody the values that we hope our students, faculty, staff, administration, and alumni possess. At the same time, the University is strongly committed to freedom of expression. Consequently, these Principles do not constitute University policy and are not intended to interfere in any way with an individual’s academic or personal freedoms. We hope, however, that individuals will voluntarily endorse these common principles, thereby contributing to the traditions and scholarly heritage left by those who preceded them, and will thus leave Penn State a better place for those who follow.\nI will respect the dignity of all individuals within the Penn State community. The University is committed to creating and maintaining an educational environment that respects the right of all individuals to participate fully in the community. Actions motivated by hate, prejudice, or intolerance violate this principle. I will not engage in any behaviors that compromise or demean the dignity of individuals or groups, including intimidation, stalking, harassment, discrimination, taunting, ridiculing, insulting, or acts of violence. I will demonstrate respect for others by striving to learn from differences between people, ideas, and opinions and by avoiding behaviors that inhibit the ability of other community members to feel safe or welcome as they pursue their academic goals.\nI will practice academic integrity. Academic integrity is a basic guiding principle for all academic activity at Penn State University, allowing the pursuit of scholarly activity in an open, honest, and responsible manner. In accordance with the University Code of Conduct, I will practice integrity in regard to all academic assignments. I will not engage in or tolerate acts of falsification, misrepresentation or deception because such acts of dishonesty violate the fundamental ethical principles of the University community and compromise the worth of work completed by others.\nI will demonstrate social and personal responsibility. The University is a community that promotes learning; any behaviors that are inconsistent with that goal are unacceptable. Irresponsible behaviors, including alcohol or drug abuse and the use of violence against people or property, undermine the educational climate by threatening the physical and mental health of members of the community. I will exercise personal responsibility for my actions and I will make sure that my actions do not interfere with the academic and social environment of the University. I will maintain a high standard of behavior by adhering to the Code of Conduct and respecting the rights of others.\nI will be responsible for my own academic progress and agree to comply with all University policies. The University allows students to identify and achieve their academic goals by providing the information needed to plan the chosen program of study and the necessary educational opportunities, but students assume final responsibility for course scheduling, program planning, and the successful completion of graduation requirements. I will be responsible for seeking the academic and career information needed to meet my educational goals by becoming knowledgeable about the relevant policies, procedures, and rules of the University and academic program, by consulting and meeting with my adviser, and by successfully completing all of the requirements for graduation.\n\n\nPenn State Values\nIntegrity: We act with integrity and honesty in accordance with the highest academic, professional, and ethical standards.\nRespect: We respect and honor the dignity of each person, embrace civil discourse, and foster a diverse and inclusive community.\nResponsibility: We act responsibly, and we are accountable for our decisions, actions, and their consequences.\nDiscovery: We seek and create new knowledge and understanding, and foster creativity and innovation, for the benefit of our communities, society, and the environment.\nExcellence: We strive for excellence in all our endeavors as individuals, an institution, and a leader in higher education.\nCommunity: We work together for the betterment of our University, the communities we serve, and the world."
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html",
    "href": "tutorials/tutorial-python-matplotlib.html",
    "title": "Plotting in Python",
    "section": "",
    "text": "Note\n\n\n\nFigures don’t seem to be cross-referencing across documents. Let’s see if they work within documents.\nDoes the link to Figure 1 work?\nHow about Figure 2?\nApparently so.\nOkay, so do the ggplot2 figures work in this document? Specifically, does the reference to ?@fig-dual-boxplots-diff-ggplot2 work?\nNo. So, the issue is cross-document figure references."
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html#about",
    "href": "tutorials/tutorial-python-matplotlib.html#about",
    "title": "Plotting in Python",
    "section": "About",
    "text": "About\nThis page provides a very basic introduction to Python and the matplotlib plotting library."
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html#why-python",
    "href": "tutorials/tutorial-python-matplotlib.html#why-python",
    "title": "Plotting in Python",
    "section": "Why Python?",
    "text": "Why Python?\nPython is an awesome language for data science and data visualization. It is more popular than R, and it is widely used in scientific research and in industry.\nI find that it has a very readable syntax, meaning that it’s relatively easy to see what well-written Python code is doing."
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html#setup",
    "href": "tutorials/tutorial-python-matplotlib.html#setup",
    "title": "Plotting in Python",
    "section": "Setup",
    "text": "Setup\nWe start by importing the numpy and pyplot libraries and giving them convenient short names for future reference.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html#plotting-one-variable",
    "href": "tutorials/tutorial-python-matplotlib.html#plotting-one-variable",
    "title": "Plotting in Python",
    "section": "Plotting one variable",
    "text": "Plotting one variable\n\nContinuous\n\nHistograms\nFrom https://matplotlib.org/stable/gallery/statistics/hist.html#sphx-glr-gallery-statistics-hist-py\nLoad components from matplotlib.\n\n\nCode\nfrom matplotlib import colors\nfrom matplotlib.ticker import PercentFormatter\n\n# Create a random number generator with a fixed seed for reproducibility\nrng = np.random.default_rng(19680801)\n\n\nGenerate data and render it.\n\n\nCode\nN_points = 100000\nn_bins = 20\n\n# Generate two normal distributions\ndist1 = rng.standard_normal(N_points)\ndist2 = 0.4 * rng.standard_normal(N_points) + 5\n\nfig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n\n# We can set the number of bins with the *bins* keyword argument.\naxs[0].hist(dist1, bins=n_bins)\naxs[1].hist(dist2, bins=n_bins)\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Two histograms with 100K points each.\n\n\n\n\n\n\n\nViolin\nViolin plots are another way to depict the distribution of a single continuous variable.\nThe following code is copied verbatim from the following site:\nhttps://matplotlib.org/stable/gallery/statistics/violinplot.html\n\n\nCode\n# fake data\nfs = 10  # fontsize\npos = [1, 2, 4, 5, 7, 8]\ndata = [np.random.normal(0, std, size=100) for std in pos]\n\n# Create a plot with 2 rows and 6 columns\nfig, axs = plt.subplots(nrows=2, ncols=6, figsize=(10, 4))\n\naxs[0, 0].violinplot(data, pos, points=20, widths=0.3,\n                     showmeans=True, showextrema=True, showmedians=True)\naxs[0, 0].set_title('Custom violin 1', fontsize=fs)\n\naxs[0, 1].violinplot(data, pos, points=40, widths=0.5,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     bw_method='silverman')\naxs[0, 1].set_title('Custom violin 2', fontsize=fs)\n\naxs[0, 2].violinplot(data, pos, points=60, widths=0.7, showmeans=True,\n                     showextrema=True, showmedians=True, bw_method=0.5)\naxs[0, 2].set_title('Custom violin 3', fontsize=fs)\n\naxs[0, 3].violinplot(data, pos, points=60, widths=0.7, showmeans=True,\n                     showextrema=True, showmedians=True, bw_method=0.5,\n                     quantiles=[[0.1], [], [], [0.175, 0.954], [0.75], [0.25]])\naxs[0, 3].set_title('Custom violin 4', fontsize=fs)\n\naxs[0, 4].violinplot(data[-1:], pos[-1:], points=60, widths=0.7,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[0.05, 0.1, 0.8, 0.9], bw_method=0.5)\naxs[0, 4].set_title('Custom violin 5', fontsize=fs)\n\naxs[0, 5].violinplot(data[-1:], pos[-1:], points=60, widths=0.7,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[0.05, 0.1, 0.8, 0.9], bw_method=0.5, side='low')\n\naxs[0, 5].violinplot(data[-1:], pos[-1:], points=60, widths=0.7,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[0.05, 0.1, 0.8, 0.9], bw_method=0.5, side='high')\naxs[0, 5].set_title('Custom violin 6', fontsize=fs)\n\naxs[1, 0].violinplot(data, pos, points=80, vert=False, widths=0.7,\n                     showmeans=True, showextrema=True, showmedians=True)\naxs[1, 0].set_title('Custom violin 7', fontsize=fs)\n\naxs[1, 1].violinplot(data, pos, points=100, vert=False, widths=0.9,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     bw_method='silverman')\naxs[1, 1].set_title('Custom violin 8', fontsize=fs)\n\naxs[1, 2].violinplot(data, pos, points=200, vert=False, widths=1.1,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     bw_method=0.5)\naxs[1, 2].set_title('Custom violin 9', fontsize=fs)\n\naxs[1, 3].violinplot(data, pos, points=200, vert=False, widths=1.1,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[[0.1], [], [], [0.175, 0.954], [0.75], [0.25]],\n                     bw_method=0.5)\naxs[1, 3].set_title('Custom violin 10', fontsize=fs)\n\naxs[1, 4].violinplot(data[-1:], pos[-1:], points=200, vert=False, widths=1.1,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[0.05, 0.1, 0.8, 0.9], bw_method=0.5)\naxs[1, 4].set_title('Custom violin 11', fontsize=fs)\n\naxs[1, 5].violinplot(data[-1:], pos[-1:], points=200, vert=False, widths=1.1,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[0.05, 0.1, 0.8, 0.9], bw_method=0.5, side='low')\n\naxs[1, 5].violinplot(data[-1:], pos[-1:], points=200, vert=False, widths=1.1,\n                     showmeans=True, showextrema=True, showmedians=True,\n                     quantiles=[0.05, 0.1, 0.8, 0.9], bw_method=0.5, side='high')\naxs[1, 5].set_title('Custom violin 12', fontsize=fs)\n\n\nfor ax in axs.flat:\n    ax.set_yticklabels([])\n\nfig.suptitle(\"Violin Plotting Examples\")\nfig.subplots_adjust(hspace=0.4)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Multiple violin plots with different parameters.\n\n\n\n\n\n\n\nBoxplot\nFrom https://matplotlib.org/stable/plot_types/stats/boxplot_plot.html#sphx-glr-plot-types-stats-boxplot-plot-py.\n\n\nCode\nplt.style.use('_mpl-gallery')\n\n# make data:\nnp.random.seed(10)\nD = np.random.normal((3, 5, 4), (1.25, 1.00, 1.25), (100, 3))\n\n# plot\nfig, ax = plt.subplots()\nVP = ax.boxplot(D, positions=[2, 4, 6], widths=1.5, patch_artist=True,\n                showmeans=False, showfliers=False,\n                medianprops={\"color\": \"white\", \"linewidth\": 0.5},\n                boxprops={\"facecolor\": \"C0\", \"edgecolor\": \"white\",\n                          \"linewidth\": 0.5},\n                whiskerprops={\"color\": \"C0\", \"linewidth\": 1.5},\n                capprops={\"color\": \"C0\", \"linewidth\": 1.5})\n\nax.set(xlim=(0, 8), xticks=np.arange(1, 8),\n       ylim=(0, 8), yticks=np.arange(1, 8))\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: Example of several boxplots with whiskers.\n\n\n\n\n\n\n\n\nDiscrete/nominal\n\nBar chart\nSource: https://matplotlib.org/stable/plot_types/basic/bar.html#sphx-glr-plot-types-basic-bar-py\n\n\nCode\nplt.style.use('_mpl-gallery')\n\n# make data:\nx = 0.5 + np.arange(8)\ny = [4.8, 5.5, 3.5, 4.6, 6.5, 6.6, 2.6, 3.0]\n\n# plot\nfig, ax = plt.subplots()\n\nax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.7)\n\nax.set(xlim=(0, 8), xticks=np.arange(1, 8),\n       ylim=(0, 8), yticks=np.arange(1, 8))\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Example of a bar plot."
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html#plotting-two-variables",
    "href": "tutorials/tutorial-python-matplotlib.html#plotting-two-variables",
    "title": "Plotting in Python",
    "section": "Plotting two variables",
    "text": "Plotting two variables\n\nScatter plots"
  },
  {
    "objectID": "tutorials/tutorial-python-matplotlib.html#other-kinds-of-plots",
    "href": "tutorials/tutorial-python-matplotlib.html#other-kinds-of-plots",
    "title": "Plotting in Python",
    "section": "Other kinds of plots",
    "text": "Other kinds of plots\nThe following is copied verbatim from the Quarto website:\nhttps://quarto.org/docs/get-started/hello/vscode.html\nFor a demonstration of a line plot on a polar axis, see Figure 5.\n\n\nCode\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5: A line plot on a polar axis"
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html",
    "href": "tutorials/tutorial-rstudio-on-pc.html",
    "title": "Setting up RStudio",
    "section": "",
    "text": "This page provides help downloading, installing, and running RStudio on your personal computer (Windows, Mac, or Linux).\nYou may also use RStudio from a Penn State computer lab machine. For those instructions, see the accompanying tutorial."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#about",
    "href": "tutorials/tutorial-rstudio-on-pc.html#about",
    "title": "Setting up RStudio",
    "section": "",
    "text": "This page provides help downloading, installing, and running RStudio on your personal computer (Windows, Mac, or Linux).\nYou may also use RStudio from a Penn State computer lab machine. For those instructions, see the accompanying tutorial."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#what-is-rstudio",
    "href": "tutorials/tutorial-rstudio-on-pc.html#what-is-rstudio",
    "title": "Setting up RStudio",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is an integrated development environment (IDE) for doing data science. An IDE is a computer program that provides tools for people who are developing and testing software. You might not think of yourself as a software developer (yet). But RStudio is a powerful tool for beginners, too. It began life as a tool primarily for users writing code in R, hence the name. RStudio supports multiple programming languages, including R and Python."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#why-install-rstudio",
    "href": "tutorials/tutorial-rstudio-on-pc.html#why-install-rstudio",
    "title": "Setting up RStudio",
    "section": "Why install RStudio?",
    "text": "Why install RStudio?\nIf you have your own personal computer, it’s very helpful to have RStudio installed on your computer. That way you can work whether you’re connected to the internet or not."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#overview",
    "href": "tutorials/tutorial-rstudio-on-pc.html#overview",
    "title": "Setting up RStudio",
    "section": "Overview",
    "text": "Overview\nInstalling RStudio consists of several steps:\n\nDownloading and installing R.\nDownloading and installing RStudio.\nConfiguring RStudio.\n\nYou can complete these in about 45 minutes, or maybe less if you have a fast internet connection."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#installing-r",
    "href": "tutorials/tutorial-rstudio-on-pc.html#installing-r",
    "title": "Setting up RStudio",
    "section": "Installing R",
    "text": "Installing R\nRStudio requires you to download and install R even if you ultimately plan to do very little programming in R.\nVisit https://cran.wustl.edu/bin/.\n\n\n\nhttps://cran.wustl.edu/bin/\n\n\nSelect the subdirectory depending on what operating system your computer is running. Windows users will select windows and Mac users will select macosx.\n\nMac users\nHere is the window that opens:\n\nNotice that there are two links under the “Latest release:” section. To decide which version is appropriate for you, you need to select the version of R that is appropriate for your computer’s central processing unit (CPU) and operating system (OS). Here’s how to find out what CPU and OS you’re running:\n\nClick on the Apple icon in the top left corner of your menu bar.\n\n\n\nSelect the ‘About This Mac’ menu item.\nA window will appear with information about your computer.\n\n\nIf the ‘macOS’ field has a number greater than 11 (MacOS Big Sur), then you can download the latest version of R. If the ‘Chip’ field says “Apple M1”, “Apple M2”, “Apple M3”, or “Apple M4”, you will want to select the ARM version, e.g. “R-4.4.2-arm64.pkg”. If the ‘Chip’ field says you have some version of an Intel chip, pick the other version of R, e.g., “R-4.4.2-x86_64.pkg”.\n\nOnce the software has downloaded, open it by double-clicking."
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#installing-rstudio",
    "href": "tutorials/tutorial-rstudio-on-pc.html#installing-rstudio",
    "title": "Setting up RStudio",
    "section": "Installing RStudio",
    "text": "Installing RStudio"
  },
  {
    "objectID": "tutorials/tutorial-rstudio-on-pc.html#configuring-rstudio",
    "href": "tutorials/tutorial-rstudio-on-pc.html#configuring-rstudio",
    "title": "Setting up RStudio",
    "section": "Configuring RStudio",
    "text": "Configuring RStudio"
  },
  {
    "objectID": "tutorials/tutorial-screenshots.html",
    "href": "tutorials/tutorial-screenshots.html",
    "title": "Capturing images",
    "section": "",
    "text": "This short tutorial shows how to capture images in web pages and how to make screenshots on Mac OS and Windows OS."
  },
  {
    "objectID": "tutorials/tutorial-screenshots.html#about",
    "href": "tutorials/tutorial-screenshots.html#about",
    "title": "Capturing images",
    "section": "",
    "text": "This short tutorial shows how to capture images in web pages and how to make screenshots on Mac OS and Windows OS."
  },
  {
    "objectID": "tutorials/tutorial-screenshots.html#capturing-images-in-web-pages",
    "href": "tutorials/tutorial-screenshots.html#capturing-images-in-web-pages",
    "title": "Capturing images",
    "section": "Capturing images in web pages",
    "text": "Capturing images in web pages\nMost browsers support “right-clicking”, clicking on the right button of a multibutton mouse (or the equivalent motion on a trackpad) when you hover over an image.\nUsing Chrome on Mac OS for example, I visited the Penn State homepage at https://www.psu.edu. In mousing over a photo, I right clicked and had the following panel appear:\n\n\n\n\n\n\nFigure 1: Image from psu.edu in Chrome using MacOS\n\n\n\nNote that there are several options. I find that these are the most useful:\n\n“Open Image in New Tab”. I often do this to make sure that the web page link (URL) actually contains the image I want it to. Then I switch to that tab for further steps.\n“Save Image As…”. This is useful if you want to download a local copy.\n“Copy Image Address”. Use this for capturing URLs of images, but not the images themselves.\n\nHere is an illustration of the same process on Windows 11:\n\n\n\n\n\n\nFigure 2: Image from psu.edu on Chrome using Windows 11\n\n\n\nNot that the pop-up has similar options.\n\n\n\n\n\n\nWord to the wise\n\n\n\nSome websites do not support this feature. That’s why I prefer to use “open image in new tab” to see if I’m actually capturing what I want to capture. As a back-up, you can usually resort to your computer’s built-in screen capture tool that we’ll describe next."
  },
  {
    "objectID": "tutorials/tutorial-screenshots.html#capturing-images-on-your-screen",
    "href": "tutorials/tutorial-screenshots.html#capturing-images-on-your-screen",
    "title": "Capturing images",
    "section": "Capturing images on your screen",
    "text": "Capturing images on your screen\nWhen the image you want is not a static image, you may need to use your computer’s screen capture tool.\nFrom the same Penn State home page, I try right-clicking on the top “hero” animation. This is the result.\n\n\n\n\n\n\nFigure 3: Results of right-clicking on psu.edu ‘hero’ image/animation.\n\n\n\nNotice that the pop-up window does not have the same menu items as it did for a static image. Of course, this is an animation, and so it’s not that surprising that things would differ. Let’s say I want to capture a static image from this animation.\n\nPress the screen capture keystroke combination for your computer. On Mac OS, you have two choices, command+shift+3 (pressed simultaneously) immediately takes a screenshot of your entire window.\n\n\n\n\n\n\n\nFigure 4: Capturing entire screen on Mac OS using command+shift+3.\n\n\n\nNote that to capture a specific segment of a video, you have to wait until that image appears and press these keys quickly.\n\nAs an alternative on Mac OS, you can use command+shift+4. Then, you click and drag your mouse to indicate the region of the screen you want to capture. When the image appears in the animation, just release the mouse button and that image will be captured.\n\n\n\n\n\n\n\nFigure 5: Capturing a segment of the screen on Mac OS using command+shift+4.\n\n\n\n\n\n\n\n\n\nUnder construction\n\n\n\nInstructions about how to do this on Windows are a work-in-progress."
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#a-picture-is-worth-a-thousand-words",
    "href": "slides/wk01-2025-01-14-course-intro.html#a-picture-is-worth-a-thousand-words",
    "title": "The Psychology of Data Visualization",
    "section": "A picture is worth a thousand words…",
    "text": "A picture is worth a thousand words…\n\n“An adage in multiple languages…” Wikipedia\nTheme for the course\nWhat words does this figure convey…"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#today",
    "href": "slides/wk01-2025-01-14-course-intro.html#today",
    "title": "The Psychology of Data Visualization",
    "section": "Today",
    "text": "Today\n\nIntroduction to the course\nVisualization in psychological science"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#people",
    "href": "slides/wk01-2025-01-14-course-intro.html#people",
    "title": "The Psychology of Data Visualization",
    "section": "People",
    "text": "People\n\nSara He, MS, Graduate Student\nRick Gilmore, Professor of Psychology"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#why-this-course-why-now",
    "href": "slides/wk01-2025-01-14-course-intro.html#why-this-course-why-now",
    "title": "The Psychology of Data Visualization",
    "section": "Why this course, why now",
    "text": "Why this course, why now"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#my-journey",
    "href": "slides/wk01-2025-01-14-course-intro.html#my-journey",
    "title": "The Psychology of Data Visualization",
    "section": "My journey",
    "text": "My journey\n\nCognitive Science major, psycholinguistics & semiotics minor\nIntroduced to vision science via Marr and J.J. Gibson\nResearch in visual development, visual neuroscience"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#many-analysts",
    "href": "slides/wk01-2025-01-14-course-intro.html#many-analysts",
    "title": "The Psychology of Data Visualization",
    "section": "Many analysts",
    "text": "Many analysts\n\nFigure 2 from Silberzahn et al. (2018)"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#many-failures",
    "href": "slides/wk01-2025-01-14-course-intro.html#many-failures",
    "title": "The Psychology of Data Visualization",
    "section": "Many failures",
    "text": "Many failures\nVisualizing the ’Many Analysts – Silberzahn et al. (2018) – data"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#plot-your-data",
    "href": "slides/wk01-2025-01-14-course-intro.html#plot-your-data",
    "title": "The Psychology of Data Visualization",
    "section": "“Plot your data!”",
    "text": "“Plot your data!”\n\nGilmore’s graduate statistics professor"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#vision-can-be-unreliable-or-ambiguous",
    "href": "slides/wk01-2025-01-14-course-intro.html#vision-can-be-unreliable-or-ambiguous",
    "title": "The Psychology of Data Visualization",
    "section": "Vision can be unreliable or ambiguous",
    "text": "Vision can be unreliable or ambiguous"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#purpose-goals",
    "href": "slides/wk01-2025-01-14-course-intro.html#purpose-goals",
    "title": "The Psychology of Data Visualization",
    "section": "Purpose & goals",
    "text": "Purpose & goals\n\n\nWhat are data? Where do data come from?\nWho visualizes data, how do they visualize it, and why?\nHow does vision science inform how we perceive patterns in data?\nWhat’s the relationship between non-visual and visual ways of understanding data?\nWhat makes a data visualization effective?\nWhat makes a data visualization misleading?\nHow can we make better data visualizations?"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#schedule",
    "href": "slides/wk01-2025-01-14-course-intro.html#schedule",
    "title": "The Psychology of Data Visualization",
    "section": "Schedule",
    "text": "Schedule\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/schedule.html"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#exercises-evaluation",
    "href": "slides/wk01-2025-01-14-course-intro.html#exercises-evaluation",
    "title": "The Psychology of Data Visualization",
    "section": "Exercises & evaluation",
    "text": "Exercises & evaluation\n\nExercises\n\n8 @ 10 pts/each\nTop 4 count\nOthers count toward partial extra credit up to 10 pts\n\nAttendance (up to 40 points)\nFinal project (40 points)"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#resources",
    "href": "slides/wk01-2025-01-14-course-intro.html#resources",
    "title": "The Psychology of Data Visualization",
    "section": "Resources",
    "text": "Resources\n\nThis site: https://psu-psychology.github.io/psych-490-data-viz-2025-spring/ \nUniversity Library"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#structure",
    "href": "slides/wk01-2025-01-14-course-intro.html#structure",
    "title": "The Psychology of Data Visualization",
    "section": "Structure",
    "text": "Structure\n\nMeet 2x weekly\n\nTuesday & Thursday\nLecture + discussion + work session\n\nDo your homework"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#this-is-a-seminar",
    "href": "slides/wk01-2025-01-14-course-intro.html#this-is-a-seminar",
    "title": "The Psychology of Data Visualization",
    "section": "This is a seminar…",
    "text": "This is a seminar…\n\nhttps://www.merriam-webster.com/dictionary/seminar"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#culture-climate",
    "href": "slides/wk01-2025-01-14-course-intro.html#culture-climate",
    "title": "The Psychology of Data Visualization",
    "section": "Culture & climate",
    "text": "Culture & climate\n\n\nCreating a community of inquiry\nEncouraging vigorous & constructive criticism\nCriticism of work/ideas/behaviors vs. people\n\n‘Smith thinks that pigs can fly.’\n‘Smith is an idiot.’\n‘Smith tried to demonstrate that pigs can fly by tossing a few off the roof of Old Main. That’s nonsense and made a huge mess.’"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#exercise-01",
    "href": "slides/wk01-2025-01-14-course-intro.html#exercise-01",
    "title": "The Psychology of Data Visualization",
    "section": "Exercise 01",
    "text": "Exercise 01\n\nVisit Exercise-01"
  },
  {
    "objectID": "slides/wk01-2025-01-14-course-intro.html#references",
    "href": "slides/wk01-2025-01-14-course-intro.html#references",
    "title": "The Psychology of Data Visualization",
    "section": "References",
    "text": "References\n\n\n\n\nGilmore, R. O., Thomas, A. L., & Fesi, J. (2016). Children’s brain responses to optic flow vary by pattern type and motion speed. PloS One, 11, e0157911. https://doi.org/10.1371/journal.pone.0157911\n\n\nHuff, D. (1993). How to lie with statistics. New York, NY: WW Norton. Retrieved from https://www.amazon.com/How-Lie-Statistics-Darrell-Huff/dp/0393310728\n\n\nIso, A. (2016). Bread - if original [1971]. Youtube. Retrieved from https://www.youtube.com/watch?v=IQyKMueMFGk\n\n\nLindsey, R. (2024, April 9). Climate change: Atmospheric carbon dioxide. Retrieved November 8, 2024, from http://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide\n\n\nMatejka, J., & Fitzmaurice, G. (2017). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI conference on human factors in computing systems. New York, NY, USA: ACM. https://doi.org/10.1145/3025453.3025912\n\n\nMonmonier, M. (2018). How to lie with maps (3rd ed.). Chicago, IL: University of Chicago Press. https://doi.org/10.7208/chicago/9780226436081.001.0001\n\n\nQian, Y., Berenbaum, S. A., & Gilmore, R. O. (2022). Vision contributes to sex differences in spatial cognition and activity interests. Scientific Reports, 12, 17623. https://doi.org/10.1038/s41598-022-22269-y\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., … Nosek, B. A. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1, 337–356. https://doi.org/10.1177/2515245917747646\n\n\nThe Datasaurus dozen - same stats, different graphs | Autodesk Research. (n.d.). Retrieved June 2, 2019, from https://www.autodeskresearch.com/publications/samestats"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#video-as-data-viz",
    "href": "slides/wk02-2025-01-21-govt-biz.html#video-as-data-viz",
    "title": "Data viz in government & business",
    "section": "Video as data viz",
    "text": "Video as data viz\n\nDenton, Asphaug, Emsenhuber, & Melikyan (2025)"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#announcements",
    "href": "slides/wk02-2025-01-21-govt-biz.html#announcements",
    "title": "Data viz in government & business",
    "section": "Announcements",
    "text": "Announcements\n\nFree access to newspapers\n\n\nhttps://studentaffairs.psu.edu/involvement-student-life/student-services/student-news-readership-program"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#last-time",
    "href": "slides/wk02-2025-01-21-govt-biz.html#last-time",
    "title": "Data viz in government & business",
    "section": "Last time…",
    "text": "Last time…\nSemiotics of data visualization"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#symbol-or-thing-symbolized",
    "href": "slides/wk02-2025-01-21-govt-biz.html#symbol-or-thing-symbolized",
    "title": "Data viz in government & business",
    "section": "Symbol or thing symbolized?",
    "text": "Symbol or thing symbolized?"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#what-did-we-uncover",
    "href": "slides/wk02-2025-01-21-govt-biz.html#what-did-we-uncover",
    "title": "Data viz in government & business",
    "section": "What did we uncover?",
    "text": "What did we uncover?\n\nSummary report"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#today",
    "href": "slides/wk02-2025-01-21-govt-biz.html#today",
    "title": "Data viz in government & business",
    "section": "Today",
    "text": "Today\nVisualization in government & business"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#goals",
    "href": "slides/wk02-2025-01-21-govt-biz.html#goals",
    "title": "Data viz in government & business",
    "section": "Goals",
    "text": "Goals\n\nExplore the landscape\nWhat types of visualizations?\nWhat types of data?\nWhy visualize?"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#what-data-do-governments-visualize",
    "href": "slides/wk02-2025-01-21-govt-biz.html#what-data-do-governments-visualize",
    "title": "Data viz in government & business",
    "section": "What data do governments visualize",
    "text": "What data do governments visualize\n\nWhat data are collected?\nPrimary sources\n\nBureau of the Census\nData.gov\nOpen Data PA: https://data.pa.gov\n\nSecondary sources\n\nhttps://datausa.io/profile/geo/state-college-pa?redirect=true"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#why-do-governments-visualize-data",
    "href": "slides/wk02-2025-01-21-govt-biz.html#why-do-governments-visualize-data",
    "title": "Data viz in government & business",
    "section": "Why do governments visualize data?",
    "text": "Why do governments visualize data?"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#what-data-do-not-for-profit-businesses-visualize",
    "href": "slides/wk02-2025-01-21-govt-biz.html#what-data-do-not-for-profit-businesses-visualize",
    "title": "Data viz in government & business",
    "section": "What data do not-for-profit businesses visualize?",
    "text": "What data do not-for-profit businesses visualize?\n\nPSU Office of Planning, Assessment, and Institutional Research\nOur World in Data\nGapminder\n\nDollar Street"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#why-do-businesses-visualize-data",
    "href": "slides/wk02-2025-01-21-govt-biz.html#why-do-businesses-visualize-data",
    "title": "Data viz in government & business",
    "section": "Why do businesses visualize data?",
    "text": "Why do businesses visualize data?"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#exercise-02",
    "href": "slides/wk02-2025-01-21-govt-biz.html#exercise-02",
    "title": "Data viz in government & business",
    "section": "Exercise 02",
    "text": "Exercise 02\n\nExercise 02\nGoogle Sheet"
  },
  {
    "objectID": "slides/wk02-2025-01-21-govt-biz.html#references",
    "href": "slides/wk02-2025-01-21-govt-biz.html#references",
    "title": "Data viz in government & business",
    "section": "References",
    "text": "References\n\n\n\n\nDenton, C. A., Asphaug, E., Emsenhuber, A., & Melikyan, R. (2025). Capture of an ancient charon around pluto. Nature Geoscience, 18, 37–43. https://doi.org/10.1038/s41561-024-01612-0\n\n\nTeutem, S. van, & Acisu, T. (2024). Most international migrants don’t move very far from their home countries. Our World in Data. Retrieved from https://ourworldindata.org/international-migrants-dont-move-far"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#announcements",
    "href": "slides/wk03-2025-01-28-making-data.html#announcements",
    "title": "Making Data",
    "section": "Announcements",
    "text": "Announcements\n\nExercise-02 write-up due Thursday, January 30."
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#last-time",
    "href": "slides/wk03-2025-01-28-making-data.html#last-time",
    "title": "Making Data",
    "section": "Last time…",
    "text": "Last time…\nVisualization in the arts, sports, & journalism"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#your-observations",
    "href": "slides/wk03-2025-01-28-making-data.html#your-observations",
    "title": "Making Data",
    "section": "Your observations",
    "text": "Your observations\n\nDistinctive features of data viz in different fields?"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#preliminary-findings",
    "href": "slides/wk03-2025-01-28-making-data.html#preliminary-findings",
    "title": "Making Data",
    "section": "Preliminary findings",
    "text": "Preliminary findings\n\nVisualization of Exercise 02 results"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#today",
    "href": "slides/wk03-2025-01-28-making-data.html#today",
    "title": "Making Data",
    "section": "Today",
    "text": "Today\n\nMaking Data\nTypes of data"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#how-are-data-made",
    "href": "slides/wk03-2025-01-28-making-data.html#how-are-data-made",
    "title": "Making Data",
    "section": "How are data made?",
    "text": "How are data made?\n\n\n\nBy measurement"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#what-is-measurement",
    "href": "slides/wk03-2025-01-28-making-data.html#what-is-measurement",
    "title": "Making Data",
    "section": "What is measurement?",
    "text": "What is measurement?\n\n\n\nA procedure for mapping properties of X onto some numerical standard or scale Y\nMetrology: The science of measurement\nPsychometrics: The study of psychological measurement"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#why-mapping",
    "href": "slides/wk03-2025-01-28-making-data.html#why-mapping",
    "title": "Making Data",
    "section": "Why ‘mapping’?",
    "text": "Why ‘mapping’?\n\n\n\n\n\n\n\n\nflowchart TB\n  A[Thing/Person]-- Procedure  --&gt;B(Instrument)\n  B --&gt; C{Data}\n\n\n\n\nFigure 1: Illustration of a mapping from observed entity to data\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  A[Thing/Person]-- Procedure  --&gt;B(Instrument)\n  A[Thing/Person]-- Procedure-2  --&gt;C(Instrument-2)\n  B --&gt; E{Data}\n  C --&gt; D{Data-2}\n\n\n\n\nFigure 2: Illustration of multiple mappings from an observed entity to data"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#data-quantitative-terminology",
    "href": "slides/wk03-2025-01-28-making-data.html#data-quantitative-terminology",
    "title": "Making Data",
    "section": "Data ~ quantitative terminology",
    "text": "Data ~ quantitative terminology\n\nData a symbol of the thing measured, not the thing itself\nE.g., words are a symbol of the things they refer to\n\n\n\n\n\n\n\nflowchart TB\n  A[Cute animal with fur that purrs] --&gt; B('cat')\n  A ---&gt; C('gato')\n  A ---&gt; D('chatte/chat')\n  A ---&gt; E('猫')\n\n\n\n\nFigure 3: Mapping from concept/entity to a word."
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#symbols-reflect-select-and-deflect",
    "href": "slides/wk03-2025-01-28-making-data.html#symbols-reflect-select-and-deflect",
    "title": "Making Data",
    "section": "Symbols reflect, select, and deflect",
    "text": "Symbols reflect, select, and deflect\n\nEven if any given terminology is a reflection of reality, by its very nature as a terminology, it must be a selection of reality; and to this extent must also as a deflection of reality\n\nBurke (1968)"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#what-is-reflected-selected-deflected",
    "href": "slides/wk03-2025-01-28-making-data.html#what-is-reflected-selected-deflected",
    "title": "Making Data",
    "section": "What is reflected, selected, deflected?",
    "text": "What is reflected, selected, deflected?\n\nLindsey (2024)"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#stevens-scales-of-measurement",
    "href": "slides/wk03-2025-01-28-making-data.html#stevens-scales-of-measurement",
    "title": "Making Data",
    "section": "Stevens’ scales of measurement",
    "text": "Stevens’ scales of measurement\n\nStevens (1946)"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#questions-about-measurement",
    "href": "slides/wk03-2025-01-28-making-data.html#questions-about-measurement",
    "title": "Making Data",
    "section": "Questions about measurement",
    "text": "Questions about measurement\n\nWhat’s the procedure for making this mapping?\nWhat are the rules for assigning numbers/categories?\nWhat can we do with the assigned numbers (summarize, depict)?"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#why-does-measurement-matter",
    "href": "slides/wk03-2025-01-28-making-data.html#why-does-measurement-matter",
    "title": "Making Data",
    "section": "Why does measurement matter?",
    "text": "Why does measurement matter?\n\nGarbage in, garbage out"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#in-other-domains",
    "href": "slides/wk03-2025-01-28-making-data.html#in-other-domains",
    "title": "Making Data",
    "section": "In other domains",
    "text": "In other domains\n\nBusiness/economics\nPolitics\nSports\nEntertainment\nWeather"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#in-psychology",
    "href": "slides/wk03-2025-01-28-making-data.html#in-psychology",
    "title": "Making Data",
    "section": "In psychology",
    "text": "In psychology\n\nInternal mental states\nBehaviors\nPhysiological processes\nPhysical characteristics\nEnvironmental properties"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#examples-of",
    "href": "slides/wk03-2025-01-28-making-data.html#examples-of",
    "title": "Making Data",
    "section": "Examples of…",
    "text": "Examples of…\n\nInternal mental states\nBehaviors\nPhysiological processes\nPhysical characteristics\nEnvironmental properties"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#how-to-measure",
    "href": "slides/wk03-2025-01-28-making-data.html#how-to-measure",
    "title": "Making Data",
    "section": "How to measure…",
    "text": "How to measure…\n\nInternal mental states\nBehaviors\nPhysiological processes\nPhysical characteristics\nEnvironmental properties"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#psychology-of-survey-response",
    "href": "slides/wk03-2025-01-28-making-data.html#psychology-of-survey-response",
    "title": "Making Data",
    "section": "Psychology of survey response",
    "text": "Psychology of survey response\n\nTourangeau, Rips, & Rasinski (2012) Table 1.1"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#scales-of-measurement",
    "href": "slides/wk03-2025-01-28-making-data.html#scales-of-measurement",
    "title": "Making Data",
    "section": "Scales of measurement",
    "text": "Scales of measurement\n\nStevens (1946)"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#making-data-1",
    "href": "slides/wk03-2025-01-28-making-data.html#making-data-1",
    "title": "Making Data",
    "section": "Making data",
    "text": "Making data\n\nExercise 03"
  },
  {
    "objectID": "slides/wk03-2025-01-28-making-data.html#references",
    "href": "slides/wk03-2025-01-28-making-data.html#references",
    "title": "Making Data",
    "section": "References",
    "text": "References\n\n\n\n\nAviv, L., Saxbe, D., Messer, D., & Rao, S. (2024). The fair play method (technical report). University of Southern California. Retrieved from https://publicexchange.usc.edu/wp-content/uploads/2024/11/PX_FairPlay-Final-Report_Dec2024.pdf\n\n\nBurke, K. (1968). Language as Symbolic Action. University of California Press. Retrieved from https://www.ucpress.edu/books/language-as-symbolic-action/paper\n\n\nDattani, S., & Roser, M. (2024). What was the golden age of antibiotics, and how can we spark a new one? Our World in Data. Retrieved from https://ourworldindata.org/golden-age-antibiotics\n\n\nLindsey, R. (2024, April 9). Climate change: Atmospheric carbon dioxide. Retrieved November 8, 2024, from http://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide\n\n\nLucaas. (2007). Talking Heads - Girlfriend is Better (from stop making sense. Youtube. Retrieved from https://www.youtube.com/watch?v=9r7X3f2gFz4&list=PLXTs9Ss_E9ARDEum9WgaJ67rvpnzogpsA&index=7\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science (New York, N.Y.), 103, 677–680. https://doi.org/10.1126/science.103.2684.677\n\n\nTourangeau, R., Rips, L. J., & Rasinski, K. (2012). The Psychology of Survey Response. Cambridge, England: Cambridge University Press. https://doi.org/10.1017/cbo9780511819322"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#announcements",
    "href": "slides/wk04-2025-02-04-figure-components.html#announcements",
    "title": "Figure components",
    "section": "Announcements",
    "text": "Announcements\n\nNo deadlines this week\nPlease complete your classmates’ surveys:"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#last-time",
    "href": "slides/wk04-2025-02-04-figure-components.html#last-time",
    "title": "Figure components",
    "section": "Last time…",
    "text": "Last time…\nMaking data & Figure types"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#lets-peek-at-your-surveys",
    "href": "slides/wk04-2025-02-04-figure-components.html#lets-peek-at-your-surveys",
    "title": "Figure components",
    "section": "Let’s peek at your surveys",
    "text": "Let’s peek at your surveys\n\nLink to survey URLs"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#considerations-when-making",
    "href": "slides/wk04-2025-02-04-figure-components.html#considerations-when-making",
    "title": "Figure components",
    "section": "Considerations when making",
    "text": "Considerations when making\n\n\nNominal/discrete\n\nWhich categories\nOrder\nOther?\n\nOrdinal"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#more-considerations",
    "href": "slides/wk04-2025-02-04-figure-components.html#more-considerations",
    "title": "Figure components",
    "section": "More considerations",
    "text": "More considerations\n\n\nContinuous\n\nContinuous or grouped?\n\nFree response"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#today",
    "href": "slides/wk04-2025-02-04-figure-components.html#today",
    "title": "Figure components",
    "section": "Today",
    "text": "Today\n\nMore on figure types\n\nOrdinal data\nContinuous data\n\nComponents of data figures"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#more-nominal-types",
    "href": "slides/wk04-2025-02-04-figure-components.html#more-nominal-types",
    "title": "Figure components",
    "section": "More nominal types…",
    "text": "More nominal types…"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#pie-charts",
    "href": "slides/wk04-2025-02-04-figure-components.html#pie-charts",
    "title": "Figure components",
    "section": "Pie charts",
    "text": "Pie charts\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#ring-chart"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#ring-charts",
    "href": "slides/wk04-2025-02-04-figure-components.html#ring-charts",
    "title": "Figure components",
    "section": "Ring charts",
    "text": "Ring charts\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#ring-chart"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#mosaic-chart",
    "href": "slides/wk04-2025-02-04-figure-components.html#mosaic-chart",
    "title": "Figure components",
    "section": "Mosaic chart",
    "text": "Mosaic chart\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorial-making-data.html#mosaic-plot"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#pie-ring-mosaic-chart-mappings",
    "href": "slides/wk04-2025-02-04-figure-components.html#pie-ring-mosaic-chart-mappings",
    "title": "Figure components",
    "section": "Pie, ring, mosaic chart mappings",
    "text": "Pie, ring, mosaic chart mappings\n\nHeights & widths \\(\\rightarrow\\) counts (or proportions)\nAreas \\(\\rightarrow\\) counts (or proportions)"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#ordinal-data",
    "href": "slides/wk04-2025-02-04-figure-components.html#ordinal-data",
    "title": "Figure components",
    "section": "Ordinal data",
    "text": "Ordinal data\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#bar-plot-ordinal"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#continuous-data",
    "href": "slides/wk04-2025-02-04-figure-components.html#continuous-data",
    "title": "Figure components",
    "section": "Continuous data",
    "text": "Continuous data\n\nCover story\n\nPeople who vary in age and body temperature"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#scatterplot",
    "href": "slides/wk04-2025-02-04-figure-components.html#scatterplot",
    "title": "Figure components",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#scatterplot"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#histogram",
    "href": "slides/wk04-2025-02-04-figure-components.html#histogram",
    "title": "Figure components",
    "section": "Histogram",
    "text": "Histogram\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#histograms\n\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#histograms"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#violin-plots",
    "href": "slides/wk04-2025-02-04-figure-components.html#violin-plots",
    "title": "Figure components",
    "section": "Violin plots",
    "text": "Violin plots\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#violin-plots\n\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#scatterplot"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#boxplot",
    "href": "slides/wk04-2025-02-04-figure-components.html#boxplot",
    "title": "Figure components",
    "section": "Boxplot",
    "text": "Boxplot\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#boxplot\n\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#boxplot"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#boxplot-features",
    "href": "slides/wk04-2025-02-04-figure-components.html#boxplot-features",
    "title": "Figure components",
    "section": "Boxplot features",
    "text": "Boxplot features\n\nSummary stats only, no raw data\nMedian, upper/lower quartiles, minimum, maximum"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#violin-boxplot",
    "href": "slides/wk04-2025-02-04-figure-components.html#violin-boxplot",
    "title": "Figure components",
    "section": "Violin + Boxplot",
    "text": "Violin + Boxplot\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#violin-boxplot\n\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#violin-boxplot"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#violin-boxplot-scatter",
    "href": "slides/wk04-2025-02-04-figure-components.html#violin-boxplot-scatter",
    "title": "Figure components",
    "section": "Violin + Boxplot + Scatter",
    "text": "Violin + Boxplot + Scatter\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#violin-boxplot-scatter\n\n\n\n\n\n\nhttps://psu-psychology.github.io/psych-490-data-viz-2025-spring/tutorials/tutorial-making-data.html#violin-boxplot-scatter"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#your-turn-1",
    "href": "slides/wk04-2025-02-04-figure-components.html#your-turn-1",
    "title": "Figure components",
    "section": "Your turn",
    "text": "Your turn\n\n\n\n\n\n\nCritiquing figures\n\n\n\nWhich of these is most, least informative?\nWhat prior knowledge do viewers need to understand the figures?"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#components",
    "href": "slides/wk04-2025-02-04-figure-components.html#components",
    "title": "Figure components",
    "section": "Components",
    "text": "Components\n\nAxes\n\nScales (discrete/nominal) vs. continuous\n\nMappings\n\nCounts \\(\\rightarrow\\) height, length or area; color; texture\n\nSort order \\(\\rightarrow\\) relative position\n\nValues \\(\\rightarrow\\) position\n\nLegends\nCaption & titles"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#references",
    "href": "slides/wk04-2025-02-04-figure-components.html#references",
    "title": "Figure components",
    "section": "References",
    "text": "References\n\n\n\n\nMatejka, J., & Fitzmaurice, G. (2017). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI conference on human factors in computing systems. New York, NY, USA: ACM. https://doi.org/10.1145/3025453.3025912\n\n\nRutter, S. (2009). Figure eight schoolhouse rock. Youtube. Retrieved from https://www.youtube.com/watch?v=UCGNUo-XQJ8\n\n\nState of the nation project. (n.d.). Retrieved February 4, 2025, from https://stateofnation.org/\n\n\nThe Datasaurus dozen - same stats, different graphs | Autodesk Research. (n.d.). Retrieved June 2, 2019, from https://www.autodeskresearch.com/publications/samestats"
  },
  {
    "objectID": "exercises/ex02-data-viz-outside-psych.html",
    "href": "exercises/ex02-data-viz-outside-psych.html",
    "title": "Exercise 02",
    "section": "",
    "text": "In-class work on Tuesday, January 21-23.\nDue on Thursday, January 30.\nCanvas dropbox."
  },
  {
    "objectID": "exercises/ex02-data-viz-outside-psych.html#dates",
    "href": "exercises/ex02-data-viz-outside-psych.html#dates",
    "title": "Exercise 02",
    "section": "",
    "text": "In-class work on Tuesday, January 21-23.\nDue on Thursday, January 30.\nCanvas dropbox."
  },
  {
    "objectID": "exercises/ex02-data-viz-outside-psych.html#goals",
    "href": "exercises/ex02-data-viz-outside-psych.html#goals",
    "title": "Exercise 02",
    "section": "Goals",
    "text": "Goals\nIn this exercise, you will work alone or a with a team of no more than two other classmates to find and describe data visualizations from business (for profit or not-for-profit), government, the arts, sports, or journalism. You will add links to the visualizations to a common database that we will use for discussion about the types of visualizations and types of data that are commonly used fields outside of psychological science."
  },
  {
    "objectID": "exercises/ex02-data-viz-outside-psych.html#assignment",
    "href": "exercises/ex02-data-viz-outside-psych.html#assignment",
    "title": "Exercise 02",
    "section": "Assignment",
    "text": "Assignment\n\nChoose at least three categories (business, government, the arts, sports, or journalism) to focus on.\nFor each category, find at least one or two visualizations of data.\n\nTry to pick visualizations that are interesting to you in some way.\n\nAdd information about the visualizations to a Google Sheet that all of us will share:\n\nhttps://docs.google.com/spreadsheets/d/1rLiLBRbDQfInauOUBPNwGYq-0VOjskGNY7Wq2QRTTbc/edit?gid=0#gid=0\nSpecifically, enter your team identifier in the identifier field, the source in source_type, and the URL in the url field. Please say briefly why you chose this particular visualization. If you have any comments to add, put those in the comments field.\n\nIf you want to submit a write-up for evaluation, please select three (3) visualizations and evaluate them based on the following questions:\n\n\nWhat data are presented?\nWhat graphic elements of the visualization map to which aspects of the data?\nWhat prior knowledge does someone viewing these data need to have in order to understand the visualizations clearly?\nWhy is the source presenting these data?\nWhat story or message is the source trying to communicate and to what audience?\nHow effective is the message?\nAre the figures statistical visualizations or information visualizations (Infovis) as described by Gelman & Unwin (2013)?\n\n\n\n\n\n\n\nNote\n\n\n\nThe visualizations you choose to write about may be the ones you found yourself or those that others found and shared."
  },
  {
    "objectID": "exercises/ex02-data-viz-outside-psych.html#submit",
    "href": "exercises/ex02-data-viz-outside-psych.html#submit",
    "title": "Exercise 02",
    "section": "Submit",
    "text": "Submit\n\nEveryone\n\nYour data to the shared Google Spreadsheet.\n\n\n\nStudents submitting write-ups\nStudents who want this submission to count for one of their four (4) required exercises should submit the following:\n\nA 2-3 page write-up in APA format where you describe three (3) figures your group found, answering the questions in 4. above.\n\nMake sure to write a complete essay. See the feedback for Exercise 01 for other hints about how to improve your submission. While we will not require it because the deadline is soon, if you are able to include images of the figures you discuss, please do so. Here is a tutorial to help.\n\n\n\n\n\n\nAPA template\n\n\n\nThis template document may be helpful."
  },
  {
    "objectID": "exercises/ex04-sci-of-data-viz.html",
    "href": "exercises/ex04-sci-of-data-viz.html",
    "title": "Exercise 04",
    "section": "",
    "text": "In-class work on Thursday, February 20 and Tuesday, February 25.\nSubmit write-up for credit due by Thursday, March 6."
  },
  {
    "objectID": "exercises/ex04-sci-of-data-viz.html#dates",
    "href": "exercises/ex04-sci-of-data-viz.html#dates",
    "title": "Exercise 04",
    "section": "",
    "text": "In-class work on Thursday, February 20 and Tuesday, February 25.\nSubmit write-up for credit due by Thursday, March 6."
  },
  {
    "objectID": "exercises/ex04-sci-of-data-viz.html#goals",
    "href": "exercises/ex04-sci-of-data-viz.html#goals",
    "title": "Exercise 04",
    "section": "Goals",
    "text": "Goals\n\nRead a scientific study about data visualization.\nEvaluate the study’s findings and its implications for the design of data visualizations."
  },
  {
    "objectID": "exercises/ex04-sci-of-data-viz.html#assignment",
    "href": "exercises/ex04-sci-of-data-viz.html#assignment",
    "title": "Exercise 04",
    "section": "Assignment",
    "text": "Assignment\n\nChoose a primary source reference that is an empirical study about data visualization. For example, Cleveland & McGill (1984) or a more recent paper that cites it, one of the papers cited by Franconeri, Padilla, Shah, Zacks, & Hullman (2021), or a paper you find on your own.\nDescribe the paper’s principal goals, methods, and findings. What are the study’s weaknesses? Does the study contain data visualizations? How well do the visualizations follow best practices in data visualization design? What practical impact do the study findings have for researchers making data visualizations?"
  },
  {
    "objectID": "exercises/ex04-sci-of-data-viz.html#submit",
    "href": "exercises/ex04-sci-of-data-viz.html#submit",
    "title": "Exercise 04",
    "section": "Submit",
    "text": "Submit\n\nA 2-3 page write-up in APA format.\n\nMake sure to write a complete essay. See the feedback for Exercise 01 for other hints about how to improve your submission.\n\n\n\n\n\n\nAPA template\n\n\n\nThis template document may be helpful."
  },
  {
    "objectID": "exercises/ex06-figs-w-r.html",
    "href": "exercises/ex06-figs-w-r.html",
    "title": "Exercise 06",
    "section": "",
    "text": "Work in progress\n\n\n\nThis page is under construction."
  },
  {
    "objectID": "exercises/final-project.html",
    "href": "exercises/final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "Your final project is an opportunity for you to produce a product that shows-off some of what you have learned in the course.\nYou may work alone or with up to two other students in the class. If you work with others, you will need to complete a statement about who did what, and all of the members of your team will get the same grade."
  },
  {
    "objectID": "exercises/final-project.html#background",
    "href": "exercises/final-project.html#background",
    "title": "Final Project",
    "section": "",
    "text": "Your final project is an opportunity for you to produce a product that shows-off some of what you have learned in the course.\nYou may work alone or with up to two other students in the class. If you work with others, you will need to complete a statement about who did what, and all of the members of your team will get the same grade."
  },
  {
    "objectID": "exercises/final-project.html#dates",
    "href": "exercises/final-project.html#dates",
    "title": "Final Project",
    "section": "Dates",
    "text": "Dates\n\nProposal assigned Tuesday, February 18\nProposal due Thursday, March 6, 2026\nFinal project survey due Tuesday, April 08\nFinal write-up due Tuesday, May 05"
  },
  {
    "objectID": "exercises/final-project.html#topics",
    "href": "exercises/final-project.html#topics",
    "title": "Final Project",
    "section": "Topics",
    "text": "Topics\nYou may choose any of a wide range of topics for your final project:\n\nA tutorial on a tool or resource for data visualization you find especially useful.\nA discussion of a specific data visualization or type of visualization and how it does or does not accurately and persuasively convey some specific finding.\nA showcase of one or more data visualizations that you have made."
  },
  {
    "objectID": "exercises/final-project.html#formats",
    "href": "exercises/final-project.html#formats",
    "title": "Final Project",
    "section": "Formats",
    "text": "Formats\nThere are multiple formats for your final project. Choose one of them.\n\nShort (5-10 min) in-class talk\nPoster\nLesson plan/exercise\nTutorial\nResearch project (& write-up)\nOpinion piece"
  },
  {
    "objectID": "exercises/final-project.html#components",
    "href": "exercises/final-project.html#components",
    "title": "Final Project",
    "section": "Components",
    "text": "Components\n\nProject proposal\n\nEvery student or team must submit a one-page single-spaced project proposal. Your proposal should state the aim or objective of your project, the format, and a include a brief description of how you intend to go about achieving your objectives.\n\nThe proposal is due on Thursday, March 6.\n\n\nProject presentation\n\nEvery student or team may make an optional presentation to the class about their project. Please indicate whether you are willing to make a presentation when you complete the survey.\nNote: Giving a presentation is worth 5 extra credit points.\nThe presentations will occur during class on December 6, 9, and 11.\nIf you wish to have your presentation made available publicly on the course website, please let me know. This is also completely optional.\n\n\n\nProject write-up\n\nEvery student or team must submit a write-up, due during finals week on Tuesday, May 05.\nDepending on the format of the project (talk, poster, paper), different written materials may be submitted (slides, poster, etc.).\nFor an in-class talk, submit a separate document with your talk text or notes and your slides. You may also submit slides that include presenter notes embedded within them.\nFor a poster, submit a PowerPoint or PDF of your poster along with any talking points.\n\nRubic: An example of potential grading template we may use: https://commons.erau.edu/db-srs/poster-scoring-rubric.pdf\nArticle: How to make a good scientific poster https://www.nature.com/articles/nj7614-115a\nTutorial video: how to make a poster https://www.youtube.com/watch?v=EL5YwkiqBho&ab_channel=SamHertig\nOther basics: https://guides.libraries.psu.edu/posters\n\nFor research paper, please submit an APA-formatted manuscript 1,500-2,000 words in length.\nFor an opinion piece, please submit a document up to 1,500 words in length.\nFor an interactive website or presentation, please submit a complete set of files needed to evaluate your website or presentation.\nFor a lesson plan, please submit a document up up to 1,500 words in length."
  },
  {
    "objectID": "exercises/final-project.html#survey",
    "href": "exercises/final-project.html#survey",
    "title": "Final Project",
    "section": "Survey",
    "text": "Survey\n\nPlease provide information about your project via this Google Form: https://forms.gle/oyotxgnnqchqnSgTA"
  },
  {
    "objectID": "supplemental/other-field-figs.html",
    "href": "supplemental/other-field-figs.html",
    "title": "Findings: Data viz outside psych sci",
    "section": "",
    "text": "This page extracts information about the data visualizations we explored in Exercise-02 from the shared Google Sheet."
  },
  {
    "objectID": "supplemental/other-field-figs.html#about",
    "href": "supplemental/other-field-figs.html#about",
    "title": "Findings: Data viz outside psych sci",
    "section": "",
    "text": "This page extracts information about the data visualizations we explored in Exercise-02 from the shared Google Sheet."
  },
  {
    "objectID": "supplemental/other-field-figs.html#google-sheet",
    "href": "supplemental/other-field-figs.html#google-sheet",
    "title": "Findings: Data viz outside psych sci",
    "section": "Google Sheet",
    "text": "Google Sheet\nDirect link: https://docs.google.com/spreadsheets/d/1rLiLBRbDQfInauOUBPNwGYq-0VOjskGNY7Wq2QRTTbc/edit?gid=0#gid=0\n\nLoading…"
  },
  {
    "objectID": "supplemental/other-field-figs.html#preparation",
    "href": "supplemental/other-field-figs.html#preparation",
    "title": "Findings: Data viz outside psych sci",
    "section": "Preparation",
    "text": "Preparation\nFirst, we load the external packages (groups of R commands) that we will be using.\n\n\n\n\n\n\nImportant\n\n\n\nThe code uses the quietly() function from the purrr package to suppress most of the feedback.\n\n\n\n\nCode\nlibrary('ggplot2')\nlibrary('dplyr')\n\nr_functions &lt;- list.files(file.path(here::here(), \"src\", \"R\"), \"\\\\.R$\", full.names = TRUE)\n\npurrr::map(r_functions, source) |&gt;\n  purrr::quietly()\n\n\nfunction (...) \ncapture_output(.f(...))\n&lt;bytecode: 0x1102d5f40&gt;\n&lt;environment: 0x1102d5c68&gt;"
  },
  {
    "objectID": "supplemental/other-field-figs.html#gathering",
    "href": "supplemental/other-field-figs.html#gathering",
    "title": "Findings: Data viz outside psych sci",
    "section": "Gathering",
    "text": "Gathering\nNext, we download the data from the Google Sheet where it is collected. Dr. Gilmore has stored his Google account credentials in a special environment file that can be accessed by the R command Sys.getenv(\"GMAIL_SURVEY\").\n\n\n\n\n\n\nTip\n\n\n\nIt’s vital to be very careful when creating and sharing code like this that involves sensitive information like login credentials.\nGilmore likes to put credentials in an .Renviron file that lives in his home directory. This is a recommended practice. On Mac OS and Linux, that’s ~/.Renviron. You can use the usethis::edit_r_profile() command at the R console (not the Terminal) to open your own .Renviron file. In Gilmore’s case, he has added the following line to that file:\nGMAIL_SURVEY=\"&lt;my-google-account&gt;\"\nHere, he has substituted his Google account with credentials/access to the required files for &lt;my-google-account&gt;. Then, when the R code below calls Sys.getenv(\"GMAIL_SURVEY\"), the value of those credentials is returned as a text string.\nMake sure to close and save the .Renviron file and restart your R session before testing this yourself.\n\n\n\n\nCode\nif (!dir.exists('csv')) {\n  message(\"Creating missing `csv/`.\")\n  dir.create(\"csv\")\n}\n\nif (params$update_data) {\n  options(gargle_oauth_email = Sys.getenv(\"GMAIL_SURVEY\"))\n  googledrive::drive_auth()\n\n  googledrive::drive_download(\n    \"PSYCH-490.003-Spr-2025-Biz-Govt\",\n    path = file.path(\"csv\", params$fn),\n    type = \"csv\",\n    overwrite = TRUE\n  )\n  message(\"Data updated.\")\n} else {\n  message(\"Using stored data.\")\n}\n\n\nThe data file has been saved as a comma-separated value (CSV) format data file in a special directory called csv/.\n\n\n\n\n\n\nNote\n\n\n\nBecause these data might contain sensitive or identifiable information, we only keep a local copy and do not share it publicly via GitHub. This is achieved by adding the name of the data directory to a special .gitignore file."
  },
  {
    "objectID": "supplemental/other-field-figs.html#cleaning",
    "href": "supplemental/other-field-figs.html#cleaning",
    "title": "Findings: Data viz outside psych sci",
    "section": "Cleaning",
    "text": "Cleaning\nNext we load the saved data file, and then proceed to clean it.\n\n\nCode\nex02 &lt;-\n  readr::read_csv(file.path(\"csv\", params$fn), show_col_types = FALSE)\n\n\nThere are 46 responses.\nThese are the column/variable names.\n\n\nCode\n# Google Forms puts the full question in the top row of the data file.\n# We use the names() function to extract and print the original questions.\nex02_qs &lt;- names(ex02)\nex02_qs\n\n\n[1] \"identifier\"    \"source_type\"   \"url_to_src\"    \"url_to_figure\"\n[5] \"why_selected\"  \"comment\"      \n\n\nFor simplicity, we visualize below only those with non-empty URLs to the specific figure."
  },
  {
    "objectID": "supplemental/other-field-figs.html#summary-data",
    "href": "supplemental/other-field-figs.html#summary-data",
    "title": "Findings: Data viz outside psych sci",
    "section": "Summary data",
    "text": "Summary data\n\n\nCode\nfigs_w_urls &lt;- ex02 |&gt;\n  filter(!is.na(url_to_figure))\n\n\nThere were n=14 unique respondents.\nOf the 46 responses from these individuals or teams, n=27 had URLs we could link to directly."
  },
  {
    "objectID": "supplemental/other-field-figs.html#figures-found",
    "href": "supplemental/other-field-figs.html#figures-found",
    "title": "Findings: Data viz outside psych sci",
    "section": "Figures found",
    "text": "Figures found\n\nCode\nthese_figs &lt;- ex02 |&gt;\n  filter(!is.na(url_to_figure))\n\nres &lt;- invisible(lapply(1:dim(these_figs)[1], return_img_chunk, df = these_figs))\ncat(unlist(res), sep = \"\\n\")\n\n\nFigure 1\nSource: https://wpdatatables.com/sports-data-visualization/#:~:text=What%20is%20Sports%20Data%20Visualization,drawn%20from%20sports%2Drelated%20data.\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\nReport\nBasketball Fan\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 2\nSource: https://kinesiology.csp.edu/sports-coaches-and-trainers/infographic-top-paid-athletes-by-gender/?nab=1\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nKmm\narticle\nThis image breaksdown a few different types of sport business issues in regard to male vs female salary in sport.\n\n\n\n\n\n\nComments\n\n\n\n\nGraphic\n\n\n\n\n\nFigure 3\nSource: \n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc1\nPoster\nSeen in person\n\n\n\n\n\n\nComments\n\n\n\n\nNumber of physicians by resident year in a hospital department\n\n\n\n\n\nFigure 4\nSource: https://hcup-us.ahrq.gov/reports/statbriefs/sb253-Influenza-Hospitalizations-ED-Visits-2006-2016.jsp\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc1\nReport\nPublic health/medical example\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 5\nSource: https://www.bruinsportsanalytics.com/post/growth-of-nwsl\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc1\nArticle\nNWSL fan\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 6\nSource: https://www.hockeyviz.com/team/CAR/2425\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc1\nWebsite\nNHL, Canes fan\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 7\nSource: https://manual.audacityteam.org/\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nayc1\nWebsite\nVisualization of sound data\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 8\nSource: https://www.nbcnews.com/data-graphics/2023-college-football-season-data-6-maps-charts-rcna102444\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\nArticle\nI am very interested in college sports and I found this graphic very interesting and easy to comprehend\n\n\n\n\n\n\n\n\n\nComments\n\n\n\n\nLocations of student-athlete recruits for the major athletic conferences in the past 10 years\n\n\n\n\n\nFigure 9\nSource: https://news.gallup.com/poll/650318/grocery-restaurant-industry-images-slide.aspx\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\nArticle\nI thought this was an interesting trend to map, especially because sports appear to be a large part of American entertainment culture\n\n\n\n\n\n\nComments\n\n\n\n\nAmerican’s overall opinions of the sports industry from 2001-2024\n\n\n\n\n\nFigure 10\nSource: https://informationisbeautiful.net/beautifulnews/595-childrens-lives-saved/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\nInfographic\nI thought this was very visually appealing yet provided a lot of useful information\n\n\n\n\n\n\n\n\n\nComments\n\n\n\n\nNumber of children’s lives saved in varying regions over the last 25 years\n\n\n\n\n\nFigure 11\nSource: https://petapixel.com/2019/10/01/photos-of-endangered-species-where-every-pixel-represents-one-animal/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\nDigital Art\nSea turtles are my favorite animal, but I thought this was a very interesting way to use digital art to bring awareness to endangerment\n\n\n\n\n\n\n\n\n\nComments\n\n\n\n\nDigital image made of pixels correlating to how the number of animals left in the population\n\n\n\n\n\nFigure 12\nSource: https://news.gallup.com/poll/655220/satisfaction-democracy-edges-record-low.aspx\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nses1\nArticle\nEspecially after the election and inauguration day, this trend is interesting to me\n\n\n\n\n\n\nComments\n\n\n\n\nPercentage of Americans satisfied with the way democracy is working\n\n\n\n\n\nFigure 13\nSource: https://osf.io/preprints/osf/3nyrq\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\napl1\n3D Art\nI like 3D Art and I liked how the data was visualized in this example, it shows how varied it can be\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 14\nSource: https://www.epa.gov/outdoor-air-quality-data/air-data-daily-air-quality-tracker\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\npp\nwebsite\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 15\nSource: https://fivethirtyeight.com/features/how-mapping-shots-in-the-nba-changed-it-forever/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nThe figure lays out a clear image of field shots paired with percentages\n\n\n\n\n\n\nComments\n\n\n\n\nsports\n\n\n\n\n\nFigure 16\nSource: https://journals.sagepub.com/doi/full/10.3233/THC-231875\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\njournal\nThe figure shows their methods through images of demonstrations\n\n\n\n\n\n\nComments\n\n\n\n\nsports\n\n\n\n\n\nFigure 17\nSource: https://www.nature.com/articles/s43247-023-00856-9\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nFigure 3 shows comparisons of negative and positive emotions tied to treatment groups in a simple way\n\n\n\n\n\n\nComments\n\n\n\n\nart\n\n\n\n\n\nFigure 18\nSource: https://pmc.ncbi.nlm.nih.gov/articles/PMC8639497/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nFigure shows an easy to read graph showing data of publications per year\n\n\n\n\n\n\nComments\n\n\n\n\nart\n\n\n\n\n\nFigure 19\nSource: https://zapier.com/blog/pandemic-business-boom-report/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nChart shows the importance of the pandemic when it comes to an explanation for the rise of businesses\n\n\n\n\n\n\nComments\n\n\n\n\nbusiness\n\n\n\n\n\nFigure 20\nSource: https://www.businessinsider.com/17-charts-that-show-just-how-scary-amazons-275-billion-business-really-is-2016-3#its-also-the-top-seller-for-personal-care-and-beauty-products-in-the-us-5\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nmec\narticle\nChart shows the stats on how amazon exceeds other sellers specifically for beauty products and personal care\n\n\n\n\n\n\nComments\n\n\n\n\nbusiness\n\n\n\n\n\nFigure 21\nSource: https://impact.economist.com/perspectives/health/addressing-recurrent-cardiovascular-events-asia-pacific\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nzw\nwebsite\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 22\nSource: https://impact.economist.com/perspectives/technology-innovation/putting-iot-work-business-operations\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nzw\nwebsite\nNA\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 23\nSource: https://ygoprodeck.com/tournament/richmond-wcq-regional-2626\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nss\nWebsite\nI play Yugioh, so that’s why I chose the graph\n\n\n\n\n\n\n\n\n\nComments\n\n\n\n\nI find the choice to use a Pie chart to represent proportion of decks used to be interesing, as compared to a bar chart for frequency\n\n\n\n\n\nFigure 24\nSource: https://www.census.gov/construction/nrs/current/index.html\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nss\nWebsite\nThe census beuaru collects a lot of data, so i felt they’d be a great source to look ino.\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 25\nSource: https://www.iea.org/data-and-statistics/charts/installed-nuclear-power-capacity-by-country-and-age-in-advanced-economies-end-2023\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nss\nWebsite\nI’m really interested in Nuclear power, and did a research project on it, so I wanted to include something on it. And this bar graph shows that the US still leads in Nuclear Power production\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 26\nSource: https://thecuriousprofessor.com/2019/12/14/visualizing-data-through-art-2/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\nwebsite\nThe visual shows a scarf knitted, with each row shows the temperature of the day\n\n\n\n\n\n\nComments\n\n\n\n\nNA\n\n\n\n\n\nFigure 27\nSource: https://thecuriousprofessor.com/2019/12/14/visualizing-data-through-art-2/\n\n\n\n\n\n\n\n\n\nAnalyst\nSource Type\nWhy Selected\n\n\n\n\nabc\nwebsite\nThe visual shows the sleep pattern of baby, showsing the wake time and sleep time\n\n\n\n\n\n\nComments\n\n\n\n\nNA"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#announcements",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#announcements",
    "title": "From stimulus to sensation",
    "section": "Announcements",
    "text": "Announcements\n\nDue next Tuesday, February 11: Exercise-03 | Canvas dropbox |"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#last-time",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#last-time",
    "title": "From stimulus to sensation",
    "section": "Last time…",
    "text": "Last time…\n\nMore figure types"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#today",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#today",
    "title": "From stimulus to sensation",
    "section": "Today",
    "text": "Today\n\nWhat is vision for?\nInformation in light\nDetecting information in light"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#goals",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#goals",
    "title": "From stimulus to sensation",
    "section": "Goals",
    "text": "Goals"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#electromagnetic-spectrum",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#electromagnetic-spectrum",
    "title": "From stimulus to sensation",
    "section": "Electromagnetic spectrum",
    "text": "Electromagnetic spectrum\n\n\n\nEM spectrum from Wikipedia"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#surfaces-reflectabsorb",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#surfaces-reflectabsorb",
    "title": "From stimulus to sensation",
    "section": "Surfaces reflect/absorb",
    "text": "Surfaces reflect/absorb\n\nSource: https://www.cns.nyu.edu/~david/courses/perception/lecturenotes/color/color-slides/Slide14.jpg"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#references",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#references",
    "title": "From stimulus to sensation",
    "section": "References",
    "text": "References\n\n\n\n\nBucalo, P. (2015, October). Falcon belly dance. Youtube. Retrieved from https://www.youtube.com/watch?v=JGArTWOJtXs\n\n\nCairo, A. (2013). The functional art: An introduction to information graphics and visualization. Upper Saddle River, N: New Riders Publishing.\n\n\nJimmyCliffVEVO. (2014). Jimmy cliff - I can see clearly now (video version). Youtube. Retrieved from https://www.youtube.com/watch?v=MrHxhQPOO2c\n\n\nRandeberg, L. (2005). Diagnostic applications of diffuse reflectance spectroscopy. Retrieved from https://www.semanticscholar.org/paper/ec9450b79923e2e2152b54ab9241b60bc5374944\n\n\nWebb’s first deep field (NIRCam image). (n.d.). Retrieved January 11, 2024, from https://webbtelescope.org/contents/media/images/2022/035/01G7DCWB7137MYJ05CSH1Q5Z1Z\n\n\nWong, B. (2011). Color blindness. Nature Methods, 8, 441. https://doi.org/10.1038/nmeth.1618"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#different-surfaces-different-reflectionabsorption",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#different-surfaces-different-reflectionabsorption",
    "title": "From stimulus to sensation",
    "section": "Different surfaces == Different reflection/absorption",
    "text": "Different surfaces == Different reflection/absorption\n\nPerceived color differences correspond to different patterns of light reflection.\n\n\n\n\nRandeberg (2005)"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#spatial-patterns",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#spatial-patterns",
    "title": "From stimulus to sensation",
    "section": "Spatial patterns",
    "text": "Spatial patterns\n\ndepend on object geometry and orientation\n\n\nSource: https://thebrain.mcgill.ca"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#the-eye",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#the-eye",
    "title": "From stimulus to sensation",
    "section": "The eye",
    "text": "The eye"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#is-like-an-auto-focus-auto-exposure-camera",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#is-like-an-auto-focus-auto-exposure-camera",
    "title": "From stimulus to sensation",
    "section": "is like an auto-focus, auto-exposure camera…",
    "text": "is like an auto-focus, auto-exposure camera…"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#part-of-a-self-stabilizing-system",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#part-of-a-self-stabilizing-system",
    "title": "From stimulus to sensation",
    "section": "part of a self-stabilizing system…",
    "text": "part of a self-stabilizing system…\n\nBucalo (2015)"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#eye-head-body-system",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#eye-head-body-system",
    "title": "From stimulus to sensation",
    "section": "Eye + head + body system",
    "text": "Eye + head + body system\n\n\n\n\n\n\nNote\n\n\n\n\nEye + head + body movements align and point the eyes\nEye + head + body movements stabilize the eyes\n\nWhen the observer moves\nWhen objects move"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#image-formation",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#image-formation",
    "title": "From stimulus to sensation",
    "section": "Image formation",
    "text": "Image formation\n\nEye’s optical components\n\nCornea (fixed refraction)\nIris/pupil (modifiable aperture)\nLens (modifiable refraction)\n\nCreate projection (image) on retina"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#the-retina",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#the-retina",
    "title": "From stimulus to sensation",
    "section": "The retina…",
    "text": "The retina…\n\n\n\n\n\n\nsamples spatial patterns of light intensity & wavelength patterns"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#information-processing",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#information-processing",
    "title": "From stimulus to sensation",
    "section": "Information processing",
    "text": "Information processing\n\nSeparate channels for short, medium, long wavelengths (cones): chromatic (color)\nBlack/gray/white or overall illumination (rods): achromatic (dark/light)\n~120 M rods + ~ 5 M cones (125 M) vs. professional cameras with 100 M pixels\n\n\n\nPoint by point, topographic (map-like) 2D image of 3D world\nNon-uniform resolution (center &gt;&gt; periphery)\nyields focused image except…\n\n\n\n…when eye misshapen for cornea +lens"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#what-information",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#what-information",
    "title": "From stimulus to sensation",
    "section": "What information?",
    "text": "What information?\n\nPosition\nLength\nArea\nColor\nTexture\n(Motion)"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#wavelength-tuned-photoreceptors",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#wavelength-tuned-photoreceptors",
    "title": "From stimulus to sensation",
    "section": "‘Wavelength-tuned’ photoreceptors",
    "text": "‘Wavelength-tuned’ photoreceptors\n\n\n\nSource: Wikipedia\n\n\n\n\n\n\nRetinal rods (green) & cones (blue)\n\n\n\n\n…arranged in mosaics\n\n\n\nNormal color vision vs. protanopic (color blind) vision; Source: https://en.wikipedia.org/wiki/Retinal_mosaic\n\n\n\n\n\nwith different concentrations in different parts of the retina\n\n\n\nWikipedia"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#consequences",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#consequences",
    "title": "From stimulus to sensation",
    "section": "Consequences",
    "text": "Consequences\n\nMust move eyes to position highest resolution part of retina over target\nKeep track of sequence of eye movements and positions over time\nIntegrate sequence of samples over time\n\n\n\n\n\nCairo (2013) Figure 5.6"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#acuity",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#acuity",
    "title": "From stimulus to sensation",
    "section": "Acuity",
    "text": "Acuity\n\nDetail/pattern vision\nGrating acuity\nVernier\nSymbol/letter (optotype) acuity"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#contrast-sensitivity",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#contrast-sensitivity",
    "title": "From stimulus to sensation",
    "section": "Contrast sensitivity",
    "text": "Contrast sensitivity\n\nLight/dark ratio (contast)\nvs. spatial frequency (level of detail)\nContrast -&gt; edges; edges -&gt; shape/form\ne.g., driving in fog\n\n\n\n\n\nContrast sensitivity function\n\n\n\n\n\n\nPelli-Robson Contrast Sensitivity Chart"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#some-consequences-for-data-figures",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#some-consequences-for-data-figures",
    "title": "From stimulus to sensation",
    "section": "Some consequences for data figures",
    "text": "Some consequences for data figures\n\nSize of visual elements (symbols, including text)\nContrast (light/dark or color)\nTextures of visual patterns\nSome colors more visible than others\n\nVischeck\n\nHow much visual scanning (# of eye movements)?"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#color-palettes",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#color-palettes",
    "title": "From stimulus to sensation",
    "section": "Color palettes",
    "text": "Color palettes\n\n\n\nWong (2011) Figure 2"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#color-perception",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#color-perception",
    "title": "From stimulus to sensation",
    "section": "Color perception",
    "text": "Color perception\n\nPerceived color a function of activity in “R”, “G”, and “B” photoreceptors\n\n\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#color-vision-anomalies",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#color-vision-anomalies",
    "title": "From stimulus to sensation",
    "section": "Color vision anomalies",
    "text": "Color vision anomalies\n\nAbsence of or anomalies in photoreceptors\n\n\n\n\nWong (2011) Figure 1"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#types",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#types",
    "title": "From stimulus to sensation",
    "section": "Types",
    "text": "Types\n\n\n\nProtanopia (impaired R/long wavelength)\nDeuteranopia (impaired G/medium wavelength)\nTritanopia (impaired B/short wavelength)\n\n\n\n\n\nhttps://www.color-blindness.com/protanopia-red-green-color-blindness/"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#your-turn",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#your-turn",
    "title": "From stimulus to sensation",
    "section": "Your turn",
    "text": "Your turn\n\n\n\n\n\n\nEvaluating figures\n\n\n\n\nVisit our sample figures page and evaluate which figures might pose challenges for people with vision impairments.\nVisit our figures in psychological science and figures in business, journalism, and the arts pages with the same goal.\nWhat specific issues do you foresee?"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#a-cautionary-tale",
    "href": "slides/wk04-2025-02-04-figure-components.html#a-cautionary-tale",
    "title": "Figure components",
    "section": "A cautionary tale",
    "text": "A cautionary tale\n\n“The Datasaurus dozen - same stats, different graphs | Autodesk Research” (n.d.); Matejka & Fitzmaurice (2017)"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#boxplot-limitations",
    "href": "slides/wk04-2025-02-04-figure-components.html#boxplot-limitations",
    "title": "Figure components",
    "section": "Boxplot limitations",
    "text": "Boxplot limitations\n\n“The Datasaurus dozen - same stats, different graphs | Autodesk Research” (n.d.); Matejka & Fitzmaurice (2017)"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#next-time",
    "href": "slides/wk04-2025-02-04-figure-components.html#next-time",
    "title": "Figure components",
    "section": "Next time",
    "text": "Next time\nFrom stimulus to sensation"
  },
  {
    "objectID": "slides/wk04-2025-02-04-figure-components.html#in-the-news",
    "href": "slides/wk04-2025-02-04-figure-components.html#in-the-news",
    "title": "Figure components",
    "section": "In the news",
    "text": "In the news\n\n“State of the nation project” (n.d.)"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#barcolumn",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#barcolumn",
    "title": "From stimulus to sensation",
    "section": "Bar/column",
    "text": "Bar/column"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#lollipop",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#lollipop",
    "title": "From stimulus to sensation",
    "section": "Lollipop",
    "text": "Lollipop"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#piering",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#piering",
    "title": "From stimulus to sensation",
    "section": "Pie/ring",
    "text": "Pie/ring"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#d-summaries",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#d-summaries",
    "title": "From stimulus to sensation",
    "section": "1D summaries",
    "text": "1D summaries"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#d-scatterplots",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#d-scatterplots",
    "title": "From stimulus to sensation",
    "section": "2D scatterplots",
    "text": "2D scatterplots"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#surfaces-reflectabsorb-or-emit",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#surfaces-reflectabsorb-or-emit",
    "title": "From stimulus to sensation",
    "section": "Surfaces reflect/absorb or emit",
    "text": "Surfaces reflect/absorb or emit\n\n\n\nSource: https://www.cns.nyu.edu/~david/courses/perception/lecturenotes/color/color-slides/Slide14.jpg"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#artificial-sources",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#artificial-sources",
    "title": "From stimulus to sensation",
    "section": "Artificial sources",
    "text": "Artificial sources"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#stacked-vs.-lollipop",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#stacked-vs.-lollipop",
    "title": "From stimulus to sensation",
    "section": "Stacked vs. Lollipop",
    "text": "Stacked vs. Lollipop"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#information-at-a-distance",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#information-at-a-distance",
    "title": "From stimulus to sensation",
    "section": "Information at a distance",
    "text": "Information at a distance\n\n\n\nJames Webb space telescope deep field “Webb’s first deep field (NIRCam image)” (n.d.)\n\n\n\nLight (+ radiowaves) circumnavigate the Earth in ~133 ms\nEarth ~8.3 light-minutes from the Sun"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#where-is-itam-i",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#where-is-itam-i",
    "title": "From stimulus to sensation",
    "section": "Where is it/am I?",
    "text": "Where is it/am I?\n\n\nAzimuth (left/right)\nElevation (up/down)\nDistance (near/far)\nOrientation"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#what-is-it",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#what-is-it",
    "title": "From stimulus to sensation",
    "section": "What is it?",
    "text": "What is it?\n\n\nSurfaces\nObjects\nEntities"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#regarding-data-figures",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#regarding-data-figures",
    "title": "From stimulus to sensation",
    "section": "Regarding data figures…",
    "text": "Regarding data figures…\n\nWhat are the figure components\n\nData points, text, bars/segments/rings/boxes\n\nWhere are different components relative to one another, axes, etc."
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#wavelengths-are-continuous-but-are-perceived-colors",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#wavelengths-are-continuous-but-are-perceived-colors",
    "title": "From stimulus to sensation",
    "section": "Wavelengths are continuous, but are perceived colors?",
    "text": "Wavelengths are continuous, but are perceived colors?\n\n\n\nhttps://rmit.pressbooks.pub/colourtheory1/part/2-colour-theory-the-visible-spectrum/"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#perceived-colors-ordinal-but",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#perceived-colors-ordinal-but",
    "title": "From stimulus to sensation",
    "section": "Perceived colors ordinal, but…",
    "text": "Perceived colors ordinal, but…\n\n\nColor is a neuropsychological construct\nA reflection, selection, and deflection of objective wavelengths of light"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#spatial-patterns-on-retina",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#spatial-patterns-on-retina",
    "title": "From stimulus to sensation",
    "section": "Spatial patterns on retina",
    "text": "Spatial patterns on retina\n\ndepend on object geometry and orientation\n\n\n\n\nSource: https://thebrain.mcgill.ca\n\n\n\n\n\n\nSource: https://thebrain.mcgill.ca"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#demo",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#demo",
    "title": "From stimulus to sensation",
    "section": "Demo",
    "text": "Demo\n\nMay I have a volunteer?"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#perceived-colors-seem-ordinal-but",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#perceived-colors-seem-ordinal-but",
    "title": "From stimulus to sensation",
    "section": "Perceived colors seem ordinal, but…",
    "text": "Perceived colors seem ordinal, but…\n\n\nColor is a neuropsychological construct"
  },
  {
    "objectID": "supplemental/ex-03-deep-dive.html",
    "href": "supplemental/ex-03-deep-dive.html",
    "title": "Deep dive on Exercise 03",
    "section": "",
    "text": "This page provides links to some of the Exercise 03 surveys and shows some of the data figure types that Google Forms generates by default.\nSee this link to visit the survey URLs."
  },
  {
    "objectID": "supplemental/ex-03-deep-dive.html#about",
    "href": "supplemental/ex-03-deep-dive.html#about",
    "title": "Deep dive on Exercise 03",
    "section": "",
    "text": "This page provides links to some of the Exercise 03 surveys and shows some of the data figure types that Google Forms generates by default.\nSee this link to visit the survey URLs."
  },
  {
    "objectID": "supplemental/ex-03-deep-dive.html#pie-charts",
    "href": "supplemental/ex-03-deep-dive.html#pie-charts",
    "title": "Deep dive on Exercise 03",
    "section": "Pie charts",
    "text": "Pie charts"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html#your-ex-03-surveys",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html#your-ex-03-surveys",
    "title": "From stimulus to sensation",
    "section": "Your Ex-03 Surveys",
    "text": "Your Ex-03 Surveys\n\nExcerpts from figures generated by Google Forms"
  },
  {
    "objectID": "slides/wk04-2025-02-06-stim-to-sensation.html",
    "href": "slides/wk04-2025-02-06-stim-to-sensation.html",
    "title": "From stimulus to sensation",
    "section": "",
    "text": "JimmyCliffVEVO (2014)"
  },
  {
    "objectID": "supplemental/ex-03-deep-dive.html#bar-plots",
    "href": "supplemental/ex-03-deep-dive.html#bar-plots",
    "title": "Deep dive on Exercise 03",
    "section": "Bar plots",
    "text": "Bar plots"
  },
  {
    "objectID": "supplemental/ex-03-deep-dive.html#other",
    "href": "supplemental/ex-03-deep-dive.html#other",
    "title": "Deep dive on Exercise 03",
    "section": "Other",
    "text": "Other"
  },
  {
    "objectID": "supplemental/ex03-deep-dive.html",
    "href": "supplemental/ex03-deep-dive.html",
    "title": "Deep dive on Exercise 03",
    "section": "",
    "text": "This page provides links to some of the Exercise 03 surveys and shows some of the data figure types that Google Forms generates by default.\nSee this link to visit the survey URLs."
  },
  {
    "objectID": "supplemental/ex03-deep-dive.html#about",
    "href": "supplemental/ex03-deep-dive.html#about",
    "title": "Deep dive on Exercise 03",
    "section": "",
    "text": "This page provides links to some of the Exercise 03 surveys and shows some of the data figure types that Google Forms generates by default.\nSee this link to visit the survey URLs."
  },
  {
    "objectID": "supplemental/ex03-deep-dive.html#pie-charts",
    "href": "supplemental/ex03-deep-dive.html#pie-charts",
    "title": "Deep dive on Exercise 03",
    "section": "Pie charts",
    "text": "Pie charts"
  },
  {
    "objectID": "supplemental/ex03-deep-dive.html#bar-plots",
    "href": "supplemental/ex03-deep-dive.html#bar-plots",
    "title": "Deep dive on Exercise 03",
    "section": "Bar plots",
    "text": "Bar plots"
  },
  {
    "objectID": "supplemental/ex03-deep-dive.html#other",
    "href": "supplemental/ex03-deep-dive.html#other",
    "title": "Deep dive on Exercise 03",
    "section": "Other",
    "text": "Other"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#in-the-news",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#in-the-news",
    "title": "From stimulus to sensation",
    "section": "In the news…",
    "text": "In the news…\n\n\n“Fossil-fuel subsidies per capita, 2021” (n.d.)"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#announcements",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#announcements",
    "title": "From stimulus to sensation",
    "section": "Announcements",
    "text": "Announcements\n\nDue today Tuesday, February 11: Exercise-03 | Canvas dropbox |\nAssigned next Tuesday, February 18: Final Project proposal"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#last-time",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#last-time",
    "title": "From stimulus to sensation",
    "section": "Last time…",
    "text": "Last time…\n\nMore figure types"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#barcolumn",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#barcolumn",
    "title": "From stimulus to sensation",
    "section": "Bar/column",
    "text": "Bar/column"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#stacked-vs.-lollipop",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#stacked-vs.-lollipop",
    "title": "From stimulus to sensation",
    "section": "Stacked vs. Lollipop",
    "text": "Stacked vs. Lollipop"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#piering",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#piering",
    "title": "From stimulus to sensation",
    "section": "Pie/ring",
    "text": "Pie/ring"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#d-summaries",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#d-summaries",
    "title": "From stimulus to sensation",
    "section": "1D summaries",
    "text": "1D summaries\n\nof continuous data"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#d-scatterplots",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#d-scatterplots",
    "title": "From stimulus to sensation",
    "section": "2D scatterplots",
    "text": "2D scatterplots"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#your-ex-03-surveys",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#your-ex-03-surveys",
    "title": "From stimulus to sensation",
    "section": "Your Ex-03 Surveys",
    "text": "Your Ex-03 Surveys\n\nExcerpts from figures generated by Google Forms"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#today",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#today",
    "title": "From stimulus to sensation",
    "section": "Today",
    "text": "Today\n\nWhat is vision for?\nInformation in light\nDetecting information in light"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#information-at-a-distance",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#information-at-a-distance",
    "title": "From stimulus to sensation",
    "section": "Information at a distance",
    "text": "Information at a distance\n\nJames Webb space telescope deep field “Webb’s first deep field (NIRCam image)” (n.d.)"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#where-is-itam-i",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#where-is-itam-i",
    "title": "From stimulus to sensation",
    "section": "Where is it/am I?",
    "text": "Where is it/am I?\n\n\nAzimuth (left/right)\nElevation (up/down)\nDistance (near/far)\nOrientation"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#what-is-it",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#what-is-it",
    "title": "From stimulus to sensation",
    "section": "What is it?",
    "text": "What is it?\n\n\nEdges \\(\\rightarrow\\)\nSurfaces \\(\\rightarrow\\)\nObjects or entities"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#regarding-data-figures",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#regarding-data-figures",
    "title": "From stimulus to sensation",
    "section": "Regarding data figures…",
    "text": "Regarding data figures…\n\nWhat are the figure components\n\nData points, text, bars/segments/rings/boxes\n\nWhere are different components relative to one another, axes, etc.\nHow do figure components convey information about data?"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#electromagnetic-spectrum",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#electromagnetic-spectrum",
    "title": "From stimulus to sensation",
    "section": "Electromagnetic spectrum",
    "text": "Electromagnetic spectrum\n\nEM spectrum from Wikipedia"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#surfaces-reflectabsorb-or-emit",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#surfaces-reflectabsorb-or-emit",
    "title": "From stimulus to sensation",
    "section": "Surfaces reflect/absorb or emit",
    "text": "Surfaces reflect/absorb or emit\n\nSource: https://www.cns.nyu.edu/~david/courses/perception/lecturenotes/color/color-slides/Slide14.jpg"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#different-surfaces-different-reflectionabsorption",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#different-surfaces-different-reflectionabsorption",
    "title": "From stimulus to sensation",
    "section": "Different surfaces == Different reflection/absorption",
    "text": "Different surfaces == Different reflection/absorption\n\nPerceived color differences correspond to different patterns of light reflection.\n\n\nRandeberg (2005)"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#artificial-sources",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#artificial-sources",
    "title": "From stimulus to sensation",
    "section": "Artificial sources",
    "text": "Artificial sources"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#spatial-patterns-on-retina",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#spatial-patterns-on-retina",
    "title": "From stimulus to sensation",
    "section": "Spatial patterns on retina",
    "text": "Spatial patterns on retina\n\ndepend on object geometry and orientation\n\n\nSource: https://thebrain.mcgill.ca"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#what-information",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#what-information",
    "title": "From stimulus to sensation",
    "section": "What information?",
    "text": "What information?\n\nPosition\nLength\nArea\nColor\nTexture\n(Motion)"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#the-eye",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#the-eye",
    "title": "From stimulus to sensation",
    "section": "The eye",
    "text": "The eye"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#is-like-an-auto-focus-auto-exposure-camera",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#is-like-an-auto-focus-auto-exposure-camera",
    "title": "From stimulus to sensation",
    "section": "is like an auto-focus, auto-exposure camera…",
    "text": "is like an auto-focus, auto-exposure camera…"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#part-of-a-self-stabilizing-system",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#part-of-a-self-stabilizing-system",
    "title": "From stimulus to sensation",
    "section": "part of a self-stabilizing system…",
    "text": "part of a self-stabilizing system…\n\nBucalo (2015)"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#eye-head-body-system",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#eye-head-body-system",
    "title": "From stimulus to sensation",
    "section": "Eye + head + body system",
    "text": "Eye + head + body system\n\n\n\n\n\n\nNote\n\n\n\nEye + head + body movements align and point the eyes\nEye + head + body movements stabilize the eyes\n\nWhen the observer moves\nWhen objects move"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#demo",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#demo",
    "title": "From stimulus to sensation",
    "section": "Demo",
    "text": "Demo\n\nMay I have a volunteer?"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#image-formation",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#image-formation",
    "title": "From stimulus to sensation",
    "section": "Image formation",
    "text": "Image formation\n\nEye’s optical components\n\nCornea (fixed refraction)\nIris/pupil (modifiable aperture)\nLens (modifiable refraction)\n\nCreate projection (image) on retina"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#the-retina",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#the-retina",
    "title": "From stimulus to sensation",
    "section": "The retina…",
    "text": "The retina…\n\n\nsamples spatial patterns of light intensity & wavelength patterns"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#wavelength-tuned-photoreceptors",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#wavelength-tuned-photoreceptors",
    "title": "From stimulus to sensation",
    "section": "‘Wavelength-tuned’ photoreceptors",
    "text": "‘Wavelength-tuned’ photoreceptors\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#consequences",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#consequences",
    "title": "From stimulus to sensation",
    "section": "Consequences",
    "text": "Consequences\n\nMust move eyes to position highest resolution part of retina over target\nKeep track of sequence of eye movements and positions over time\nIntegrate sequence of samples over time"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#information-processing",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#information-processing",
    "title": "From stimulus to sensation",
    "section": "Information processing",
    "text": "Information processing\n\nSeparate channels for short, medium, long wavelengths (cones): chromatic (color)\nBlack/gray/white or overall illumination (rods): achromatic (dark/light)\n~120 M rods + ~ 5 M cones (125 M) vs. professional cameras with 100 M pixels"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#acuity",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#acuity",
    "title": "From stimulus to sensation",
    "section": "Acuity",
    "text": "Acuity\n\nDetail/pattern vision\nGrating acuity\nVernier\nSymbol/letter (optotype) acuity"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#contrast-sensitivity",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#contrast-sensitivity",
    "title": "From stimulus to sensation",
    "section": "Contrast sensitivity",
    "text": "Contrast sensitivity\n\nLight/dark ratio (contast)\nvs. spatial frequency (level of detail)\nContrast -&gt; edges; edges -&gt; shape/form\ne.g., driving in fog"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#color-perception",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#color-perception",
    "title": "From stimulus to sensation",
    "section": "Color perception",
    "text": "Color perception\n\nPerceived color a function of activity in “R”, “G”, and “B” photoreceptors\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#wavelengths-are-continuous-but-are-perceived-colors",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#wavelengths-are-continuous-but-are-perceived-colors",
    "title": "From stimulus to sensation",
    "section": "Wavelengths are continuous, but are perceived colors?",
    "text": "Wavelengths are continuous, but are perceived colors?\n\nhttps://rmit.pressbooks.pub/colourtheory1/part/2-colour-theory-the-visible-spectrum/"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#perceived-colors-seem-ordinal-but",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#perceived-colors-seem-ordinal-but",
    "title": "From stimulus to sensation",
    "section": "Perceived colors seem ordinal, but…",
    "text": "Perceived colors seem ordinal, but…\n\n\nColor is a neuropsychological construct"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#color-vision-anomalies",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#color-vision-anomalies",
    "title": "From stimulus to sensation",
    "section": "Color vision anomalies",
    "text": "Color vision anomalies\n\nAbsence of or anomalies in photoreceptors\n\n\nWong (2011) Figure 1"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#types",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#types",
    "title": "From stimulus to sensation",
    "section": "Types",
    "text": "Types\n\n\n\nProtanopia (impaired R/long wavelength)\nDeuteranopia (impaired G/medium wavelength)\nTritanopia (impaired B/short wavelength)\n\n\n\n\n\nhttps://www.color-blindness.com/protanopia-red-green-color-blindness/"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#color-palettes",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#color-palettes",
    "title": "From stimulus to sensation",
    "section": "Color palettes",
    "text": "Color palettes\n\nWong (2011) Figure 2"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#some-consequences-for-data-figures",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#some-consequences-for-data-figures",
    "title": "From stimulus to sensation",
    "section": "Some consequences for data figures",
    "text": "Some consequences for data figures\n\nSize of visual elements (symbols, including text)\nContrast (light/dark or color)\nTextures of visual patterns\nSome colors more visible than others\n\nVischeck\n\nHow much visual scanning (# of eye movements)?"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#your-turn",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#your-turn",
    "title": "From stimulus to sensation",
    "section": "Your turn",
    "text": "Your turn\n\n\n\n\n\n\nEvaluating figures\n\n\n\nVisit our sample figures page and evaluate which figures might pose challenges for people with vision impairments.\nVisit our figures in psychological science and figures in business, journalism, and the arts pages with the same goal.\nWhat specific issues do you foresee?"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#references",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#references",
    "title": "From stimulus to sensation",
    "section": "References",
    "text": "References\n\n\n\n\nBucalo, P. (2015, October). Falcon belly dance. Youtube. Retrieved from https://www.youtube.com/watch?v=JGArTWOJtXs\n\n\nCairo, A. (2013). The functional art: An introduction to information graphics and visualization. Upper Saddle River, N: New Riders Publishing.\n\n\nFossil-fuel subsidies per capita, 2021. (n.d.). Retrieved February 10, 2025, from https://ourworldindata.org/grapher/fossil-fuel-subsidies-per-capita\n\n\nJimmyCliffVEVO. (2014). Jimmy cliff - I can see clearly now (video version). Youtube. Retrieved from https://www.youtube.com/watch?v=MrHxhQPOO2c\n\n\nRandeberg, L. (2005). Diagnostic applications of diffuse reflectance spectroscopy. Retrieved from https://www.semanticscholar.org/paper/ec9450b79923e2e2152b54ab9241b60bc5374944\n\n\nWebb’s first deep field (NIRCam image). (n.d.). Retrieved January 11, 2024, from https://webbtelescope.org/contents/media/images/2022/035/01G7DCWB7137MYJ05CSH1Q5Z1Z\n\n\nWong, B. (2011). Color blindness. Nature Methods, 8, 441. https://doi.org/10.1038/nmeth.1618"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#d-summaries-of-continuous-data",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#d-summaries-of-continuous-data",
    "title": "From stimulus to sensation",
    "section": "1D summaries of continuous data",
    "text": "1D summaries of continuous data"
  },
  {
    "objectID": "slides/wk05-2025-02-11-stim-to-sensation.html#natures-speed-demonspeed-limit",
    "href": "slides/wk05-2025-02-11-stim-to-sensation.html#natures-speed-demonspeed-limit",
    "title": "From stimulus to sensation",
    "section": "Nature’s speed demon/speed limit",
    "text": "Nature’s speed demon/speed limit\n\nLight (+ radiowaves) circumnavigate the Earth in ~133 ms\n\n\nhttps://w3tm.org\nEarth ~8.3 light-minutes from the Sun"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#announcements",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#announcements",
    "title": "From sensation to perception",
    "section": "Announcements",
    "text": "Announcements\n\nAssigned next Tuesday, February 18: Final Project proposal."
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#last-time",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#last-time",
    "title": "From sensation to perception",
    "section": "Last time…",
    "text": "Last time…\n\nLight informs\n\nSpatial perception: Where, how far, how big?\nObject perception: What is it, what form, color, etc.\n\nEye\n\nHigh resolution info only in center\nSamples different categories of light wavelength\nMoves to stablize retina, scan environment"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#today",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#today",
    "title": "From sensation to perception",
    "section": "Today",
    "text": "Today\n\nWrap-up on sensation\nFrom sensation to perception"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#color-perception",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#color-perception",
    "title": "From sensation to perception",
    "section": "Color perception",
    "text": "Color perception\n\nPerceived color a function of activity in “R”, “G”, and “B” photoreceptors\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#wavelengths-are-continuous-but-are-perceived-colors",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#wavelengths-are-continuous-but-are-perceived-colors",
    "title": "From sensation to perception",
    "section": "Wavelengths are continuous, but are perceived colors?",
    "text": "Wavelengths are continuous, but are perceived colors?\n\nhttps://rmit.pressbooks.pub/colourtheory1/part/2-colour-theory-the-visible-spectrum/"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#perceived-colors-seem-ordinal-but",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#perceived-colors-seem-ordinal-but",
    "title": "From sensation to perception",
    "section": "Perceived colors seem ordinal, but…",
    "text": "Perceived colors seem ordinal, but…\n\n\nColor is a neuropsychological construct"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#whats-a-reddish-green-look-like",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#whats-a-reddish-green-look-like",
    "title": "From sensation to perception",
    "section": "What’s a reddish-green look like?",
    "text": "What’s a reddish-green look like?"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#whats-a-reddish-green-look-like-1",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#whats-a-reddish-green-look-like-1",
    "title": "From sensation to perception",
    "section": "What’s a reddish-green look like?",
    "text": "What’s a reddish-green look like?"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#explanation",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#explanation",
    "title": "From sensation to perception",
    "section": "Explanation",
    "text": "Explanation"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#color-vision-anomalies",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#color-vision-anomalies",
    "title": "From sensation to perception",
    "section": "Color vision anomalies",
    "text": "Color vision anomalies\n\nAbsence of or anomalies in photoreceptors\n\n\nWong (2011) Figure 1"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#types",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#types",
    "title": "From sensation to perception",
    "section": "Types",
    "text": "Types\n\n\n\nProtanopia (impaired R/long wavelength)\nDeuteranopia (impaired G/medium wavelength)\nTritanopia (impaired B/short wavelength)\n\n\n\n\n\nhttps://www.color-blindness.com/protanopia-red-green-color-blindness/"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#color-palettes",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#color-palettes",
    "title": "From sensation to perception",
    "section": "Color palettes",
    "text": "Color palettes\n\nWong (2011) Figure 2"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#some-consequences-for-data-figures",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#some-consequences-for-data-figures",
    "title": "From sensation to perception",
    "section": "Some consequences for data figures",
    "text": "Some consequences for data figures\n\nSize of visual elements (symbols, including text)\nContrast (light/dark or color)\nTextures of visual patterns\nSome colors more visible than others\n\nVischeck\n\nHow much visual scanning (# of eye movements) required?"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#references",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#references",
    "title": "From sensation to perception",
    "section": "References",
    "text": "References\n\n\n\n\nCairo, A. (2013). The functional art: An introduction to information graphics and visualization. Upper Saddle River, N: New Riders Publishing.\n\n\nCleveland, W. S., & McGill, R. (1984). Graphical perception: Theory, experimentation, and application to the development of graphical methods. Journal of the American Statistical Association, 79, 531–554. https://doi.org/10.1080/01621459.1984.10478080\n\n\nFew, S. (2004). Show me the numbers: Designing tables and graphs to enlighten. Oakland, CA: Analytics Press.\n\n\nKahneman, D. (2013). Thinking, fast and slow (1st edition). Farrar, Straus; Giroux. Retrieved from https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555\n\n\nMarvinGayeVEVO. (2019). Marvin gaye - what’s going on (official video 2019). Youtube. Retrieved from https://www.youtube.com/watch?v=o5TmORitlKk\n\n\nWade, N. J. (2015). How were eye movements recorded before yarbus? Perception, 44, 851–883. https://doi.org/10.1177/0301006615594947\n\n\nWong, B. (2011). Color blindness. Nature Methods, 8, 441. https://doi.org/10.1038/nmeth.1618"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#visual-brains-love-differences",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#visual-brains-love-differences",
    "title": "From sensation to perception",
    "section": "Visual brains love differences",
    "text": "Visual brains love differences\n\nFigure 6.1 Cairo (2013)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#gestalt-properties",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#gestalt-properties",
    "title": "From sensation to perception",
    "section": "Gestalt properties",
    "text": "Gestalt properties\n\nProximity\nSimilarity\nConnectedness\nClosure\nContinuity"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#some-features-more-easily-judged-than-others",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#some-features-more-easily-judged-than-others",
    "title": "From sensation to perception",
    "section": "Some features more easily judged than others",
    "text": "Some features more easily judged than others\n\nFigure 1 Cleveland & McGill (1984)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#gestalt-school",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#gestalt-school",
    "title": "From sensation to perception",
    "section": "Gestalt school",
    "text": "Gestalt school\n\nGestalt: “whole form”\nCan psychological phenomena be understood from their parts?\nOr is the whole greater than the sum of the parts?"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#reification",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#reification",
    "title": "From sensation to perception",
    "section": "Reification",
    "text": "Reification\n\n\n\nPerception is constructive\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#multistability",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#multistability",
    "title": "From sensation to perception",
    "section": "Multistability",
    "text": "Multistability\n\n\n\nPerception is multistable\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#section",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#section",
    "title": "From sensation to perception",
    "section": "",
    "text": "Figure 6.12 Cairo (2013)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#differences-in",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#differences-in",
    "title": "From sensation to perception",
    "section": "Differences in…",
    "text": "Differences in…\n\nIntensity (light/dark)\n\nContrast\n\nColor\nPosition or size"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#some-features-easier-to-judge",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#some-features-easier-to-judge",
    "title": "From sensation to perception",
    "section": "Some features easier to judge",
    "text": "Some features easier to judge\n\nFigure 1 Cleveland & McGill (1984)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#invariance",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#invariance",
    "title": "From sensation to perception",
    "section": "Invariance",
    "text": "Invariance\n\n\n\nAnd yet…\nPerception is invariant\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#gestalt-laws-of-perceptual-grouping",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#gestalt-laws-of-perceptual-grouping",
    "title": "From sensation to perception",
    "section": "Gestalt “laws” of perceptual grouping",
    "text": "Gestalt “laws” of perceptual grouping\n\nProximity\nSimilarity\nConnectedness\nClosure\nContinuity\nSymmetry"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#proximity",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#proximity",
    "title": "From sensation to perception",
    "section": "Proximity",
    "text": "Proximity\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#similarity",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#similarity",
    "title": "From sensation to perception",
    "section": "Similarity",
    "text": "Similarity\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#closure",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#closure",
    "title": "From sensation to perception",
    "section": "Closure",
    "text": "Closure\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#symmetry",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#symmetry",
    "title": "From sensation to perception",
    "section": "Symmetry",
    "text": "Symmetry\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#continuity",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#continuity",
    "title": "From sensation to perception",
    "section": "Continuity",
    "text": "Continuity\n\nhttps://en.wikipedia.org/wiki/Gestalt_psychology"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#data-viz-example",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#data-viz-example",
    "title": "From sensation to perception",
    "section": "Data viz example",
    "text": "Data viz example\n\nFigure 6.3 Cairo (2013)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#especially",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#especially",
    "title": "From sensation to perception",
    "section": "Especially …",
    "text": "Especially …\n\nIntensity (light/dark)\n\nContrast\n\nColor\nPosition or size\nChanges in…"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#pre-attentive-vision",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#pre-attentive-vision",
    "title": "From sensation to perception",
    "section": "Pre-attentive vision",
    "text": "Pre-attentive vision\n\nDetect quickly, with minimal effort\nUsually in a single glance/fixation\nvs. attentive vision\n\nOvert shifts of attention (eye movements)\nCovert shifts (“mind’s eye” movements)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#some-features-easierfaster-to-judge",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#some-features-easierfaster-to-judge",
    "title": "From sensation to perception",
    "section": "Some features easier/faster to judge",
    "text": "Some features easier/faster to judge\n\nFigure 1 Cleveland & McGill (1984)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#connectedness",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#connectedness",
    "title": "From sensation to perception",
    "section": "Connectedness",
    "text": "Connectedness\n\nFigure 6.8 Cairo (2013)"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#your-turn",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#your-turn",
    "title": "From sensation to perception",
    "section": "Your turn",
    "text": "Your turn\n\nFind a compelling illustration of one of the Gestalt phenomena (non-data visualization-related)\nFind an illustration of one of the Gestalt phenomena in a data visualization\nAdd findings (and URLs) here:\n\nhttps://docs.google.com/spreadsheets/d/1G8U_IPMP0x17Sfl-FQfF37DN19bDQFm0GO_UmQQzv7Q/edit?usp=sharing"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#similar-but-not-too-similar",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#similar-but-not-too-similar",
    "title": "From sensation to perception",
    "section": "Similar but not too similar",
    "text": "Similar but not too similar"
  },
  {
    "objectID": "slides/wk05-2025-02-13-sensation-to-perception.html#putting-it-all-together",
    "href": "slides/wk05-2025-02-13-sensation-to-perception.html#putting-it-all-together",
    "title": "From sensation to perception",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\n\nFigure 6.20 Cairo (2013)"
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html",
    "href": "supplemental/gestalt-in-the-wild.html",
    "title": "Gestalt in the wild",
    "section": "",
    "text": "This page extracts information about illustrations of Gestalt principles that students found as part of their work on 2025-02-13. Data are pulled from the shared Google Sheet."
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#about",
    "href": "supplemental/gestalt-in-the-wild.html#about",
    "title": "Gestalt in the wild",
    "section": "",
    "text": "This page extracts information about illustrations of Gestalt principles that students found as part of their work on 2025-02-13. Data are pulled from the shared Google Sheet."
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#data",
    "href": "supplemental/gestalt-in-the-wild.html#data",
    "title": "Gestalt in the wild",
    "section": "Data",
    "text": "Data\nDirect link: https://docs.google.com/spreadsheets/d/1G8U_IPMP0x17Sfl-FQfF37DN19bDQFm0GO_UmQQzv7Q/edit?usp=sharing\n\nLoading…"
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#preparation",
    "href": "supplemental/gestalt-in-the-wild.html#preparation",
    "title": "Gestalt in the wild",
    "section": "Preparation",
    "text": "Preparation\nFirst, we load the external packages (groups of R commands) that we will be using.\n\n\n\n\n\n\nImportant\n\n\n\nThe code uses the quietly() function from the purrr package to suppress most of the feedback.\n\n\n\n\nCode\nlibrary('ggplot2')\nlibrary('dplyr')\n\n# r_functions &lt;- list.files(file.path(here::here(), \"src\", \"R\"), \"\\\\.R$\", full.names = TRUE)\n# \n# purrr::map(r_functions, source) |&gt;\n#   purrr::quietly()"
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#gathering",
    "href": "supplemental/gestalt-in-the-wild.html#gathering",
    "title": "Gestalt in the wild",
    "section": "Gathering",
    "text": "Gathering\nNext, we download the data from the Google Sheet where it is collected. Dr. Gilmore has stored his Google account credentials in a special environment file that can be accessed by the R command Sys.getenv(\"GMAIL_SURVEY\").\n\n\n\n\n\n\nTip\n\n\n\nIt’s vital to be very careful when creating and sharing code like this that involves sensitive information like login credentials.\nGilmore likes to put credentials in an .Renviron file that lives in his home directory. This is a recommended practice. On Mac OS and Linux, that’s ~/.Renviron. You can use the usethis::edit_r_profile() command at the R console (not the Terminal) to open your own .Renviron file. In Gilmore’s case, he has added the following line to that file:\nGMAIL_SURVEY=\"&lt;my-google-account&gt;\"\nHere, he has substituted his Google account with credentials/access to the required files for &lt;my-google-account&gt;. Then, when the R code below calls Sys.getenv(\"GMAIL_SURVEY\"), the value of those credentials is returned as a text string.\nMake sure to close and save the .Renviron file and restart your R session before testing this yourself.\n\n\n\n\nCode\nif (!dir.exists('csv')) {\n  message(\"Creating missing `csv/`.\")\n  dir.create(\"csv\")\n}\n\nif (params$update_data) {\n  options(gargle_oauth_email = Sys.getenv(\"GMAIL_SURVEY\"))\n  googledrive::drive_auth()\n\n  googledrive::drive_download(\n    params$google_sheet_name,\n    path = file.path(\"csv\", params$fn),\n    type = \"csv\",\n    overwrite = TRUE\n  )\n  message(\"Data updated.\")\n} else {\n  message(\"Using stored data.\")\n}\n\n\nThe data file has been saved as a comma-separated value (CSV) format data file in a special directory called csv/."
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#cleaning",
    "href": "supplemental/gestalt-in-the-wild.html#cleaning",
    "title": "Gestalt in the wild",
    "section": "Cleaning",
    "text": "Cleaning\nNext we load the saved data file, and then proceed to clean it.\n\n\nCode\ngestalt &lt;-\n  readr::read_csv(file.path(\"csv\", params$fn), show_col_types = FALSE)\n\n\nThere are 22 responses.\nThese are the column/variable names.\n\n\nCode\n# Google Forms puts the full question in the top row of the data file.\n# We use the names() function to extract and print the original questions.\ngestalt_qs &lt;- names(gestalt)\ngestalt_qs\n\n\n[1] \"identifier\"        \"gestalt_principle\" \"url_src\"          \n[4] \"url_to_img\"       \n\n\nFor simplicity, we visualize below only those with non-empty URLs to the specific figure."
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#summary-data",
    "href": "supplemental/gestalt-in-the-wild.html#summary-data",
    "title": "Gestalt in the wild",
    "section": "Summary data",
    "text": "Summary data\n\n\nCode\nfigs_w_urls &lt;- gestalt |&gt;\n  filter(!is.na(url_to_img)) |&gt;\n  filter(stringr::str_detect(url_to_img, \"[png|jpg|webp]$\"))\n\n\nThere were n=14 unique respondents.\nOf the 22 responses from these individuals or teams, n=13 had URLs we could link to directly with non-data-visualization figures."
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#make-helper-functions",
    "href": "supplemental/gestalt-in-the-wild.html#make-helper-functions",
    "title": "Gestalt in the wild",
    "section": "Make helper functions",
    "text": "Make helper functions\n\n\nCode\nmake_img_markdown_from_url &lt;- function(img_url = \"https://www.psychologicalscience.org/redesign/wp-content/uploads/2015/12/TCD_fig_1.jpg\",\n                                       lightbox = \"{.lightbox}\") {\n  assertthat::is.string(img_url)\n  \n  component_1 &lt;- paste0(\"![](\")\n  component_2 &lt;- paste0(img_url, \")\", lightbox)\n  paste0(component_1, component_2)\n}\n\n\nreturn_img_chunk &lt;- function(i, df) {\n  assertthat::is.number(i)\n  assertthat::assert_that(i &gt; 0)\n  assertthat::assert_that(is.data.frame(df))\n  \n  df_i &lt;- df[i,]\n  chunk_hdr_txt &lt;- paste0(\"### Figure \", i, \"\\n\\n\")\n  chunk_hdr &lt;- knitr::knit_expand(text = chunk_hdr_txt)\n  \n  if (!is.na(df_i$url_to_img)) {\n    img_markdown &lt;- make_img_markdown_from_url(df_i$url_to_img)\n  } else {\n    img_markdown = \"**No direct link to figure**\"\n  }\n  body_txt &lt;- paste0(\"\\n\\n| Analyst | Principle | \\n|---|---|\\n\", \n  \"| \", df_i$identifier, \" | \", df_i$gestalt_principle, \"|\")\n  knitr::knit_child(\n    text = c(chunk_hdr, img_markdown, body_txt),\n    envir = environment(),\n    quiet = TRUE\n  )  \n}"
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#non-data-visualization-examples",
    "href": "supplemental/gestalt-in-the-wild.html#non-data-visualization-examples",
    "title": "Gestalt in the wild",
    "section": "Non data-visualization examples",
    "text": "Non data-visualization examples\n\nCode\nthese_figs &lt;- gestalt |&gt;\n  dplyr::mutate(url_to_figure = url_to_non_data_viz)\n\n\nres &lt;- invisible(lapply(1:dim(these_figs)[1], return_img_chunk, df = these_figs))\ncat(unlist(res), sep = \"\\n\")\n\n\nFigure 1\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nHRQ\nClosure\n\n\n\n\n\nFigure 2\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nTJD\nContinuity\n\n\n\n\n\nFigure 3\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nSS\nClosure\n\n\n\n\n\nFigure 4\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nSES\nClosure\n\n\n\n\n\nFigure 5\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nKMM\nClosure\n\n\n\n\n\nFigure 6\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nJVM\nProximity\n\n\n\n\n\nFigure 7\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nBM\nNA\n\n\n\n\n\nFigure 8\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nABC\nContinuity\n\n\n\n\n\nFigure 9\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nKVV\nClosure\n\n\n\n\n\nFigure 10\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nac\nContinuity\n\n\n\n\n\nFigure 11\nNo direct link to figure\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nBSW\nClosure\n\n\n\n\n\nFigure 12\nNo direct link to figure\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nrf\nClosure\n\n\n\n\n\nFigure 13\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nNMSL\nContinuity\n\n\n\n\n\nFigure 14\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\npp\nReification"
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#figures-found",
    "href": "supplemental/gestalt-in-the-wild.html#figures-found",
    "title": "Gestalt in the wild",
    "section": "Figures found",
    "text": "Figures found\n\nCode\nres &lt;- invisible(lapply(1:dim(figs_w_urls)[1], return_img_chunk, df = figs_w_urls))\ncat(unlist(res), sep = \"\\n\")\n\n\nFigure 1\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nHRQ\nClosure\n\n\n\n\n\nFigure 2\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nHRQ\nClosure\n\n\n\n\n\nFigure 3\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nTJD\nContinuity\n\n\n\n\n\nFigure 4\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nTJD\nContinuity\n\n\n\n\n\nFigure 5\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nSS\nClosure\n\n\n\n\n\nFigure 6\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nJVM\nProximity\n\n\n\n\n\nFigure 7\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nABC\nContinuity\n\n\n\n\n\nFigure 8\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nABC\nContinuity\n\n\n\n\n\nFigure 9\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nKVV\nClosure\n\n\n\n\n\nFigure 10\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nKVV\nClosure\n\n\n\n\n\nFigure 11\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nac\nContinuity\n\n\n\n\n\nFigure 12\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\nNA\nNA\n\n\n\n\n\nFigure 13\n\n\n\n\nAnalyst\nPrinciple\n\n\n\n\npp\nReification"
  },
  {
    "objectID": "supplemental/gestalt-in-the-wild.html#sites-found",
    "href": "supplemental/gestalt-in-the-wild.html#sites-found",
    "title": "Gestalt in the wild",
    "section": "Sites found",
    "text": "Sites found\n\n\nCode\ngestalt |&gt;\n  filter(!is.na(url_src)) |&gt;\n  filter(stringr::str_detect(url_src, \"^https://\")) |&gt;\n  dplyr::select(url_src) |&gt;\n#  dplyr::mutate(url_src = paste0(\"&lt;\", url_src, \"&gt;\")) |&gt;\n  knitr::kable(format = 'html')\n\n\n\n\n\nurl_src\n\n\n\n\nhttps://www.wikiart.org/en/salvador-dali/face-of-mae-west-which-may-be-used-as-an-apartment\n\n\nhttps://www.olympics.com/ioc/olympic-rings\n\n\nhttps://www.census.gov/library/visualizations/interactive/state-private-nonres-construction-spending.html\n\n\nhttps://www.behance.net/gallery/18122387/Gestalt-Principles\n\n\nhttps://nastengraph.medium.com/gestalt-principles-in-data-visualization-a4e56e6074b5\n\n\nhttps://www.uxdesigninstitute.com/blog/gestalt-principles-ux-ui-design/\n\n\nhttps://towardsdatascience.com/the-psychology-behind-data-visualization-techniques-68ef12865720/\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC3728284/\n\n\nhttps://wbispace.usc.edu/gestalt.html\n\n\nhttps://www.pinterest.com/pin/355854808061515950/sent/?invite_code=838115ec6814476584ca76ff24e9d590&sfo=1"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#announcements",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#announcements",
    "title": "From cognition to understanding",
    "section": "Announcements",
    "text": "Announcements\n\nAssigned today: Final Project proposal"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#last-time",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#last-time",
    "title": "From cognition to understanding",
    "section": "Last time…",
    "text": "Last time…\n\nPre-attentive vs. attentive vision\nGestalt principles\n\nYour findings"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#today",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#today",
    "title": "From cognition to understanding",
    "section": "Today",
    "text": "Today\n\nFrom specifc to general; concrete to abstract\nThe comparing brain"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#from-specific-to-general",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#from-specific-to-general",
    "title": "From cognition to understanding",
    "section": "From specific to general",
    "text": "From specific to general\n\nFigure 7.3 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#bottom-up-and-top-down",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#bottom-up-and-top-down",
    "title": "From cognition to understanding",
    "section": "Bottom-up and top-down",
    "text": "Bottom-up and top-down\n\nFigure 7.5 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#references",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#references",
    "title": "From cognition to understanding",
    "section": "References",
    "text": "References\n\n\n\n\nCairo, A. (2013). The functional art: An introduction to information graphics and visualization. Upper Saddle River, N: New Riders Publishing.\n\n\nFeynman, R. P. (1974). Cargo cult science. Retrieved from https://calteches.library.caltech.edu/51/2/CargoCult.htm\n\n\nFranconeri, S. L., Padilla, L. M., Shah, P., Zacks, J. M., & Hullman, J. (2021). The science of visual data communication: What works. Psychological Science in the Public Interest: A Journal of the American Psychological Society, 22(3), 110–161. https://doi.org/10.1177/15291006211051956\n\n\nLindsey, R. (2024, April 9). Climate change: Atmospheric carbon dioxide. Retrieved November 8, 2024, from http://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide\n\n\nMatejka, J., & Fitzmaurice, G. (2017). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI conference on human factors in computing systems. New York, NY, USA: ACM. https://doi.org/10.1145/3025453.3025912\n\n\nMerton, R. W. (1973). The normative structure of science. In R. K. Merton & N. W. Storer (Eds.), The Sociology of Science: Theoretical and Empirical Investigations (pp. 267–278). The University of Chicago Press.\n\n\nThe Datasaurus dozen - same stats, different graphs | Autodesk Research. (n.d.). Retrieved June 2, 2019, from https://www.autodeskresearch.com/publications/samestats"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#how-large-is-the-memory-bank",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#how-large-is-the-memory-bank",
    "title": "From cognition to understanding",
    "section": "How large is the memory bank?",
    "text": "How large is the memory bank?\n\nFigure 7.8 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#abstraction-to-the-rescue",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#abstraction-to-the-rescue",
    "title": "From cognition to understanding",
    "section": "Abstraction to the rescue",
    "text": "Abstraction to the rescue\n\nFigure 7.7 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#some-parts-others",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#some-parts-others",
    "title": "From cognition to understanding",
    "section": "Some parts > others",
    "text": "Some parts &gt; others\n\nFigure 7.9 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#when-less-detail-more",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#when-less-detail-more",
    "title": "From cognition to understanding",
    "section": "When less detail > more",
    "text": "When less detail &gt; more\n\nFigure 7.11 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#back-to-visualizations",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#back-to-visualizations",
    "title": "From cognition to understanding",
    "section": "Back to visualizations",
    "text": "Back to visualizations\n\nFranconeri, Padilla, Shah, Zacks, & Hullman (2021)\n“Visualizations let viewers see beyond summary statistics”"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#franconeri2021-uv",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#franconeri2021-uv",
    "title": "From cognition to understanding",
    "section": "Franconeri et al. (2021)",
    "text": "Franconeri et al. (2021)\n\n“Visual channels translate numbers into images”"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#franconeri2021-uv-1",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#franconeri2021-uv-1",
    "title": "From cognition to understanding",
    "section": "Franconeri et al. (2021)",
    "text": "Franconeri et al. (2021)\n\nFigure 2 from Franconeri et al. (2021)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#hard-to-map-without-distortion",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#hard-to-map-without-distortion",
    "title": "From cognition to understanding",
    "section": "Hard to map without distortion",
    "text": "Hard to map without distortion"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-american-and-scientific-way",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-american-and-scientific-way",
    "title": "From cognition to understanding",
    "section": "Debate is the American (and scientific) way",
    "text": "Debate is the American (and scientific) way\n https://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-american-way",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-american-way",
    "title": "From cognition to understanding",
    "section": "Debate is the American way",
    "text": "Debate is the American way\n\nhttps://www.wcpo.com/news/state/state-ohio/ohio-senate-bans-diversity-initiatives-polices-topics-taught-in-name-of-free-speech-on-college-campuses"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-way-of-science",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-way-of-science",
    "title": "From cognition to understanding",
    "section": "Debate is the way of science",
    "text": "Debate is the way of science\n\nEvidence + logical argument"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-way-of-science-scholarship",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#debate-is-the-way-of-science-scholarship",
    "title": "From cognition to understanding",
    "section": "Debate is the way of science & scholarship",
    "text": "Debate is the way of science & scholarship\n\nShow me the data!\nEvidence + logical argument\nPlus rigorous self-criticism"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#scientific-norms-merton1973-vf",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#scientific-norms-merton1973-vf",
    "title": "From cognition to understanding",
    "section": "Scientific norms (Merton, 1973)",
    "text": "Scientific norms (Merton, 1973)\n\n\n\n\nCommunalism (common ownership)\nUniversalism (independent validity)\nDisinterestedness (public benefit)\nOrganized skepticism (scrutinize everything)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#merton1973-vf",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#merton1973-vf",
    "title": "From cognition to understanding",
    "section": "Merton (1973)",
    "text": "Merton (1973)\n\n\n\nThe mores of science possess a methodologic rationale…They are procedurally efficent…"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognitition-to-understanding.html#feynman1974-ld",
    "href": "slides/wk06-2025-02-18-cognitition-to-understanding.html#feynman1974-ld",
    "title": "From cognition to understanding",
    "section": "Feynman (1974)",
    "text": "Feynman (1974)\n\n\n\n“The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that…”"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#announcements",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#announcements",
    "title": "From cognition to understanding",
    "section": "Announcements",
    "text": "Announcements\n\nAssigned today: Final Project proposal"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#last-time",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#last-time",
    "title": "From cognition to understanding",
    "section": "Last time…",
    "text": "Last time…\n\nPre-attentive vs. attentive vision\nGestalt principles\n\nYour findings"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#today",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#today",
    "title": "From cognition to understanding",
    "section": "Today",
    "text": "Today\n\nFrom specifc to general; concrete to abstract\nThe comparing brain"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#from-specific-to-general",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#from-specific-to-general",
    "title": "From cognition to understanding",
    "section": "From specific to general",
    "text": "From specific to general\n\nFigure 7.3 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#bottom-up-and-top-down",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#bottom-up-and-top-down",
    "title": "From cognition to understanding",
    "section": "Bottom-up and top-down",
    "text": "Bottom-up and top-down\n\nFigure 7.5 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#how-large-is-the-memory-bank",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#how-large-is-the-memory-bank",
    "title": "From cognition to understanding",
    "section": "How large is the memory bank?",
    "text": "How large is the memory bank?\n\nFigure 7.8 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#when-less-detail-more",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#when-less-detail-more",
    "title": "From cognition to understanding",
    "section": "When less detail > more",
    "text": "When less detail &gt; more\n\nFigure 7.11 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#abstraction-to-the-rescue",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#abstraction-to-the-rescue",
    "title": "From cognition to understanding",
    "section": "Abstraction to the rescue",
    "text": "Abstraction to the rescue\n\nFigure 7.7 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#some-parts-others",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#some-parts-others",
    "title": "From cognition to understanding",
    "section": "Some parts > others",
    "text": "Some parts &gt; others\n\nFigure 7.9 from Cairo (2013)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#back-to-visualizations",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#back-to-visualizations",
    "title": "From cognition to understanding",
    "section": "Back to visualizations",
    "text": "Back to visualizations\n\nFranconeri, Padilla, Shah, Zacks, & Hullman (2021)\n“Visualizations let viewers see beyond summary statistics”"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#franconeri2021-uv",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#franconeri2021-uv",
    "title": "From cognition to understanding",
    "section": "Franconeri et al. (2021)",
    "text": "Franconeri et al. (2021)\n\n“Visual channels translate numbers into images”"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#hard-to-map-without-distortion",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#hard-to-map-without-distortion",
    "title": "From cognition to understanding",
    "section": "Hard to map without distortion",
    "text": "Hard to map without distortion"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#debate-is-the-american-way",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#debate-is-the-american-way",
    "title": "From cognition to understanding",
    "section": "Debate is the American way",
    "text": "Debate is the American way"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#debate-is-the-way-of-science-scholarship",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#debate-is-the-way-of-science-scholarship",
    "title": "From cognition to understanding",
    "section": "Debate is the way of science & scholarship",
    "text": "Debate is the way of science & scholarship\n\nShow me the data!\nEvidence + logical argument\nPlus rigorous self-criticism"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#scientific-norms-merton1973-vf",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#scientific-norms-merton1973-vf",
    "title": "From cognition to understanding",
    "section": "Scientific norms (Merton, 1973)",
    "text": "Scientific norms (Merton, 1973)\n\n\n\n\nCommunalism (common ownership)\nUniversalism (independent validity)\nDisinterestedness (public benefit)\nOrganized skepticism (scrutinize everything)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#merton1973-vf",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#merton1973-vf",
    "title": "From cognition to understanding",
    "section": "Merton (1973)",
    "text": "Merton (1973)\n\n\n\nThe mores of science possess a methodologic rationale…They are procedurally efficent…"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#feynman1974-ld",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#feynman1974-ld",
    "title": "From cognition to understanding",
    "section": "Feynman (1974)",
    "text": "Feynman (1974)\n\n\n\n“The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that…”"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#the-u.s.-is-only-1-country",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#the-u.s.-is-only-1-country",
    "title": "From cognition to understanding",
    "section": "The U.S. is only 1 country",
    "text": "The U.S. is only 1 country\n\nFerrell (2025)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#references",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#references",
    "title": "From cognition to understanding",
    "section": "References",
    "text": "References\n\n\n\n\nCairo, A. (2013). The functional art: An introduction to information graphics and visualization. Upper Saddle River, N: New Riders Publishing.\n\n\nFerrell, J. (2025, February 10). January was coldest in U.S. Since 1988 but globe was warmest ever. Retrieved February 17, 2025, from https://www.accuweather.com/en/climate/january-was-coldest-in-u-s-since-1988-but-globe-was-warmest-ever/1743438\n\n\nFeynman, R. P. (1974). Cargo cult science. Retrieved from https://calteches.library.caltech.edu/51/2/CargoCult.htm\n\n\nFranconeri, S. L., Padilla, L. M., Shah, P., Zacks, J. M., & Hullman, J. (2021). The science of visual data communication: What works. Psychological Science in the Public Interest: A Journal of the American Psychological Society, 22(3), 110–161. https://doi.org/10.1177/15291006211051956\n\n\nLindsey, R. (2024, April 9). Climate change: Atmospheric carbon dioxide. Retrieved November 8, 2024, from http://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide\n\n\nMatejka, J., & Fitzmaurice, G. (2017). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI conference on human factors in computing systems. New York, NY, USA: ACM. https://doi.org/10.1145/3025453.3025912\n\n\nMerton, R. W. (1973). The normative structure of science. In R. K. Merton & N. W. Storer (Eds.), The Sociology of Science: Theoretical and Empirical Investigations (pp. 267–278). The University of Chicago Press.\n\n\nThe Datasaurus dozen - same stats, different graphs | Autodesk Research. (n.d.). Retrieved June 2, 2019, from https://www.autodeskresearch.com/publications/samestats"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#section",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#section",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Ferrell (2025)"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-capita-by-rich-countries",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-capita-by-rich-countries",
    "title": "From cognition to understanding",
    "section": "\\(CO_2\\) emissions (per capita) by rich countries",
    "text": "\\(CO_2\\) emissions (per capita) by rich countries\n\nhttps://rick-gilmore.com/posts/data-stories-climate-change/"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-gdp-by-rich-countries",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-gdp-by-rich-countries",
    "title": "From cognition to understanding",
    "section": "\\(CO_2\\) emissions (per GDP) by rich countries",
    "text": "\\(CO_2\\) emissions (per GDP) by rich countries\n\nhttps://rick-gilmore.com/posts/data-stories-climate-change-II/"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#debate-is-the-scholarly-way",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#debate-is-the-scholarly-way",
    "title": "From cognition to understanding",
    "section": "Debate is the scholarly way",
    "text": "Debate is the scholarly way\n\nShow me the data!\nEvidence + logical argument\nPlus rigorous self-criticism"
  },
  {
    "objectID": "slides/wk06-2025-02-18-cognition-to-understanding.html#the-u.s.-is-only-one-country",
    "href": "slides/wk06-2025-02-18-cognition-to-understanding.html#the-u.s.-is-only-one-country",
    "title": "From cognition to understanding",
    "section": "The U.S. is only one country",
    "text": "The U.S. is only one country\n\nFerrell (2025)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Assigned today: Final Project proposal\n\n\n\n\n\nPre-attentive vs. attentive vision\nGestalt principles\n\nYour findings\n\n\n\n\n\n\nFrom specifc to general; concrete to abstract\nThe comparing brain\n\n\n\n\n\n\n\nFigure 7.3 from Cairo (2013)\n\n\n\n\n\n\n\n\nFigure 7.5 from Cairo (2013)\n\n\n\n\n\n\nFigure 7.6 from Cairo (2013)\n\n\n\n\n\n\n\n\n\n\nFigure 7.8 from Cairo (2013)\n\n\n\n\n\n\n\n\nFigure 7.11 from Cairo (2013)\n\n\n\n\n\n\n\n\nFigure 7.7 from Cairo (2013)\n\n\n\n\n\n\n\n\nFigure 7.9 from Cairo (2013)\n\n\n\n\n\n\nFranconeri, Padilla, Shah, Zacks, & Hullman (2021)\n“Visualizations let viewers see beyond summary statistics”\n\n\n\n\n\n“The Datasaurus dozen - same stats, different graphs | Autodesk Research” (n.d.); Matejka & Fitzmaurice (2017)\n\n\n\n\n\n\n“The Datasaurus dozen - same stats, different graphs | Autodesk Research” (n.d.); Matejka & Fitzmaurice (2017)\n\n\n\n\n\n\n“Visual channels translate numbers into images”\n\n\n\n\n\nFigure 2 from Franconeri et al. (2021)\n\n\n\n\n\n\n\n\n\nFigure 3 from Franconeri et al. (2021)\n\n\n\n\n\n\nhttps://www.wcpo.com/news/state/state-ohio/ohio-senate-bans-diversity-initiatives-polices-topics-taught-in-name-of-free-speech-on-college-campuses\n\n\n\n\n\n\n\n\n\nShow me the data!\nEvidence + logical argument\nPlus rigorous self-criticism\n\n\n\n\n\n\n\n\nCommunalism (common ownership)\nUniversalism (independent validity)\nDisinterestedness (public benefit)\nOrganized skepticism (scrutinize everything)\n\n\n\n\n\n\n\n\n\n\n\n\nThe mores of science possess a methodologic rationale…They are procedurally efficent…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that…”\n\n\n\n\n\n\n\n\n\n\n\nhttps://giphy.com\n\n\n\n\n\n\nhttps://giphy.com\n\n\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\n\n\nHow are CO₂ concentrations related to warming? infographic by Fakta o klimatu, licensed under CC BY 4.0.\n\n\n\n\n\n\nFerrell (2025)\n\n\n\n\n\n\n\n\nFerrell (2025)\n\n\n\n\n\n\n\n\nhttps://rick-gilmore.com/posts/data-stories-climate-change/\n\n\n\n\n\n\n\n\nhttps://rick-gilmore.com/posts/data-stories-climate-change-II/"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#announcements",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#announcements",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Assigned today: Final Project proposal"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#last-time",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#last-time",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Pre-attentive vs. attentive vision\nGestalt principles\n\nYour findings"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#today",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#today",
    "title": "From cognition to understanding",
    "section": "",
    "text": "From specifc to general; concrete to abstract\nThe comparing brain"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#from-specific-to-general",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#from-specific-to-general",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 7.3 from Cairo (2013)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#bottom-up-and-top-down",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#bottom-up-and-top-down",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 7.5 from Cairo (2013)\n\n\n\n\n\n\nFigure 7.6 from Cairo (2013)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#how-large-is-the-memory-bank",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#how-large-is-the-memory-bank",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 7.8 from Cairo (2013)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#when-less-detail-more",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#when-less-detail-more",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 7.11 from Cairo (2013)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#abstraction-to-the-rescue",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#abstraction-to-the-rescue",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 7.7 from Cairo (2013)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#some-parts-others",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#some-parts-others",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 7.9 from Cairo (2013)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#back-to-visualizations",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#back-to-visualizations",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Franconeri, Padilla, Shah, Zacks, & Hullman (2021)\n“Visualizations let viewers see beyond summary statistics”\n\n\n\n\n\n“The Datasaurus dozen - same stats, different graphs | Autodesk Research” (n.d.); Matejka & Fitzmaurice (2017)\n\n\n\n\n\n\n“The Datasaurus dozen - same stats, different graphs | Autodesk Research” (n.d.); Matejka & Fitzmaurice (2017)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#franconeri2021-uv",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#franconeri2021-uv",
    "title": "From cognition to understanding",
    "section": "",
    "text": "“Visual channels translate numbers into images”\n\n\n\n\n\nFigure 2 from Franconeri et al. (2021)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#hard-to-map-without-distortion",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#hard-to-map-without-distortion",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Figure 3 from Franconeri et al. (2021)\n\n\n\n\n\n\nhttps://www.wcpo.com/news/state/state-ohio/ohio-senate-bans-diversity-initiatives-polices-topics-taught-in-name-of-free-speech-on-college-campuses"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#debate-is-the-scholarly-way",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#debate-is-the-scholarly-way",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Show me the data!\nEvidence + logical argument\nPlus rigorous self-criticism"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#scientific-norms-merton1973-vf",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#scientific-norms-merton1973-vf",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Communalism (common ownership)\nUniversalism (independent validity)\nDisinterestedness (public benefit)\nOrganized skepticism (scrutinize everything)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#merton1973-vf",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#merton1973-vf",
    "title": "From cognition to understanding",
    "section": "",
    "text": "The mores of science possess a methodologic rationale…They are procedurally efficent…"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#feynman1974-ld",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#feynman1974-ld",
    "title": "From cognition to understanding",
    "section": "",
    "text": "“The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that…”\n\n\n\n\n\n\n\n\n\n\n\nhttps://giphy.com\n\n\n\n\n\n\nhttps://giphy.com\n\n\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\nLindsey (2024)\n\n\n\n\n\n\n\n\nHow are CO₂ concentrations related to warming? infographic by Fakta o klimatu, licensed under CC BY 4.0."
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#the-u.s.-is-only-one-country",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#the-u.s.-is-only-one-country",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Ferrell (2025)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#section",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#section",
    "title": "From cognition to understanding",
    "section": "",
    "text": "Ferrell (2025)"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-capita-by-rich-countries",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-capita-by-rich-countries",
    "title": "From cognition to understanding",
    "section": "",
    "text": "https://rick-gilmore.com/posts/data-stories-climate-change/"
  },
  {
    "objectID": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-gdp-by-rich-countries",
    "href": "slides/CopyOfwk06-2025-02-18-cognition-to-understanding.html#co_2-emissions-per-gdp-by-rich-countries",
    "title": "From cognition to understanding",
    "section": "",
    "text": "https://rick-gilmore.com/posts/data-stories-climate-change-II/"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#announcements",
    "href": "slides/wk06-2025-02-20-designing-viz.html#announcements",
    "title": "Designing efficient & understandable visualizations",
    "section": "Announcements",
    "text": "Announcements\n\nAssigned: Final Project proposal"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#in-the-news",
    "href": "slides/wk06-2025-02-20-designing-viz.html#in-the-news",
    "title": "Designing efficient & understandable visualizations",
    "section": "In the news…",
    "text": "In the news…"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#possible-final-project-topic",
    "href": "slides/wk06-2025-02-20-designing-viz.html#possible-final-project-topic",
    "title": "Designing efficient & understandable visualizations",
    "section": "Possible final project topic",
    "text": "Possible final project topic\n\nMany more findings & nuances than discussed here\nData are shared, see Isenberg & Brauer (2023)"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#last-time",
    "href": "slides/wk06-2025-02-20-designing-viz.html#last-time",
    "title": "Designing efficient & understandable visualizations",
    "section": "Last time…",
    "text": "Last time…"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#top-down-processing",
    "href": "slides/wk06-2025-02-20-designing-viz.html#top-down-processing",
    "title": "Designing efficient & understandable visualizations",
    "section": "Top-down processing",
    "text": "Top-down processing"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#today",
    "href": "slides/wk06-2025-02-20-designing-viz.html#today",
    "title": "Designing efficient & understandable visualizations",
    "section": "Today",
    "text": "Today\n\nDesigning efficient & understandable visualizations\nFinal project check-ins"
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 3. Deceptive axis manipulations across a line graph (top left) and a bar graph (top right). So, should data always be plotted relative to zero? The graph on the bottom left depicts climate change by plotting temperature data from a baseline of 0 °F, yet most would agree that graph is less informative than the version to its right, which allows the differences in temperatures to be seen. At the bottom right of the figure, a cover of The Economist from September 2019 maps the same restricted range of data to the full range of a blue-to-red color scale. The graphs at top left are inspired by Huff (1954); those at bottom left are inspired by Correll et al. (2020). The magazine cover at bottom right is reprinted, with permission, from The Economist (September 19, 2019)."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-1",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-1",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 4. A set of common visual confusions, illusions, and distortions. At upper left, the two human icons represent vastly different ratios depending on whether the data are represented by their one-dimensional heights, their two-dimensional areas, or their three-dimensional volumes. The donut graph to their right shows that three-dimensional depictions can artificially inflate data values in the two-dimensional plane. At bottom left, the same fMRI data are plotted with two color mappings. The brain image on the left produces less of a spurious categorical boundary effect, whereas the image on the right shows a common red-to-green color map that makes continuous variation appear exaggerated when it maps onto transitions from one color category to another. At center, an illusion prohibits the accurate recovery of differences between values in a line graph. At right, correlation is easier to detect from the scatterplot, but individual histograms for each dimension are easier to see when plotted separately."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-2",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-2",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 5. Three ways to encode data for two groups in a scatterplot, as seen by observers with typical color perception and those with protanopia, a form of color blindness. Protanopia was simulated in Photoshop."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-3",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-3",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 6. The standard shape set for Microsoft Excel (left) compared with a perceptually spaced set (right; inspired by Huang, 2020). Try to pick out the four instances of each shape in each display—you should find that task easier on the right side."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-4",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-4",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 7. Visual comparison as a serial process. In the bar graph on the left, which student has a second bar that is lower than the first? To find the answer, the viewer needs to process each set of bars individually, rather than all at once. On the right, viewers tasked with processing the blue set of marks failed to notice the dinosaur shape created by the green set of marks. The image on the right is reprinted from Boger et al. (2021)."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-5",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-5",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 8. Several grouping cues that can control how data values are compared. Connecting lines are particularly powerful cues, followed by proximity, color, and shape (Brooks, 2015)."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-6",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-6",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 9. How visual grouping cues can control visual comparison. At top, a combination of color and proximity grouping lead the viewer to different visual comparisons across the two bar graphs. At the bottom, comparisons in a word cloud are weakly controlled by color grouping, and more strongly controlled with proximity grouping."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#section-7",
    "href": "slides/wk06-2025-02-20-designing-viz.html#section-7",
    "title": "Designing efficient & understandable visualizations",
    "section": "",
    "text": "Franconeri et al. (2021). Fig. 10. Color highlighting and direct annotation to help viewers make the right comparison first and know what conclusion is supported by that pattern in the data. The graphic at the top illustrates a color-highlighting technique suggested in business-oriented practitioner guides (e.g., Knaflic, 2015). The graphs at the bottom (inspired by Bostock et al., 2012) are an adaptation of a graph by data journalists using grouping, highlighting, and verbal annotation."
  },
  {
    "objectID": "slides/wk06-2025-02-20-designing-viz.html#references",
    "href": "slides/wk06-2025-02-20-designing-viz.html#references",
    "title": "Designing efficient & understandable visualizations",
    "section": "References",
    "text": "References\n\n\n\n\nDid aristotle say \"the more you know...\". (n.d.). Retrieved February 19, 2025, from https://philosophy.stackexchange.com/questions/46282/did-aristotle-say-the-more-you-know\n\n\nFranconeri, S. L., Padilla, L. M., Shah, P., Zacks, J. M., & Hullman, J. (2021). The science of visual data communication: What works. Psychological Science in the Public Interest: A Journal of the American Psychological Society, 22(3), 110–161. https://doi.org/10.1177/15291006211051956\n\n\nHirschman, D. (2010, September 4). Adventures in fact-checking: Einstein quote edition. Retrieved February 19, 2025, from https://asociologist.com/2010/09/04/adventures-in-fact-checking-einstein-quote-edition/\n\n\nIndigoGirlsVEVO. (2009). Indigo girls - galileo (official video). Youtube. Retrieved from https://www.youtube.com/watch?v=dI1keSSwdcI\n\n\nIsenberg, N., & Brauer, M. (2023). Pluralistic ignorance about DEI. Retrieved from https://osf.io/ncd29/?view_only=fa3b86146da6440c85a2ca1f39dac247\n\n\nIsenberg, N., & Brauer, M. (2024). Diversity and inclusion have greater support than most americans think. Scientific Reports, 14, 28616. https://doi.org/10.1038/s41598-024-76761-8"
  }
]